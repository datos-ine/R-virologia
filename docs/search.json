[
  {
    "objectID": "unidad8.html",
    "href": "unidad8.html",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "",
    "text": "Quarto ofrece un marco de creación unificado para la ciencia de datos, que combina código, resultados del código y escritura. Es decir, combina un lenguaje de programación (R, en nuestro caso pero podríamos usar otros lenguajes como python o julia) con un lenguaje de documentación (markdown + otras utilidades).\nLos documentos de Quarto son totalmente reproducibles y admiten docenas de formatos de salida, como archivos HTML, PDF, Word, presentaciones y más.\nLos archivos Quarto están diseñados para usarse de tres maneras:\n\nComunicar resultados y nuestras conclusiones (sin mostrar el código detrás del análisis).\nColaborar con otros científicos de datos que trabajen en el mismo proyecto o estén interesados en nuestro trabajo (aquí seguramente incluimos el código).\nComo un entorno en el que hacer ciencia de datos, como un cuaderno de laboratorio moderno donde podemos registrar no solo lo que hicimos, sino también lo que pensamos.\n\nHeredan lo mejor de los 10 años de desarrollo acumulado, dado que los documentos tienen muchas similitudes pero con la ventaja de integrar otras herramientas que surgieron como extensiones de Rmarkdown.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#documentos-quarto",
    "href": "unidad8.html#documentos-quarto",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "",
    "text": "Quarto ofrece un marco de creación unificado para la ciencia de datos, que combina código, resultados del código y escritura. Es decir, combina un lenguaje de programación (R, en nuestro caso pero podríamos usar otros lenguajes como python o julia) con un lenguaje de documentación (markdown + otras utilidades).\nLos documentos de Quarto son totalmente reproducibles y admiten docenas de formatos de salida, como archivos HTML, PDF, Word, presentaciones y más.\nLos archivos Quarto están diseñados para usarse de tres maneras:\n\nComunicar resultados y nuestras conclusiones (sin mostrar el código detrás del análisis).\nColaborar con otros científicos de datos que trabajen en el mismo proyecto o estén interesados en nuestro trabajo (aquí seguramente incluimos el código).\nComo un entorno en el que hacer ciencia de datos, como un cuaderno de laboratorio moderno donde podemos registrar no solo lo que hicimos, sino también lo que pensamos.\n\nHeredan lo mejor de los 10 años de desarrollo acumulado, dado que los documentos tienen muchas similitudes pero con la ventaja de integrar otras herramientas que surgieron como extensiones de Rmarkdown.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#conceptos-básicos",
    "href": "unidad8.html#conceptos-básicos",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Conceptos básicos",
    "text": "Conceptos básicos\nQuarto es un software que se instala independientemente de R y Rstudio. En si mismo funciona con una interfaz de línea de comandos (CLI).\nSu sitio web es https://quarto.org/ y el acceso a la descarga ese encuentra en Get Started. Una vez descargado el ejecutable su instalación es sencilla y similar a cualquier aplicación de Windows.\nLas últimas versiones de RStudio ya lo tienen integrado, al igual que markdown y Pandoc, por lo que vamos a utilizarlo directamente sin necesidad de aprendernos los comandos nativos de su línea de comandos.\nCabe destacar que Quarto se encuentra en pleno desarrollo y es habitual que se publiquen versiones actualizadas que incluyen avances y nuevas tecnologías. Estas nuevas versiones demoran un tiempo en aparecer incluídas en RStudio, por lo que se sugiere actualizarlo individualmente.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#anatomía-de-un-documento-quarto",
    "href": "unidad8.html#anatomía-de-un-documento-quarto",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Anatomía de un documento Quarto",
    "text": "Anatomía de un documento Quarto\nLos archivos fuentes de Quarto tienen extensión .qmd y sus partes fundamentales son:\n\n\n\n\n\n\nEditor Visual:\nRStudio incorporó un editor gráfico de archivos Quarto, similar a un editor de texto como Word. En lugar de código en texto plano con sus marcas, vemos un aspecto más visual con un menú que permite integrar imágenes, tablas, títulos, colores, etc.\n\n\nCabecera YAML:\nEsta cabecera inicia todo documento Quarto y contiene los metadatos del archivo con las opciones de configuración generales. Es el lugar donde se define que tipo de documento estamos produciendo (html, pdf, etc).\nYAML es un lenguaje de marcas ligero del cual utilizaremos algunas opciones.\n\n\nEncabezados (títulos) y Outline:\nLos documentos Quarto contienen un formato jerárquico con cabeceras que permiten dar estructura al contenido. Además, mientras se escribe, genera un índice (outline) a la derecha del script con el cual nos movemos rápidamente por el documento\n\n\nTexto en markdown\nNo solo se puede incluir texto plano acompañado de marcas que le dan un formato particular, sino también embeber imágenes, tablas, fragmentos estéticos diferentes, etc.\n\n\nFragmentos de código (chunk)\nEn estas secciones delimitadas se incluye el código que se ejecuta (y también puede ser mostrado) en el documento final. Estos chunk, como se denominan en inglés, pueden ser de diferentes lenguajes (en nuestro caso utilizaremos habitualmente el lenguaje R).",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#editor-visual-de-rstudio",
    "href": "unidad8.html#editor-visual-de-rstudio",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Editor visual de RStudio",
    "text": "Editor visual de RStudio\nEl editor visual proporciona una interfaz sencilla para la creación de documentos de Quarto. En el fondo, el texto de los documentos de Quarto (archivos .qmd) se escribe en lenguaje Markdown, un conjunto ligero de marcas para formatear archivos de texto sin formato. De hecho, Quarto utiliza Markdown de Pandoc (una versión ampliada de Markdown que Quarto entiende), incluidas tablas, citas, referencias cruzadas, notas al pie, listas de definiciones, atributos, HTML/TeX sin formato y más, así como compatibilidad con la ejecución de celdas de código y la visualización de su salida en línea. Si bien Markdown está diseñado para ser fácil de leer y escribir, requiere aprender una nueva sintaxis, por lo tanto conviene utilizar las herramientas del modo visual.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#edición-en-código-fuente",
    "href": "unidad8.html#edición-en-código-fuente",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Edición en código fuente",
    "text": "Edición en código fuente\nEl modo source (fuente) sirve para editar el documento en markdown puro con todas sus marcas sin la ayuda del modo visual. Para aquellos acostumbrados a sus sintaxis posibilita escribir directamente con la estructura adecuada y depurar sus errores.\nAhora bien, cuando trabajamos en el editor visual aunque nos muestre los elementos con el formato de salida, en realidad en el documento guarda su contenido en Markdown simple y se puede alternar entre los editores visuales y de source para ver y editar el contenido usando cualquiera de las herramientas.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#fragmentos-de-código",
    "href": "unidad8.html#fragmentos-de-código",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Fragmentos de código",
    "text": "Fragmentos de código\nPara ejecutar código dentro de un documento de Quarto, es necesario insertar un fragmento.\nLas tres formas de hacerlo son:\n\nUsar el atajo de teclado Ctrl + Alt + I.\nPulsar el icono del botón “Insert” en la barra de herramientas del editor.\nEscribir manualmente los delimitadores de fragmentos ```{r} y ```.\n\nEl código que se incluye tiene las misma características que el código de un script común de R. Lo que si hay que tener en cuenta es que la activación de paquetes y la lectura de archivos debe ser explícita dentro del documento, es decir aunque tengamos algún paquete activo en la sesión de trabajo o datos leídos en el entorno de trabajo, si estos no figuran dentro de algún fragmento del documento (por ejemplo, porque se ejecutaron en consola directamente) al momento de renderizar vamos a tener la devolución de un error.\n\nOpciones de fragmentos\nDentro de los fragmentos de código se puede declarar metadatos llamados opciones de ejecución.\nEl formato sintáctico en Quarto tiene la forma #| y suele encabezar el fragmento.\n\n```{r}\n#| echo: fenced\n\n1 + 1\n```\n\nEn el ejemplo anterior echo: fenced es una opción de ejecución que como metadato asociado al código provoca que en el documento renderizado dicho código se muestre junto al resultado incluída la opción de ejecución.\nEl motor Knitr incluído en RStudio es el que proporciona casi 60 opciones de ejecución que se pueden usar para personalizar los fragmentos de código.\nLa lista completa de códigos se puede ver en https://yihui.org/knitr/options.\nAlgunas de las opciones más importantes para controlar bloques son:\n\neval: false Evita que se evalúe el código (y, obviamente, si no se ejecuta el código, no se generarán resultados). Esto es útil para mostrar código de ejemplo o para deshabilitar un bloque grande de código sin comentar cada línea.\ninclude: false Ejecuta el código, pero no muestra el código ni los resultados en el documento final. Puede servir para tareas internas.\necho: false Evita que el código, pero no los resultados, aparezcan en el archivo final.\nmessage: false o warning: false Evita que aparezcan mensajes o advertencias en el archivo terminado.\nresults: hide Oculta la salida impresa; fig-show: hide Oculta los gráficos.\nerror: true Hace que la renderización continúe incluso si el código devuelve un error.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#formatos",
    "href": "unidad8.html#formatos",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Formatos",
    "text": "Formatos\nLos formatos de salida de Quarto son bien variados y todos se definen dentro del encabezado YAML del documento.\nDe forma predeterminada la salida es HTML y una cabecera básica sería:\n\n---\ntitle: \"Título del documento\"\nformat: html\n---\n\nEn esta misma cabecera se incluyen también las opciones de salida o renderizado, por ejemplo:\n\n---\ntitle: \"Título del documento\"\nformat: \n  html:\n    toc: true\n    toc_float: true\n---\n\nLa salida será un archivo html con tabla de contenidos (toc) flotante.\nOtros formatos posibles son:\n\nDocumentos\n\npdf crea un PDF con LaTeX (un sistema de diseño de documentos de código abierto)\ntypst crea un PDF con typst (un sistema de composición moderno y sencillo de documentos pdf)\ndocx construye documentos de Microsoft Word ( .docx).\nodt construye documentos OpenDocument Text ( .odt).\nrtf construye documentos con formato de texto enriquecido ( .rtf).\n\n\n\nPresentaciones\n\nrevealjs Presentación HTML con RevealJS\npptx Presentación de Powerpoint\nbeamer Presentación en PDF con LaTeX Beamer.\n\nExisten numerosas opciones relacionadas al tipo de salida propuesta que se pueden encontrar en cada apartado de la guía oficial de Quarto.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#tableros-de-quarto",
    "href": "unidad8.html#tableros-de-quarto",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Tableros de Quarto",
    "text": "Tableros de Quarto\nA partir de la versión 1.4, Quarto incorpora la creación de tableros (dashboard). Con una forma de producción sencilla que tiene varios elementos similares a los utilizados por el paquete flexdashboard de RMarkdown.\nLos tableros pueden ser estáticos o interactivos, se les puede incluir una gran variedad de componentes como dispositivos externos provenientes de htmlwidgets y sus diseños suelen ser flexibles y adaptativos (los componentes se redimensionan de forma inteligente para llenar el navegador y se adaptan para su visualización en dispositivos móviles).",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#cabecera-yaml-1",
    "href": "unidad8.html#cabecera-yaml-1",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Cabecera YAML",
    "text": "Cabecera YAML\nLa cabecera que define un tablero tiene el formato configurado en dashboard.\n---\nformat: dashboard\n---\nAlgunas opciones de ejecución YAML son similares a las conocidas para otros documentos: title, author, theme, toc, otras son particulares de este formato: orientation, scrolling, expandable, nav-buttons, etc.\nCuando el tablero tiene componentes de interactividad debemos indicar en la cabecera el motor Shiny que manejará el código, de la siguiente forma:\n---\nformat: dashboard\nserver: shiny\n---\n\n\n\n\n\n\nEn tableros con componentes interactivos htmlwidgets basados en JavaScript u Observable JS no hace falta incluir nada especial en la cabecera.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#componentes-de-un-tablero",
    "href": "unidad8.html#componentes-de-un-tablero",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Componentes de un tablero",
    "text": "Componentes de un tablero\nLos componentes básicos de un tablero son:\n\nBarra de navegación (páginas):\nSuele ser la barra superior horizontal donde incluimos el ícono, título y autor junto con enlaces a subpáginas (si se define más de una página).\nAquí un ejemplo de barra de navegación:\n\n\n\n\n\n\n\nBarras laterales, filas y columnas y conjuntos de pestañas:\nEn estas barras se ubican muchas veces las entradas (inputs) interactivas.\nAdemás se pueden agregar filas y columnas con encabezados markdown (atributos opcionales para controlar la altura, el ancho, etc.) y conjuntos de pestañas para dividir aún más el contenido.\n\n\n\n\n\n\n\nTarjetas (gráficos, tablas, cajas de valores, contenido):\nLas tarjetas (cards) son contenedores para resultados de celdas y texto markdown de formato libre. El contenido de las tarjetas normalmente se asigna a las celdas de su documento fuente.\nEn estas celdas se suele incluir valores, tablas, gráficos, elementos dinámicos o interactivos. Algunos formatos vienen previamente soportados como las cajas de valores (valuebox)",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#diseño",
    "href": "unidad8.html#diseño",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Diseño",
    "text": "Diseño\nA la combinación de barras y tarjetas con su ubicación y orientación la llamamos diseño del tablero.\nEl diseño va a estar dado por los distintos componentes que deseemos mostrar. Mientras las páginas se declaran con encabezados 1 (#) los bloques fila o columna se hacen con encabezados 2 (##), a los cuales se le puede agregar definición de ancho con width o alto con height.\nLas barras laterales se arman con encabezados 1 (#) con estilo .sidebar y las pestañas con encabezados 2 y estilo .tabset.\nAlgunos ejemplos:\nBarra lateral\n---\ntitle: \"Mi Tablero\"\nformat: dashboard\n---\n\n# Pagina 1\n\n## {.sidebar}\n\n```{r}\n\n```\n\n## Column\n\n```{r}\n\n```\n\n```{r}\n\n```\n\n\n\n\n\nFilas\n---\ntitle: \"Mi Tablero\"\nformat: dashboard\n---\n\n## Row {height=70%}\n\n```{r}\n```\n\n## Row {height=30%}\n\n```{r}\n```\n\n```{r}\n```\n\n\n\n\n\nColumnas\n---\ntitle: \"Mi Tablero\"\nformat: dashboard\n---\n\n## Column {width=60%}\n\n```{r}\n```\n\n## Column {width=40%}\n\n```{r}\n```\n\n```{r}\n```\n\n\n\n\n\nPestañas\n---\ntitle: \"Mi Tablero\"\nformat: dashboard\n---\n\n## Row\n\n```{r}\n```\n\n## Row {.tabset}\n\n```{r}\n#| title: Chart 2\n```\n\n```{r}\n#| title: Chart 3\n```",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#tarjetas",
    "href": "unidad8.html#tarjetas",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Tarjetas",
    "text": "Tarjetas\nLas tarjetas son la unidad fundamental de visualización dentro de los tableros.\nPueden encerrar tanto texto markdown como código que produzca alguna salida tipo valor, tabla o gráfico.\n::: {.card}\n\nAquí va el contenido de la tarjeta. Puede ser un markdown directo o la salida de código.\n\n```{r}\n\n```\n\n:::\nLas cajas de valor son tarjetas especiales que se declaran con el estilo reservado .valuebox.\n\n::: {.valuebox}\nFecha actual\n\n2025-07-03\n:::\nTambién se pueden declarar con metadatos dentro del bloque de código:\n#| content: valuebox\n#| title: \"Caja de valor\"\nn &lt;- mtcars |&gt; \n  tibble::as_tibble() |&gt; \n  dplyr::count() |&gt; \n  dplyr::pull(n)\n\nlist(\n  icon = \"trash\",\n  color = \"red\",\n  value = n\n)\n\n\n\n\n\n\nAquí se incluyen también dispositivos con cierta interactividad directa como son los htmlwidgets o si se conoce el lenguaje, código de Observable JS.\nLa galería de widgets disponibles en la actualidad cuenta con 132 dispositivos que se puede ver en https://gallery.htmlwidgets.org/",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#interactividad",
    "href": "unidad8.html#interactividad",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Interactividad",
    "text": "Interactividad\nLos documentos que tienen elementos interactivos de R utilizan Shiny como servidor. Shiny es una librería para producir aplicaciones interactivas bajo R y recientemente en python.\nAnteriormente vimos que la cabecera YAML tiene que tener la opción server: shiny para que este se encuentre activo y pueda utilizarse dentro del tablero.\nLa estructura de Shiny necesita de dos componentes:\n\nla interfaz de usuario (ui)\nel servidor Shiny\n\nEl funcionamiento interno es tipo cliente/servidor, donde en la interfaz de usuario se ubican los inputs con los que el usuario se vincula y del lado del servidor se responde a los cambios de esas entradas.\nGeneralmente los inputs van dentro de la barra lateral y el server se declara como contexto en los fragmentos de código. Por ejemplo:\n\n## {.sidebar}\n\n```{r}\nselectInput(\n    \"variableChoice\",\n    \"Seleccione una variable:\",\n    choices = names(mtcars)\n  )\n```\n\n## Row\n\n```{r}\n#| context: server\n\noutput$variablePlot &lt;- renderPlot({\n  yVar &lt;- mtcars[[input$variableChoice]]\n  plot(mtcars$index, yVar)\n})\n```\n\nEste código tiene un input de selección en la barra lateral, donde el usuario puede seleccionar una variable del dataset mtcars, y un fragmento de contexto servidor donde renderiza un gráfico de dispersión en base a la variable elegida (input$variableChoice).",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#inputs",
    "href": "unidad8.html#inputs",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Inputs",
    "text": "Inputs\nLas entradas de Shiny son funciones que sirven para crear elementos de interfaz de usuario que solicitan al usuario valores de entrada o interacción.\nAlgunos de sus inputs básicos son:\n\n\n\n\n\nBotones, casillas de verificación (sola o múltiples), ingreso de fechas, números y texto, rangos, cajas de selección, barras de desplazamiento, etc son algunos de los muchos dispositivos que vienen ya preparados.\nLa referencia a esas funciones las podrán encontrar en https://shiny.posit.co/r/reference/shiny/latest/.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#temas",
    "href": "unidad8.html#temas",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Temas",
    "text": "Temas\nDe la misma forma que en los productos Quarto anteriores se pueden definir temas estéticos preconfigurados o personalizar uno propio, mediante la declaración en la cabecera YAML de theme:.\nEntre los predeterminados, encontramos 25 posibles (Bootswatch project): lumen, materia, minty, slate son alguno de ellos.\nPara personalizar un tema se procede a utilizar archivos css o scss (Sass). Bootstrap define más de 1400 variables Sass que controlan fuentes, colores, relleno, bordes y mucho más. Se pueden ver todas las variables aquí:\nhttps://github.com/twbs/bootstrap/blob/main/scss/_variables.scss\nPara personalizar un tema Bootstrap existente con un conjunto propio de variables o reglas, solo definimos el tema base y luego los archivos de tema personalizados:\n\ntheme:\n  - cosmo\n  - custom.scss\n\nEl archivo de personalización Sass custom.scss podría ser:\n/*-- scss:defaults --*/\n$h2-font-size:          1.6rem !default;\n\n\n/*-- scss:rules --*/\nh1, h2, h3, h4, h5, h6 {\n  text-shadow: -1px -1px 0 rgba(0, 0, 0, .3);\n}\nDonde en la sección indicada por /*-- scss:defaults --*/ pertenece a las variables ($h2-font-size: tamaño de fuente en encabezado 2) y la sección de reglas (donde van las reglas CSS normales) está indicada por el /*-- scss:rules --*/ (text-shadow: -1px -1px 0 rgba(0, 0, 0, .3); sombreado en encabezados desde 1 al 6).\nNaturalmente, también se puede crear un tema totalmente personalizado y proporcionar solo eso (en este caso, se hereda el tema Bootstrap predeterminado):\n\ntheme: custom.scss\nLas variables Sass más comunes estan publicadas en: https://quarto.org/docs/dashboards/theming.html#sass-variables\nMas información sobre temas HTML en https://quarto.org/docs/output-formats/html-themes-more.html",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad8.html#publicación",
    "href": "unidad8.html#publicación",
    "title": "Unidad 8: Comunicar con Quarto",
    "section": "Publicación",
    "text": "Publicación\nLos tableros suelen ser simplemente páginas HTML estáticas, por lo que se pueden implementar en cualquier servidor web.\nEstos tableros, a su vez si se combinan con una lectura periódica de la fuente de datos pueden mostrar actualizaciones según vayan variando esos datos. A esto se le llama tablero programado (por ejemplo, a través de una tarea cron).\nTambién se pueden parametrizar, a traves de parameters en la cabecera YAML o bien pasar a ser tableros completamente interactivos con Shiny, donde se requiere un servidor especial para su implementación.\nRStudio trae incorporado en su IDE accesos directos de publicación a Posit Connect Cloud mediante el botón , dado que pertenece a la misma empresa Posit. Sus servicios son los que mejor se adaptan a los requerimientos de usuarios que producen estos documentos pero con planes comerciales.\nOtras opciones de sitios que publican tableros estáticos gratuitamente son:\n\nQuarto Pub\n\nEs un servicio gratuito de publicación de contenido hecho en Quarto. Además de tableros se puede alojar blogs, sitios web, libros, presentaciones y otros documentos.\nEstas publicaciones serán siempre visibles por cualquier usuario de Internet, no pueden tener más de 100 Mb y poseen un ancho de banda de navegación de 10 Gb por mes.\nSe puede publicar mediante el comando quarto publish en la Terminal. Deberá tener una cuenta a su nombre que podrá obtener en https://www.quarto.pub. La dirección creada agrega como dominio quarto.pub a su nombre de usuario y luego la dirección al sitio creado (puede tener varios). La administración se realiza desde el propio sitio web.\nMás información en https://quarto.org/docs/publishing/quarto-pub.html\n\nConfluence\n\nAtlassian Confluence es una plataforma de publicación que soporta la colaboración en equipo.\nQuarto proporciona la cpacidad de publicar documentos individuales, así como proyectos compuestos por múltiples documentos en Confluence Spaces.\nConfluence cuenta con una variedad de opciones de alojamiento que incluyen planes de suscripción gratuitos y pagos.\nSe puede publicar mediante el comando quarto publish confluence en la Terminal de RStudio, siempre y cuando contemos con una cuenta configurada.\nPara más información ver en https://quarto.org/docs/publishing/confluence.html\n\nGitHub Pages\n\nEs un servicio de alojamiento de sitios web que le permite publicar contenido basado en código fuente administrado dentro de un repositorio de GitHub.\nLos repositorios GitHub se alojan en una plataforma online de desarrollo de software basada en la nube que permite a los desarrolladores almacenar, compartir y trabajar juntos en proyectos de código abierto. GitHub utiliza un sistema de control de versiones llamado Git para alojar los proyectos y llevar un registro de los cambios. Esto permite colaborar y realizar cambios en los proyectos compartidos, al tiempo que mantienen un seguimiento detallado del progreso.\nTambién se puede publicar mediante el comando quarto publish gh-pages en la Terminal de RStudio, mientras exista la cuenta y repositorio del proyecto y esté habilitada la opción de GitHub Pages.\nPara más información leer https://quarto.org/docs/publishing/github-pages.html\nEn el caso de tableros interactivos, que necesiten de un servidor Shiny, se puede usar versiones en la nube tipo:\n\nshinyapps.io\n\nShiny Apps de Posit es un sitio de alojamiento con recursos de servidor para aplicaciones interactivas Shiny.\nEl plan gratuito consta de un máximo de 5 aplicaciones subidas y 25 horas activas (uso de la aplicación). Luego posee planes comerciales con mayores recursos.\nLa publicación viene integrada con RStudio y utiliza el paquete rsconnect para realizar las tareas necesarias.\n\nHugging Face\n\nHugging Face es una plataforma open source de ciencia de datos y machine learning que proporciona herramientas para construir, entrenar y desplegar soluciones de aprendizaje automático. Como repositorio es similar a GitHub y tiene un servicio de Spaces donde se pueden publicar aplicaciones Shiny mediante tecnología Docker.\nO instalación de servidores locales como Shiny Server (open-source), que seguramente necesitará de personal formado como Administrador de TI y disponer de un servidor linux con conexión simétrica a Internet y firewall, entre otros recursos.",
    "crumbs": [
      "Unidad 8: Comunicar con Quarto"
    ]
  },
  {
    "objectID": "unidad6.html",
    "href": "unidad6.html",
    "title": "Unidad 6: Inferencia estadística",
    "section": "",
    "text": "La estadística inferencial es la rama de la estadística que permite formular conclusiones sobre una población a partir del análisis de una muestra. Se apoya en el cálculo de probabilidades, que proporciona el marco teórico para modelar fenómenos aleatorios y generalizar los resultados muestrales a toda la población. Dado que las inferencias basadas en muestras están sujetas a incertidumbre, es fundamental expresarlas siempre en términos probabilísticos.\nLas dos actividades principales en este proceso son:\n\nEstimación de parámetros: consiste en calcular, a partir de los datos muestrales, valores que aproximen parámetros desconocidos de la población.\n\nEjemplo: Estimar la prevalencia de una enfermedad X en la población.\n\nPruebas de hipótesis: implica evaluar con base estadística afirmaciones acerca de uno o más parámetros.\nEjemplos:\n\n¿La prevalencia de la enfermedad X en Argentina es menor que en Uruguay?\n¿La prevalencia de la enfermedad X en Argentina en 2010 fue menor que en el año 2000?\n\n\nAl trabajar con muestras, entra en juego el concepto de teoría del muestreo, que, si bien no abordaremos en profundidad aquí, es clave para comprender cómo se relacionan los valores observados en la muestra con los de la población.\nEsta teoría estudia la relación entre la distribución de una variable en la población y el comportamiento de dicha variable en muestras aleatorias extraídas de ella. A las medidas obtenidas a partir de la muestra se las denomina estadísticos muestrales o simplemente estadísticos, mientras que sus contrapartes en la población se denominan parámetros.\nPor ejemplo, supongamos que queremos conocer el valor medio de colesterol total de la población de Mar del Plata y tomamos una muestra de tamaño \\(n\\).\n\nLa media poblacional del colesterol total se representa con la letra griega \\(\\mu\\) y corresponde al parámetro.\nLa media muestral, que se obtiene a partir de los datos de la muestra, se representa como \\(\\bar{x}\\) y es un estimador o estadístico muestral.\n\n\n\n\n\n\nLa distribución muestral de un estadístico es la distribución de todos los valores posibles que ese estadístico puede tomar al calcularse en muestras aleatorias del mismo tamaño extraídas de una misma población. Este concepto es central en la inferencia estadística, ya que permite cuantificar la incertidumbre asociada a las estimaciones.\nComo construir una distribución muestral puede resultar muy laborioso cuando la población es grande, y directamente imposible si es infinita, se suelen utilizar aproximaciones basadas en la toma de un gran número de muestras aleatorias del mismo tamaño.",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad6.html#introducción",
    "href": "unidad6.html#introducción",
    "title": "Unidad 6: Inferencia estadística",
    "section": "",
    "text": "La estadística inferencial es la rama de la estadística que permite formular conclusiones sobre una población a partir del análisis de una muestra. Se apoya en el cálculo de probabilidades, que proporciona el marco teórico para modelar fenómenos aleatorios y generalizar los resultados muestrales a toda la población. Dado que las inferencias basadas en muestras están sujetas a incertidumbre, es fundamental expresarlas siempre en términos probabilísticos.\nLas dos actividades principales en este proceso son:\n\nEstimación de parámetros: consiste en calcular, a partir de los datos muestrales, valores que aproximen parámetros desconocidos de la población.\n\nEjemplo: Estimar la prevalencia de una enfermedad X en la población.\n\nPruebas de hipótesis: implica evaluar con base estadística afirmaciones acerca de uno o más parámetros.\nEjemplos:\n\n¿La prevalencia de la enfermedad X en Argentina es menor que en Uruguay?\n¿La prevalencia de la enfermedad X en Argentina en 2010 fue menor que en el año 2000?\n\n\nAl trabajar con muestras, entra en juego el concepto de teoría del muestreo, que, si bien no abordaremos en profundidad aquí, es clave para comprender cómo se relacionan los valores observados en la muestra con los de la población.\nEsta teoría estudia la relación entre la distribución de una variable en la población y el comportamiento de dicha variable en muestras aleatorias extraídas de ella. A las medidas obtenidas a partir de la muestra se las denomina estadísticos muestrales o simplemente estadísticos, mientras que sus contrapartes en la población se denominan parámetros.\nPor ejemplo, supongamos que queremos conocer el valor medio de colesterol total de la población de Mar del Plata y tomamos una muestra de tamaño \\(n\\).\n\nLa media poblacional del colesterol total se representa con la letra griega \\(\\mu\\) y corresponde al parámetro.\nLa media muestral, que se obtiene a partir de los datos de la muestra, se representa como \\(\\bar{x}\\) y es un estimador o estadístico muestral.\n\n\n\n\n\n\nLa distribución muestral de un estadístico es la distribución de todos los valores posibles que ese estadístico puede tomar al calcularse en muestras aleatorias del mismo tamaño extraídas de una misma población. Este concepto es central en la inferencia estadística, ya que permite cuantificar la incertidumbre asociada a las estimaciones.\nComo construir una distribución muestral puede resultar muy laborioso cuando la población es grande, y directamente imposible si es infinita, se suelen utilizar aproximaciones basadas en la toma de un gran número de muestras aleatorias del mismo tamaño.",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad6.html#intervalos-de-confianza-ic",
    "href": "unidad6.html#intervalos-de-confianza-ic",
    "title": "Unidad 6: Inferencia estadística",
    "section": "Intervalos de Confianza (IC)",
    "text": "Intervalos de Confianza (IC)\nUna forma eficaz de abordar la inferencia estadística es a través de los intervalos de confianza (IC), ya que, aunque son procedimientos inferenciales, están estrechamente vinculados con la estadística descriptiva.\nSupongamos que queremos estimar la media de colesterol de la población de Mar del Plata. Sería inviable medir el colesterol de cada habitante, por lo que optamos por tomar una muestra de, por ejemplo, 100, 200 o 300 individuos (más adelante veremos cómo determinar el tamaño adecuado de la muestra). Debemos recordar que diferentes muestras producirán en general medias diferentes. Existe, por tanto, un grado de incertidumbre asociado. Si hiciéramos una estimación puntual, obtendríamos un solo valor, pero sin información sobre su variabilidad. No sabríamos qué tan cerca o lejos está nuestra estimación (\\(\\bar{x}\\)) de la verdadera media poblacional (\\(\\mu\\)).\nEl intervalo de confianza proporciona un rango de valores dentro del cual se espera que se encuentre el valor verdadero del parámetro poblacional, con un cierto nivel de confianza. A diferencia de la estimación puntual que proporciona un único valor numérico, el intervalo consta de dos valores entre los cuales se supone está contenido el parámetro estimado. Entonces, el intervalo de confianza puede expresarse como:\n\\[ IC = estimador~puntual \\pm (coeficiente~de~confiabilidad) * (error~ estandar) \\]\ndonde:\n\nEstimador puntual:\n\nPara la media poblacional (\\(\\mu\\)), se toma la media muestral(\\(\\bar{x}\\)).\nPara una proporción de la población (\\(p\\)), se toma la proporción muestral (\\(\\hat{p}\\)).\n\nCoeficiente de confiabilidad: Se relaciona con el nivel de confianza deseado (por ejemplo, 90%, 95% o 99%), y se expresa como \\(1 - \\alpha\\), es decir la probabilidad de que el parámetro se encuentre dentro del IC. Recordemos que el nivel de significancia (\\(\\alpha\\)) es la probabilidad de que el parámetro no se halle dentro del IC y es un valor generalmente pequeño (por ejemplo, 0.1, 0.05 o 0.01) expresado como probabilidad o porcentaje (por ejemplo, 10%, 5% o 1%).\nError estándar (SE): Representa la variabilidad de la distribución muestral. Por ejemplo, para la media el error estándar se calcula como la raíz cuadrada de la varianza de la distribución muestral:\n\\[\nSE = \\frac{\\sigma}{\\sqrt{n}}\n\\]\nDonde \\(\\sigma\\) es la desviación estándar poblacional y \\(n\\) el tamaño de la muestra. Si se estima un IC para una proporción, el error estándar es:\n\\[\nSE = \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\n\\]\n\nEl proceso se fundamenta en el Teorema del Límite Central (TCL), que establece que, para muestras suficientemente grandes, la distribución de \\(\\bar{x}\\) es aproximadamente normal, con media \\(\\mu\\) y varianza \\(\\sigma^2/n\\). Así, la variable tipificada:\n\\[\nZ = \\frac{\\bar{x}-\\mu}{\\sigma}\n\\]\nsigue una distribución normal estándar (media 0 y desviación estándar 1), lo que permite calcular probabilidades y construir el IC.\nEn cualquier distribución normal:\n\nEntre \\(\\mu \\pm \\sigma\\) se encuentra el 68% de los datos.\nEntre \\(\\mu \\pm 2\\sigma\\) se encuentra el 95%.\nEntre \\(\\mu \\pm 3\\sigma\\) se encuentra el 99%.\n\nEl siguiente gráfico ilustra lo explicado anteriormente:\n\n\n\n\n\n\n\n\n\nSabemos que, independientemente de la localización de los valores, aproximadamente el 95% de los valores posibles de \\(\\bar{x}\\) en la distribución muestral estarán a menos de dos desviaciones estándar de la media \\(\\mu\\). Es decir, el intervalo \\(\\mu \\pm 2\\sigma\\) contendrá el 95% de los valores posibles de \\(\\bar{x}\\).\nSupongamos que formamos intervalos a partir de todos los posibles valores de \\(\\bar{x}\\), calculados a partir de todas las muestras posibles de tamaño \\(n\\) tomadas de la población de interés. Esto generará una gran cantidad de intervalos de la forma \\(\\mu \\pm  2\\sigma\\), todos con la misma amplitud, centrados en torno a una \\(\\mu\\) desconocida.\nAproximadamente el 95% de estos intervalos tendrán sus centros dentro del intervalo \\(\\mu \\pm  2\\sigma\\). Cada uno de estos intervalos, que se encuentran dentro de \\(\\mu \\pm  2\\sigma\\), puede contener el valor verdadero de \\(\\mu\\).\n\n\n\n\n\n\n\n\n\nFinalmente, y basándonos en las propiedades de la distribución Normal, se puede deducir la expresión del IC:\n\\[\nP(Z_{\\alpha/2} &lt; Z_{1-\\alpha/2)} = 1 - \\alpha\n\\] Reemplazando \\(Z\\):\n\\[\nP(Z_{\\alpha/2} &lt; \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} &lt; Z_{(1-\\alpha/2)}) = 1-\\alpha   \n\\]\nReordenando, la expresión del IC para la media queda:\n\\[\n\\bar{x} - Z_{\\alpha/2}\\sqrt{\\frac{\\sigma^2}{n}} &lt; \\mu &lt; \\bar{x} + Z_{\\alpha/2}\\frac{\\sigma^2}{n}   \n\\]\n\n¿Cómo se interpreta un IC?\nSi hubiésemos tomado múltiples muestras del mismo tamaño de la población, en al menos \\(100 * (1 − \\alpha)\\%\\) de las ocasiones el intervalo calculado contendría el parámetro poblacional real. Es decir, un IC al 95% implica que, a largo plazo, el 95% de los intervalos obtenidos a partir de muestras repetidas incluirán el valor verdadero del parámetro.\nEl producto del coeficiente de confiabilidad y el error estándar se denomina precisión de la estimación y es el componente responsable de la amplitud del IC. Recordemos que la fórmula general para construir un intervalo de confianza era:\n\\[ IC = estimador~puntual \\pm (coeficiente~de~confiabilidad) * (error~ estandar) \\]\nPara el caso de la media:\n\nAumento de la confiabilidad: Si se incrementa el nivel de confianza, el coeficiente (por ejemplo, pasando de 1.96 a un valor mayor) aumenta, lo que a su vez incrementa la amplitud del IC.\nReducción del error estándar: Si se fija la confiabilidad (por ejemplo, al 95%), para disminuir la amplitud del IC es necesario reducir el error estándar. Dado que el error estándar de la media es:\n\\[ SE = \\frac{\\sigma}{\\sqrt{n}} \\]\ny considerando que \\(\\sigma\\) es constante, la única forma de disminuir el error estándar es aumentando el tamaño muestral (\\(n\\)).\n\nSurge entonces la pregunta: ¿qué tan grande debe ser \\(n\\)?\nLa respuesta dependerá de \\(\\sigma\\), del nivel de significación (\\(\\alpha\\)) y de la amplitud deseada para el IC. La relación es:\n\\[ Amplitud = Z \\frac{\\sigma}{\\sqrt{n}} \\Longrightarrow n = \\frac{Z^2\\sigma^2}{Amplitud^2} \\quad (Z = 1.96~si~\\alpha = 0.05) \\]\n(En la práctica, \\(\\sigma\\) generalmente no se conoce, así que se usa su estimación muestral).\nLa expresión del error estándar varía según el parámetro a estimar. Hemos visto el caso de la media; si lo que se desea es calcular un IC para una proporción, recordemos que, para muestras grandes, la distribución de las proporciones de la muestra es aproximadamente normal de acuerdo con el TCL. En este caso:\n\nLa media de la distribución es la proporción real \\(p\\)\nLa varianza es \\(p(1-p)/n\\), lo que nos lleva a que el error estándar es:\n\n\\[\nSE = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}      \n\\]\ny el IC para la proporción se expresa como:\n\\[ \\hat{p} - Z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} &lt; p &lt; \\hat{p} + Z_{1-\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}  \\]\nDado que un intervalo de confianza implica una declaración probabilística, su cálculo se fundamenta en las distribuciones muestrales de los estimadores y en el correspondiente error estándar. Aunque las fórmulas pueden parecer complejas, los paquetes estadísticos (como R) realizan estos cálculos automáticamente. Lo fundamental es comprender en qué depende la amplitud del IC (nivel de confianza, error estándar y tamaño muestral) y cómo cada uno de estos componentes influye en la precisión de la estimación.\nPara profundizar y visualizar simulaciones sobre estos conceptos, pueden explorar recursos interactivos como:\n➡️ Viendo la teoría: Una introducción visual a probabilidad y estadística",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad6.html#normalidad-y-homocedasticidad",
    "href": "unidad6.html#normalidad-y-homocedasticidad",
    "title": "Unidad 6: Inferencia estadística",
    "section": "Normalidad y homocedasticidad",
    "text": "Normalidad y homocedasticidad\nLas características fundamentales a la hora de decidir si utilizaremos métodos paramétricos o no paramétricos para la inferencia estadística, es que los datos se ajusten a una distribución normal y conocer si tienen una dispersión homogénea o heterogénea.",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad6.html#normalidad",
    "href": "unidad6.html#normalidad",
    "title": "Unidad 6: Inferencia estadística",
    "section": "Normalidad",
    "text": "Normalidad\nDeterminar que una distribución es aproximadamente normal nos permite decidirnos por test de comparaciones paramétricos.\nExisten tres enfoques que debemos analizar simultáneamente:\n\nMétodos gráficos\nMétodos analíticos\nPruebas de bondad de ajuste\n\n\nMétodos gráficos\nEl gráfico por excelencia para evaluar normalidad es el Q-Q Plot que consiste en comparar los cuantiles de la distribución observada con los cuantiles teóricos de una distribución normal con la misma media y desviación estándar que los datos.\nCuanto más se aproximen los datos a una normal, más alineados están los puntos entorno a la recta.\nEn el lenguaje R hay varios paquetes que tienen funciones para construirlos:\n\nlibrary(dlookr)\nlibrary(ggpubr)\nlibrary(moments)\nlibrary(nortest)\nlibrary(car)\nlibrary(tidyverse)\n\nCargamos datos de ejemplo:\n\ndatos &lt;- read_csv2(\"datos/datos_normalidad.csv\")\n\nEvaluación gráfica de normalidad usando la función plot_normality() del paquete dlookr:\n\ndatos |&gt; \n  plot_normality(peso) \n\n\n\n\n\n\n\n\nA simple vista observamos que los puntos de la variable peso se ajustan bastante bien a la recta.\nTambién podemos generar el qqplot usando las funciones geom_qq_line() y geom_qq() de ggplot2:\n\ndatos |&gt; \n  ggplot(mapping = aes(sample = peso)) +\n  geom_qq_line() +\n  geom_qq() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nLa función ggqqplot() del paquete ggpubr [@ggpubr] nos permite agregar intervalos de confianza (zona gris alrededor de la recta) que nos orienta mejor sobre “donde caen” los puntos de la variable analizada:\n\ndatos$peso |&gt; \n  ggqqplot()\n\n\n\n\n\n\n\n\nUn ejemplo donde la variable parece no cumplir con el supuesto de normalidad en estos datos de prueba es edad:\n\ndatos$edad |&gt; \n  ggqqplot()\n\n\n\n\n\n\n\n\n\n\nMétodos analíticos\n\nMedidas de forma\nExisten dos medidas de forma útiles que podemos calcular mediante funciones de R.\n\nLa curtosis (kurtosis)\nLa asimetría (skewness)\n\nLa curtosis mide el grado de agudeza o achatamiento de una distribución con relación a la distribución normal.\n\n&lt; 0 Distribución platicúrtica (apuntamiento negativo): baja concentración de valores\n&gt; 0 Distribución leptocúrtica (apuntamiento positivo): gran concentración de valores\n= 0 Distribución mesocúrtica (apuntamiento normal): concentración como en la distribución normal.\n\nEl paquete moments [@moments] posee algunas funciones interesantes para analizar medidas de forma, como el estimador de Pearson para curtosis:\n\ndatos |&gt; \n  summarise(kurtosis_edad = kurtosis(edad, na.rm = T),\n            kurtosis_peso = kurtosis(peso, na.rm = T))\n\n# A tibble: 1 × 2\n  kurtosis_edad kurtosis_peso\n          &lt;dbl&gt;         &lt;dbl&gt;\n1          8.05          2.72\n\n\nEn los dos casos estamos frente a una distribución leptocúrtica pero de magnitudes bien diferentes. Muy alta en el caso de la variable edad (8,0) y mucho menor para la variable peso (2,7).\nEl índice de asimetría es un indicador que permite establecer el grado de asimetría que presenta una distribución. Los valores menores que 0 indican distribución asimétrica negativa; los mayores a 0: distribución asimetrica positiva y cuando sea 0, o muy próximo a 0, distribución simétrica:\n\ndatos |&gt;  \n  summarise(asimetria_edad = skewness(edad, na.rm = T),\n            asimetria_peso = skewness(peso, na.rm = T))\n\n# A tibble: 1 × 2\n  asimetria_edad asimetria_peso\n           &lt;dbl&gt;          &lt;dbl&gt;\n1           2.19          0.122\n\n\nLos valores obtenidos con la función skewness() del paquete moments nos informan que la distribución de la edad tienen una asimetría positiva (2,2) y que los valores de peso se distribuyen bastante simétricos (0,1).\nEstas características de las distribuciones también se pueden ver mediante histogramas o gráficos de densidad:\n\ndatos  |&gt;  \n  plot_normality(edad, col = \"forestgreen\") \n\n\n\n\n\n\n\ndatos |&gt; \n  plot_normality(peso, col = \"royalblue\") \n\n\n\n\n\n\n\n\nLos histogramas que se acerquen a la clásica “campana de Gauss” tendrán curtosis y asimetrías alrededor del valor cero.\n\n\n\nPruebas de bondad de ajuste\nUna prueba de bondad de ajuste permite testear la hipótesis de que una variable aleatoria sigue cierta distribución de probabilidad y se utiliza en situaciones donde se requiere comparar una distribución observada con una teórica o hipotética.\nEl mecanismo es idéntico a cualquier test de hipótesis salvo que aquí esperamos no descartar la hipótesis nula de igualdad, por lo que obtener valores p de probabilidad mayores a 0,05 es signo de que la distribución de la variable analizada se ajusta.\nA continuación, presentaremos los test de hipótesis más utilizados para analizar normalidad.\n\nTest de Shapiro-Wilk\nLleva el nombre de sus autores (Samuel Shapiro y Martin Wilk) y es usado preferentemente para muestras de hasta 50 observaciones.\nLa función se encuentra desarrollada en el paquete stats y se llama shapiro.test():\n\nshapiro.test(datos$edad)\n\n\n    Shapiro-Wilk normality test\n\ndata:  datos$edad\nW = 0.69517, p-value = 4.912e-13\n\nshapiro.test(datos$peso)\n\n\n    Shapiro-Wilk normality test\n\ndata:  datos$peso\nW = 0.98615, p-value = 0.383\n\n\nInterpretación: Siendo la hipótesis nula que la población está distribuida normalmente, si el p-valor es menor a \\(\\alpha\\) (nivel de significancia, convencionalmente un 0,05) entonces la hipótesis nula es rechazada (se concluye que los datos no provienen de una distribución normal). Si el p-valor es mayor a \\(\\alpha\\), se concluye que no se puede rechazar dicha hipótesis.\nEn función de esta interpretación (que es común a todos los test de hipótesis de normalidad), podemos decir que la distribución de la variable edad no se ajusta a la normal y no podemos rechazar que la distribución de la variable peso se ajuste.\n\n\nTest de Kolmogorov-Smirnov\nEl test de Kolmogorov-Smirnov permite estudiar si una muestra procede de una población con una determinada distribución que no está limitado únicamente a la distribución normal.\nEl test asume que se conoce la media y varianza poblacional, lo que en la mayoría de los casos no es posible. Para resolver este problema, se realizó una modificación conocida como test Lilliefors.\n\n\nTest de Lilliefors\nEl test de Lilliefors asume que la media y varianza son desconocidas y está especialmente desarrollado para contrastar la normalidad.\nEs la alternativa al test de Shapiro-Wilk cuando el número de observaciones es mayor de 50.\nLa función lillie.test() del paquete nortest [@nortest] permite aplicarlo:\n\nlillie.test(datos$edad)\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  datos$edad\nD = 0.24892, p-value &lt; 2.2e-16\n\nlillie.test(datos$peso)\n\n\n    Lilliefors (Kolmogorov-Smirnov) normality test\n\ndata:  datos$peso\nD = 0.049534, p-value = 0.7905\n\n\nLos resultados son coincidentes con los obtenidos anteriormente.\n\n\nTest de D’agostino\nEsta prueba se basa en las transformaciones de la curtosis y la asimetría de la muestra, y solo tiene poder frente a las alternativas de que la distribución sea sesgada.\nEl paquete moments la tiene implementada en agostino.test():\n\nagostino.test(datos$edad)\n\n\n    D'Agostino skewness test\n\ndata:  datos$edad\nskew = 2.1947, z = 6.3465, p-value = 2.203e-10\nalternative hypothesis: data have a skewness\n\nagostino.test(datos$peso)\n\n\n    D'Agostino skewness test\n\ndata:  datos$peso\nskew = 0.12160, z = 0.52683, p-value = 0.5983\nalternative hypothesis: data have a skewness\n\n\nLos resultados coinciden con la observación de asimetría que efectuamos con los métodos analíticos, confirmando que la variable edad no se ajusta a una curva simétrica y la variable peso si lo hace.\nCuando estos test se emplean con la finalidad de verificar las condiciones de métodos paramétricos es importante tener en cuenta que, al tratarse de valores probabilidad, cuanto mayor sea el tamaño de la muestra más poder estadístico tienen y más fácil es encontrar evidencias en contra de la hipótesis nula de normalidad.\nPor otra parte, cuanto mayor sea el tamaño de la muestra, menos sensibles son los métodos paramétricos a la falta de normalidad. Por esta razón, es importante no basar las conclusiones únicamente en los resultados de los test, sino también considerar los otros métodos (gráfico y analítico) y no olvidar el tamaño de la muestra.",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad6.html#homocedasticidad",
    "href": "unidad6.html#homocedasticidad",
    "title": "Unidad 6: Inferencia estadística",
    "section": "Homocedasticidad",
    "text": "Homocedasticidad\nLa homogeneidad de varianzas es un supuesto que considera constante la varianza en los distintos grupos que queremos comparar.\nEsta homogeneidad es condición necesaria antes de aplicar algunos test de hipótesis de comparaciones o bien para aplicar correcciones mediante los argumentos de las funciones de R.\nExisten diferentes test de bondad de ajuste que permiten evaluar la distribución de la varianza. Todos ellos consideran como \\(H_0\\) que la varianza es igual entre los grupos y como \\(H_1\\) que no lo es.\nLa diferencia entre ellos es el estadístico de centralidad que utilizan:\n\nMedia de la varianza: son los más potentes pero se aplican en distribuciones que se aproximan a la normal.\nMediana de la varianza: son menos potentes pero consiguen mejores resultados en distribuciones asimétricas.\n\n\nF-test\nEste test es un contraste de la razón de varianzas, mediante el estadístico F que sigue una distribución F-Snedecor.\nSe utiliza cuando las distribuciones se aproximan a la “normal” y en R base se la encuentra en la función var.test() que permite utilizar la sintaxis de fórmula:\n\nvariable_cuantitativa ~ variable_categórica_grupos\n\nPor ejemplo:\n\nvar.test(formula = peso ~ sexo, data = datos)\n\n\n    F test to compare two variances\n\ndata:  peso by sexo\nF = 0.67914, num df = 50, denom df = 48, p-value = 0.1781\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.384712 1.194943\nsample estimates:\nratio of variances \n         0.6791414 \n\n\nComparamos las varianzas de la variable peso entre el grupo de mujeres y hombres. El valor \\(p\\) del test indica que no podemos descartar la igualdad de varianzas entre los grupos (\\(H_0\\)) o lo que es lo mismo el test no encuentra diferencias significativas entre las varianzas de los dos grupos.\n\n\nTest de Bartlett\nEste test se puede utilizar como alternativa al F-test, sobre todo porque nos permite aplicarlo cuando tenemos más de 2 grupos de comparación. Al igual que el anterior es sensible a las desviaciones de la normalidad.\nLa función en R base es bartlett.test() y también se pueden usar argumentos tipo fórmula:\n\nbartlett.test(formula = peso ~ sexo, data = datos)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  peso by sexo\nBartlett's K-squared = 1.8082, df = 1, p-value = 0.1787\n\n\nEl resultado es coincidente con el mostrado por var.test(). No se encuentran diferencias significativas entres las varianzas de los pesos en los dos grupos (Mujer - Varon)\n\n\nTest de Levene\nEl test de Levene sirve para comparar la varianza de 2 o más grupos pero además permite elegir distintos estadísticos de tendencia central. Por lo tanto, la podemos adaptar a distribuciones alejadas de la normalidad seleccionando por ejemplo la mediana.\nLa función leveneTest() se encuentra disponible en el paquete car. La vemos aplicada sobre peso para los diferentes grupos de sexo y utilizando la media como estadístico de centralidad, dado que la distribución de peso se aproxima a la normal.\n\nleveneTest(y = peso ~ sexo, data = datos, center = \"mean\")\n\nLevene's Test for Homogeneity of Variance (center = \"mean\")\n      Df F value Pr(&gt;F)\ngroup  1       2 0.1605\n      98               \n\n\nLa conclusión es la misma que la encontrada anteriormente.\nAhora vamos aplicarla sobre la variable edad, de la que habíamos descartado “normalidad”. Lo hacemos usando el argumento center con \"mean\" (media) y con \"median\" (mediana).\n\nleveneTest(y = edad ~ sexo, data = datos, center = \"mean\")\n\nLevene's Test for Homogeneity of Variance (center = \"mean\")\n      Df F value Pr(&gt;F)  \ngroup  1  4.6784  0.033 *\n      97                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nleveneTest(y = edad ~ sexo, data = datos, center = \"median\")\n\nLevene's Test for Homogeneity of Variance (center = \"median\")\n      Df F value Pr(&gt;F)\ngroup  1  2.4413 0.1214\n      97               \n\n\nLos resultados son diferentes. Mientras con el centrado en la media nos da un p valor significativo menor a 0,05 con el centrado en la mediana no nos permite descartar homocedasticidad.\nObservamos aquí las distorsiones sobre la media y las formas paramétricas que devienen de distribuciones asimétricas y alejadas de la curva normal. El código correcto para este caso (variable edad) es usar el centrado en la mediana (center = \"median\").",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad6.html#test-de-hipótesis",
    "href": "unidad6.html#test-de-hipótesis",
    "title": "Unidad 6: Inferencia estadística",
    "section": "Test de hipótesis",
    "text": "Test de hipótesis\nAunque los estudios de corte transversal no se diseñan originalmente con grupos de comparación, en aquellos de carácter más analítico es frecuente establecer comparaciones. Por ejemplo, pueden surgir preguntas como:\n\n¿La prevalencia de la enfermedad es mayor en mujeres, en determinados grupos etarios o en una provincia específica?\n\nCon esto en mente, revisaremos las herramientas que permiten comparar grupos mediante test o contrastes de hipótesis. El propósito de estos test es ofrecer al investigador una herramienta para tomar decisiones sobre la población a partir de la información obtenida en una muestra.\nAntes de adentrarnos en la parte estadística, es importante distinguir entre dos tipos de hipótesis:\n\nHipótesis de investigación: Es la conjetura o suposición que motiva la investigación.\nHipótesis estadística: Es aquella que puede ser evaluada mediante técnicas estadísticas apropiadas.\n\nEn este texto nos centraremos en aclarar aspectos relativos a las hipótesis estadísticas, asumiendo que las hipótesis de investigación ya han sido discutidas previamente por los investigadores. Describiremos brevemente el razonamiento subyacente a estos test.\nLos contrastes de hipótesis parten de una hipótesis nula, la cual afirma que los dos grupos comparados son iguales o, en otras palabras, que las diferencias observadas se deben únicamente al azar. Como ya se ha mencionado, la variabilidad intrínseca de cualquier muestra impide que la diferencia entre grupos sea exactamente cero.\nEl método estadístico nos permite cuantificar la diferencia entre grupos asumiendo que, si repitiésemos el experimento infinitas veces obtenemos todas las posibles muestras del tamaño indicado a partir de nuestras poblaciones (distribución muestral), las diferencias entre grupos “iguales” se distribuirían conforme a una curva teórica. Basándonos en las propiedades de esta distribución, podemos determinar un valor límite que comprende, por ejemplo, el 95% o el 99% de las diferencias esperadas. Si la diferencia observada entre las muestras supera este valor límite, se considera excesiva para ser atribuible al azar y, por tanto, se rechaza la hipótesis nula. Por el contrario, si la diferencia cae dentro del área del 95%, se concluye que la diferencia encontrada podría atribuirse al azar, y no habría evidencia que nos permita rechazar la hipótesis nula. En estos casos decimos que los grupos “no son diferentes” pero no “son iguales”, ya que la variabilidad inherente impide probar una igualdad exacta.\nLos contrastes de hipótesis se realizan generalmente bajo las siguientes condiciones:\n\nSe asume a priori que la ley de distribución de la población es conocida.\nSe extrae una muestra aleatoria de dicha población.\n\nEl conjunto de estas técnicas de inferencia se denomina técnicas paramétricas. Sin embargo, existen otros métodos, denominados técnicas no paramétricas o contrastes de distribuciones libres, que no requieren estimar parámetros ni suponer una ley de probabilidad específica para la población. Algunos de estos métodos serán desarrollados más adelante en este módulo.\nEs importante señalar que los contrastes de hipótesis se utilizan no solo en estudios transversales, sino con mayor frecuencia en diseños en los que a priori existen grupos de comparación, como en estudios de casos y controles, cohortes, ensayos clínicos, entre otros. Desarrollaremos aquí la teoría que los sustenta y los utilizaremos a lo largo de todo el curso.\n\nEstructura del test de hipótesis\nLos componentes básicos de cualquier test de contraste de hipótesis son:\n\nHipótesis nula (\\(H_0\\)): Afirma que no existe diferencia entre los grupos que se comparan, es decir, que las variaciones observadas se deben únicamente al azar.\nHipótesis alternativa (\\(H_1\\)): Es la conjetura o suposición que plantea el investigador, estableciendo que sí existe una diferencia entre los grupos. Generalmente es complementaria de la \\(H_0\\).\nEstadístico de prueba: Es el valor calculado a partir de los datos muestrales que se utiliza para tomar la decisión sobre la \\(H_0\\). Cada tipo de problema tiene un estadístico adecuado, cuya magnitud, al compararse con su distribución muestral (por ejemplo, la distribución normal estándar en el caso del estadístico \\(Z\\)), permite determinar si las diferencias observadas son atribuibles al azar.\nValor crítico o Región crítica: La región crítica se establece en función del nivel de significación (\\(\\alpha\\)) y consiste en el conjunto de valores extremos del estadístico de prueba que, de ser alcanzados, llevarían a rechazar la \\(H_0\\). Todos los posibles valores del estadístico se ubican en el eje horizontal de la gráfica de su distribución, y la región crítica delimita aquellos valores que son muy poco probables bajo la hipótesis nula.\n\n\n\n\n\n\n\n\n\nLa regla de decisión es la siguiente:\n\nSi el valor del estadístico de prueba calculado a partir de la muestra cae en la región crítica, se rechaza la \\(H_0\\)​ y se concluye que las diferencias observadas son estadísticamente significativas.\nSi el valor no cae en la región crítica, no se rechaza la \\(H_0\\)​; esto indica que las diferencias entre lo observado y lo esperado pueden explicarse por el azar. Es decir, no son estadísticamente significativas.\n\nNivel de significación (\\(\\alpha\\)): Es la probabilidad de cometer un error tipo I, es decir, rechazar \\(H_0\\) cuando es verdadera. Este valor, elegido por el investigador (comúnmente 5% o 1%), determina el límite entre la región de no rechazo y la región crítica.\nValor p: Es una medida de qué tan probable son los resultados de la muestra, considerando que \\(H_0\\) sea verdadera.\n\nUn valor \\(p\\) muy pequeño indica que es muy poco probable obtener los resultados observados para el estadístico muestral si \\(H_0\\) fuese cierta, por lo que debemos rechazarla.\nEsto significa que si el valor \\(p \\leq \\alpha\\), es posible rechazar \\(H_0\\); mientras que si \\(p &gt; \\alpha\\), no es posible rechazar la hipótesis nula.\n\nPor ejemplo, si en un test de contraste de dos proporciones se obtiene un estadístico \\(Z= 3,034\\) y un valor \\(p = 0.0024\\), esto significa que la probabilidad de obtener un valor de \\(Z\\) de 3.034 o mayor, suponiendo que \\(H_0\\) es cierta, es del 0.24%. Dado que este valor es mucho menor que un nivel de significación del 5% (o incluso del 1%), se rechaza \\(H_0\\) y se concluye que la diferencia observada es estadísticamente significativa. En otras palabras, si bajo un supuesto dado, la probabilidad de un suceso observado particular es excepcionalmente pequeña, concluimos que el supuesto probablemente es incorrecto (regla del suceso infrecuente).\n\n\n\nTipos de contrastes\nLos contrastes de hipótesis se clasifican según la forma de la hipótesis alternativa (\\(H_1\\)). Esta clasificación determina si la prueba es unilateral de cola izquierda o derecha) o bilateral (de dos colas). Siendo las colas de la distribución las regiones extremas limitadas por los valores críticos.\n\nTest de cola izquierda\nLa hipótesis alternativa plantea que la media del primer grupo es significativamente menor que la del segundo:\n\\[\nH_1: \\mu_1 &lt; \\mu_2\n\\]\nLa región crítica se encuentra en el extremo izquierdo de la distribución. Todo el área crítica tiene un tamaño \\(\\alpha\\) con un valor crítico de \\(-1,645\\).\n\n\n\n\n\n\n\n\n\n\n\nTest de cola derecha\nLa hipótesis alternativa establece que la media del primer grupo es significativamente mayor que la del segundo:\n\\[ H_1: \\mu_1 &gt; \\mu_2 \\]\nLa región crítica se concentra en el extremo derecho de la distribución y toda el área crítica tiene un tamaño \\(\\alpha\\) con un valor crítico de \\(1,645\\).\n\n\n\n\n\n\n\n\n\n\n\nPruebas bilaterales\nLa hipótesis alternativa afirma que existen diferencias entre los grupos, sin especificar la dirección:\n\\[\nH_1: \\mu_1 \\neq \\mu_2\n\\]\nLa región crítica se divide entre ambos extremos de la distribución, con valores críticos de \\(\\pm 1,96\\). El nivel de significación total (\\(\\alpha\\)) se reparte en partes iguales entre las dos colas (\\(\\alpha/2\\) en cada una), lo que implica un 2,5% de probabilidad en cada cola si \\(H_0\\) es verdadera.\n\n\n\n\n\n\n\n\n\n\n\n\nErrores\nAl utilizar el razonamiento de los contrastes de hipótesis, existen dos tipos principales de errores que podemos cometer:\n\nError tipo I (\\(\\alpha\\)): Ocurre cuando el investigador rechaza la hipótesis nula (\\(H_0\\)) siendo esta verdadera en la población y se concluye erróneamente que existe una diferencia cuando en realidad no la hay. Se suele eligir un valor pequeño de \\(\\alpha\\) (0.01, 0.05 y 0.10) para hacer que la probabilidad de rechazo de \\(H_0\\) sea pequeña.\nError tipo II (\\(\\beta\\)): Ocurre cuando el investigador no rechaza la \\(H_0\\) siendo esta falsa en la población, es decir, se falla en detectar una diferencia real. Generalmente \\(\\beta\\) es mayor que \\(\\alpha\\), pero su valor real se desconoce en la práctica.\n\nEs importante notar que, una vez que se realiza el procedimiento de prueba, no es posible saber con certeza si se ha cometido alguno de estos errores, ya que se desconoce el verdadero estado de la realidad. Sin embargo, al fijar un \\(\\alpha\\) pequeño, se busca asegurar que, en caso de rechazar la \\(H_0\\), la probabilidad de haber cometido un error Tipo I sea baja.\nEn resumen, al interpretar los resultados de un test de hipótesis:\n\nSi se rechaza la \\(H_0\\): se asume que la probabilidad de haber cometido un error Tipo I es baja (debido al valor pequeño de \\(\\alpha\\)).\nSi no se rechaza la \\(H_0\\): se desconoce el riesgo real de un error Tipo II, pero es importante tener en cuenta que, en muchas situaciones, este riesgo es mayor que el de un error Tipo I.\n\nLa tabla que se presenta a continuación resume las posibles situaciones a las que nos enfrentamos con los test de hipótesis:\n\n\n\n\n\n\nNo rechazar H0\nRechazar H0\n\n\n\n\nH0 es cierta\nCorrecto (1-α)\nError tipo I (α)\n\n\nH0 es falsa\nError tipo II (β)\nCorrecto (1-β)\n\n\n\n\n\nPara quienes están familiarizados con el ámbito del diagnóstico, existe una clara analogía entre los falsos positivos y falsos negativos en las pruebas diagnósticas y, respectivamente, el error Tipo I y el error Tipo II en los contrastes de hipótesis.\nHemos discutido el significado de \\(\\alpha\\) (error Tipo I); ahora veamos qué implica \\(\\beta\\). Recordemos que el error Tipo II es análogo a los falsos negativos de las pruebas diagnósticas: es la probabilidad de no detectar una diferencia cuando, en realidad, ésta existe. En otras palabras, \\(\\beta\\) es la probabilidad de no rechazar la hipótesis nula (\\(H_0\\)​) siendo esta falsa.\nA diferencia de \\(\\alpha\\) que se fija en un único valor y es determinado por el investigador, \\(\\beta\\) varía según el valor real del parámetro en estudio. Por ejemplo, si consideramos la hipótesis nula \\(H_0: \\mu_1 - \\mu_2 = 0\\), habrá un valor de \\(\\beta\\) para cada posible diferencia entre \\(\\mu_1\\)​ y \\(\\mu_2\\) cuando el valor real no sea cero. La probabilidad de detectar correctamente una diferencia real - es decir, de obtener un resultado estadísticamente significativo cuando la diferencia existe- se denomina potencia estadística y se expresa como \\(1-\\beta\\).\nLos contrastes de hipótesis no son exclusivos de los estudios transversales; por el contrario, su uso es más común en estudios analíticos que involucran grupos de comparación, tales como estudios de casos y controles, cohortes o ensayos clínicos. Por ejemplo, en un ensayo clínico que evalúa dos tratamientos, la potencia estadística refleja la capacidad del estudio para identificar un efecto real del tratamiento.\nEs deseable que la potencia del estudio sea lo mayor posible, ya que esto incrementa la probabilidad de detectar diferencias verdaderas. Sin embargo, no es posible minimizar ambos errores simultáneamente ya que al disminuir \\(\\alpha\\) (es decir, al ser más exigentes para rechazar la \\(H_0\\)​), \\(\\beta\\) tiende a aumentar, y viceversa. En los contrastes, la hipótesis privilegiada es \\(H_0\\) que solo será rechazada cuando la evidencia de su falsedad supere el umbral del \\(1-\\alpha\\). Esto significa que, a menos que la evidencia en contra de \\(H_0\\) sea muy significativa, se opta por no rechazarla. Lo ideal a la hora de definir un test es encontrar un compromiso entre \\(\\beta\\) y \\(\\alpha\\).\n\n\n\n\n\n\n\n\n\nMientras que para tests bilaterales:\n\n\n\n\n\n\n\n\n\nFinalmente, podemos decir que la potencia estadística ofrece un segundo mecanismo de seguridad en un contraste de hipótesis. Es como contar con una protección adicional en la toma de decisiones: si solo dispusiéramos del nivel de significación (\\(\\alpha\\)), tendríamos menos garantías. Al incorporar la potencia (\\(1-\\beta\\)) agregamos un segundo control. Por ello, en un contraste no basta con tener un valor p pequeño; también se necesita una potencia alta, que en la práctica suele fijarse en un 80% (es decir, \\(1 - \\beta = 0.8\\)).\nPor otro lado, cuando existe una diferencia real —o un efecto real de una terapia, o una verdadera diferencia entre dos fármacos—, la magnitud de ese efecto influye en la facilidad para detectarlo. Los efectos grandes son más fáciles de identificar que los pequeños. Para estimar la potencia de una prueba, debemos especificar el efecto mínimo que valga la pena identificar.\nLa potencia de un test estadístico depende de tres factores que actúan de manera interrelacionada:\n\nEl riesgo de error que se tolerará al rechazar la hipótesis de ausencia de efecto o diferencia (\\(\\alpha\\)).\nLa dimensión de la diferencia que se desea identificar en relación con la variabilidad en las poblaciones.\nEl tamaño de la muestra.\n\nDel mismo modo que en un problema de estimación se necesita una idea de la magnitud a estimar y del error aceptable para definir el tamaño de la muestra, en un contraste de hipótesis se requiere conocer el tamaño del efecto que se quiere detectar. Así, el tamaño muestral se determina en función del nivel de confianza y de la potencia de la prueba, además de otros aspectos relacionados con el diseño y la prueba estadística elegida.\nEn epidemiología, una de las situaciones más frecuentes al diseñar un estudio es el cálculo del tamaño muestral para un nivel de confianza del 95% y una potencia del 80%, que, como se mencionó, es un nivel de potencia alto y que además permite manejar un \\(\\alpha\\) relativamente bajo. El lenguaje R cuenta con diversas funciones para calcular y visualizar la relación entre tamaño muestral, potencia, tamaño del efecto y nivel de confianza, facilitando el diseño de estudios con un adecuado balance entre la probabilidad de detectar diferencias reales y la de controlar errores estadísticos.\nPor ejemplo, la función pwr.t.test() del paquete pwr [@pwr], calcula la potencia para pruebas \\(t\\) de Student de medias (para una muestra, dos muestras y muestras pareadas), basado en el tamaño de la muestra, el nivel de confianza y el tamaño de efecto:\n\npwr.t.test(n, d, sig.level = 0.05, power, type, alternative)\n\nDonde:\n\nn: Número de observaciones para cada grupo.\nd: tamaño de efecto (\\(d\\) de Cohen) - diferencia (estandarizada) entre grupos.\n\nNota: La \\(d\\) de Cohen representa las desviaciones estándar que separan dos o más grupos. Por ejemplo: \\(d_{Cohen} = 0.5\\) representa que la diferencia entre grupo experimental y muestral es de media desviación estándar. Cohen sugirió (provisoriamente) que 0.2 es un tamaño de efecto pequeño, 0.5 es mediano y 0.8 es grande,\n\nsig.level: nivel de significación (probabilidad del error de tipo I).\npower: potencia del test (1 menos la probabilidad del error tipo II).\ntype: tipo de test (\"two.sample\", \"one.sample\", \"paired\").\nalternative: palabra que especifica la hipotesis alternativa, debe ser \"two.sided\" (predeterminado), \"greater\" or \"less\".\n\nLa función se ejecuta incorporando todos los argumentos obligatorios (d,n, power y sig.level) menos el que se quiere calcular. En ese caso se iguala a NULL o se omite.\nSupongamos que queremos conocer el tamaño de la muestra para detectar diferencias en la media de la hemoglobina glicosilada entre dos grupos de pacientes con tratamientos de control de la diabetes distintos. Aceptamos un nivel de efecto convencional de una pequeña desviación (\\(d_{Cohen} = 0.2\\)), una potencia del 80% y una significación habitual de 0,05.\nCargamos el paquete requerido:\n\nlibrary(pwr)\n\nCalculamos el tamaño de muestra:\n\npwr.t.test(d = 0.2, \n           power = 0.8,\n           sig.level = 0.05, \n           type = \"two.sample\", \n           alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 393.4057\n              d = 0.2\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nTambién podemos graficar la salida:\n\npwr.t.test(d = 0.2, \n           power = 0.8,\n           sig.level = 0.05, \n           type = \"two.sample\", \n           alternative = \"two.sided\") |&gt; \n  plot()\n\n\n\n\n\n\n\n\nObservamos que, si por ejemplo tomásemos una muestra de 300 individuos por grupo, la potencia del estudio con ese tamaño de efecto y nivel de significación del 0,05 sería aproximadamente de 68%.\n\n\n¿Qué test se debe aplicar en cada caso?\nHemos discutido la mecánica general de los test de hipótesis. Ahora, nos centraremos en orientarnos sobre qué test aplicar en cada situación. Aunque existe un desarrollo teórico detrás de cada caso, aquí nos quedaremos con ciertas reglas prácticas.\nPara sistematizar los contrastes de hipótesis, es útil responder dos preguntas fundamentales:\n\n¿Qué tipo de variable dependiente tengo?\nLa variable resultado puede ser cuantitativa, cualitativa, de tiempo hasta un evento, etc.\n¿Qué se está comparando?\nEsto se traduce en evaluar el tipo de experimento: ¿se comparan dos grupos o más? ¿Son muestras independientes o relacionadas (por ejemplo, medidas en el mismo grupo antes y después de una intervención)?\n\n\nVariable resultado cuantitativa\nCuando la variable de interés es cuantitativa, la comparación de grupos generalmente se traduce en comparar las medias de dichos grupos. En este contexto, se deben responder una tercera pregunta y es si dicha variable se distribuye normalmente, porque si no fuera así, debemos recurrir a los contrastes no paramétricos.\nPor ejemplo, para comparar dos grupos se plantearía:\n\n\\(H_0: \\mu_1 = \\mu_2\\) (o su equivalente \\(\\mu_1 - \\mu_2 = 0\\))\n\\(H_1: \\mu_1 \\neq \\mu_2\\) (contraste bilateral) o bien \\(\\mu_1 &lt; \\mu_2\\) o \\(\\mu_1 &gt; \\mu_2\\) (contrastes unilaterales).\n\nSe calcula el estadístico de prueba (por ejemplo, \\(t\\) de Student o \\(Z\\), según el tamaño de la muestra y si se conoce la varianza poblacional), se determina la región de rechazo y, finalmente, si \\(p &lt; \\alpha\\) rechazo \\(H_0\\) y si \\(p &gt;  \\alpha\\) no rechazo \\(H_0\\).\nA continuación presentamos un esquema que sirve de guía para potenciales situaciones:\n\n\n\n\n\n\n\nG\n\n\n\nn1\n\nVariable respuesta \n cuantitativa\n\n\n\nA\n\nComparación de grupos\n\n\n\nn1-&gt;A\n\n\n\n\n\nC\n\nComparación antes y después \n de un tratamiento\n\n\n\nn1-&gt;C\n\n\n\n\n\nB\n\nDistribución normal\n\n\n\nA-&gt;B\n\n\n\n\n\nb1\n\nt de Student\n\n\n\nB-&gt;b1\n\n\nSi (2 grupos)\n\n\n\nb2\n\nMann-Whitney\n\n\n\nB-&gt;b2\n\n\nNo (2 grupos)\n\n\n\nb3\n\nANOVA\n\n\n\nB-&gt;b3\n\n\nSi (3+ grupos)\n\n\n\nb4\n\nKruskal-Wallis\n\n\n\nB-&gt;b4\n\n\nNo (3+ grupos)\n\n\n\nD\n\nDistribución normal\n\n\n\nC-&gt;D\n\n\n\n\n\nd1\n\nt de Student \n (datos apareados)\n\n\n\nD-&gt;d1\n\n\nSi (mismo grupo)\n\n\n\nd2\n\nWilcoxon\n\n\n\nD-&gt;d2\n\n\nNo (mismo grupo)\n\n\n\nd3\n\nANOVA \n (medidas repetidas)\n\n\n\nD-&gt;d3\n\n\nSi (2+ grupos)\n\n\n\nd4\n\nFriedman\n\n\n\nD-&gt;d4\n\n\nNo (2+ grupos)\n\n\n\n\n\n\n\n\nHay algo más que los estadísticos nos “obligan” a considerar en el caso que compare medias independientes y se haya verificado la normalidad de la distribución, y se trata de considerar si las varianzas de las poblaciones que comparo son iguales o diferentes. El algoritmo de resolución es el siguiente:\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nComparo medias\n\n\n\nB\n\nMuestras independientes\n\n\n\nA-&gt;B\n\n\n\n\n\nC\n\nMuestras pareadas\n\n\n\nA-&gt;C\n\n\n\n\n\nb1\n\nVarianzas conocidas\n\n\n\nB-&gt;b1\n\n\n\n\n\nc1\n\nMismo tamaño de muestra\n\n\n\nC-&gt;c1\n\n\n\n\n\nb2\n\nPrueba Z (normal)\n\n\n\nb1-&gt;b2\n\n\nSí\n\n\n\nb3\n\nPrueba t\n\n\n\nb1-&gt;b3\n\n\nNo\n\n\n\nc2\n\nPrueba t\n\n\n\nc1-&gt;c2\n\n\n\n\n\n\n\n\n\n\nCuando trabajamos con muestras independientes, a menudo nos encontramos en el escenario de varianzas desconocidas. Esto nos obliga a realizar, de manera previa, un test de homogeneidad de varianzas para determinar si se puede asumir que son iguales o si, por el contrario, difieren. La razón es que, aunque se utiliza el estadístico \\(t\\) de Student para comparar las medias, su cálculo y la forma en que se distribuye varían en función de si las varianzas de los grupos son iguales o no.\n\n\nVariable resultado cualitativa\nCuando la variable dependiente es cualitativa (categórica), como por ejemplo Enfermo (Sí/No) o Expuesto (Sí/No), la comparación de grupos no se basa en medias, sino en proporciones. Para ello, se utilizan pruebas estadísticas específicas según el número de grupos y el diseño del estudio.\nA continuación, presentamos una guía análoga a la anterior:\n\n\n\n\n\n\n\nG\n\n\n\nn1\n\nVariable respuesta \n cualitativa\n\n\n\nA\n\nComparación de grupos\n\n\n\nn1-&gt;A\n\n\n\n\n\nC\n\nComparación antes y después \n de un tratamiento\n\n\n\nn1-&gt;C\n\n\n\n\n\nB\n\nn &gt; 30 y frecuencia \n por grupo &gt;= 5\n\n\n\nA-&gt;B\n\n\n\n\n\nb1\n\ntest de proporciones/ \n Chi-cuadrado\n\n\n\nB-&gt;b1\n\n\nSi (2+ grupos)\n\n\n\nb2\n\ntest exacto de Fisher\n\n\n\nB-&gt;b2\n\n\nNo (2+ grupos)\n\n\n\nD\n\nMismo grupo \n (dos categorías)\n\n\n\nC-&gt;D\n\n\n\n\n\nE\n\nVarios grupos \n (n &gt;= 4 y k &gt;= 24)\n\n\n\nC-&gt;E\n\n\n\n\n\nd1\n\nMc Nemar\n\n\n\nD-&gt;d1\n\n\n\n\n\ne1\n\nCochrane Q\n\n\n\nE-&gt;e1",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad6.html#anova",
    "href": "unidad6.html#anova",
    "title": "Unidad 6: Inferencia estadística",
    "section": "ANOVA",
    "text": "ANOVA\nEl análisis de varianza (ANOVA) es una extensión del modelo lineal general que se utiliza para comparar las medias de una variable dependiente continua (\\(Y\\)) entre diferentes niveles de una variable explicativa categórica (\\(X\\)), que debe tener al menos tres niveles.\nLa hipótesis nula (\\(H_0\\)) del test estadístico establece que las medias de la variable dependiente son iguales en todos los grupos, mientras que la hipótesis alternativa (\\(H_1\\)) plantea que al menos dos medias difieren significativamente:\n\n\\(H_0: \\mu_1 = \\mu_2 = ... = \\mu_i\\)\n\\(H_1\\): al menos una \\(\\mu_i \\not= \\mu_j\\)\n\nPor lo tanto, el ANOVA permite comparar múltiples medias, pero lo hace analizando la variabilidad entre y dentro de los grupos.\nLa variabilidad total se descompone en dos componentes:\n\nIntervarianza (SSB): Variabilidad entre los grupos.\nIntravarianza (SSE): Variabilidad dentro de los grupos.\n\nEl estadístico \\(F\\) del ANOVA, que sigue una distribución F de Fisher-Snedecor, compara estas dos fuentes de variabilidad:\n\\[\nF = \\frac{SSB/(k-1)}{SSE/(n-k)}\n\\]\ndonde:\n\n\\(k\\): el número de grupos.\n\\(n\\): número total de observaciones.\n\nSi se cumple \\(H_0\\), el estadístico \\(F\\) tiende a 1, ya que las varianzas entre y dentro de los grupos son similares. Si las medias difieren significativamente, la intervarianza será mayor que la intravarianza, resultando en valores de \\(F\\) superiores a 1.",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad6.html#anova-de-un-factor-o-de-una-vía",
    "href": "unidad6.html#anova-de-un-factor-o-de-una-vía",
    "title": "Unidad 6: Inferencia estadística",
    "section": "ANOVA de un factor o de una vía",
    "text": "ANOVA de un factor o de una vía\nEl ANOVA de una vía puede considerare como una extensión de los t-test independientes para comparar más de dos grupos de un factor. En este contexto, factor se refiere a la variable categórica que define los grupos.\nPara que los resultados del ANOVA sean válidos, deben cumplirse los siguientes supuestos:\n\nAleatoriedad: Las observaciones deben ser aleatorias.\nIndependencia: Las observaciones entre grupos deben ser independientes.\nVariable dependiente: Cuantitativa continua.\nVariable explicativa: Categórica con más de dos niveles.\nNormalidad: La distribución de la variable dependiente dentro de cada grupo debe ser normal.\nHomocedasticidad: Las varianzas de los grupos deben ser homogéneas.\n\n\nFunciones de R\nPodemos realizar un test ANOVA de 1 factor o 1 vía mediante la función aov() de R base. Utiliza sintaxis fórmula del tipo \\(var_cuanti∼factor\\) y su resultado es un objeto lista (modelo “aov-lm”).\nSiempre conviene que asignemos los resultados a objetos que luego nos servirán para aplicar otras funciones como summary() para obtener los resultados completos, incluido el p-valor.\nTambién podemos usar la función lm() del paquete stats que ajusta modelos lineales y luego la función anova() sobre el objeto para obtener la significancia del test F.\nSi los resultados del test F nos muestra un \\(p-valor\\) menor a 0,05 el análisis sugiriere que al menos dos grupos son diferentes entre sí.\n\n\nComparaciones múltiples\nUna vez que comprobamos que existen diferencias significativas entre grupos, nos interesa saber cuáles grupos son diferentes entre sí. Para ello, existen distintos algoritmos de comparaciones múltiples con sus respectivas correcciones, como el test de Diferencia Honestamente Significativa de Tukey, también llamado Tukey HSD o test de Tukey. Esta prueba se aplica para grupos equilibrados (mismo tamaño) y varianzas similares (homocedásticas). Es una prueba conservadora, dado que mantiene bajo el error de tipo I, sacrificando la capacidad de detectar diferencias existentes.\nSi las varianzas son homocedásticas pero los grupos difieren en tamaño, podemos usar el test de Tukey si tenemos que comparar entre varios grupos, o la corrección de Bonferroni para grupos más reducidos.\nEl paquete emmeans es una herramienta muy versátil y poderosa para realizar comparaciones múltiples. Comenzaremos utilizando la función emmeans() con el argumento specs = a la variable de grupo/factor para crear un objeto que contenga las medias marginales por grupo:\n\ncomp &lt;- emmeans(anova, specs = \"grupo\")\n\nPara realizar las comparaciones múltiples mediante test de Tukey usamos el comando contrast() con el argumento method = \"pairwise\":\n\ncontrast(comp, method = \"pairwise\")",
    "crumbs": [
      "Unidad 6: Inferencia estadística"
    ]
  },
  {
    "objectID": "unidad4.html",
    "href": "unidad4.html",
    "title": "Unidad 4: Tratamiento de datos específicos",
    "section": "",
    "text": "Artwork por @allison_horst\n\n\n\nLos eventos epidemiológicos se presentan en algun momento del tiempo, por lo que las variables de tiempo son habituales componentes de las bases de datos con las que trabaja un epidemiólogo. Estas variables pueden presentarse en distintas unidades de medida, tales como horas, días, años, decadas, etc.\nA veces trabajar con datos tipo fecha y hora puede ser frustrante.Las fechas vienen en muchos formatos diferentes, que hace que reconocerlos y analizarlos sea un desafío.\nPrimero necesitamos que los datos sean reconocidos como formato fecha (Date) y luego debemos lidiar con operaciones específicas como extraer componentes de los horarios, como años, meses o segundos, o cambiar zonas horarias o hacer cálculos entres fechas.\nPara simplificar esta tarea tidyverse trae el paquete lubridate que proporciona herramientas para manipular variables fecha-hora.\nEspecíficamente, lubridate ayuda a los usuarios a:\n\nIdentificar y analizar los datos de fecha y hora.\nExtrer y modificar componentes de una fecha y hora, como años, meses, días, horas, minutos y segundos.\nRealizar cálculos precisos con fecha y hora.\nManejar zonas horarias y horario de verano.\n\nlubridate se instala y activa con tidyverse:\n\n\nPodemos leer fechas en R usando la serie de funciones ymd() proporcionada por este paquete. Estas funciones analizan el contenido de cadenas de caracteres y las transforman a fechas.\nLas letras y, m y d corresponden al año, mes y día de una fecha. Para leer una fecha, seleccionamos el nombre de la función que coincide con el orden de los elementos contenidos en el objeto original. Por ejemplo, en la siguiente fecha el elemento mes viene primero, seguido por el día y luego el año, al estilo estadounidense. Entonces usaríamos la función mdy():\n\nmdy(\"01-24-2024\")\n\n[1] \"2024-01-24\"\n\n\nEl formato de salida siempre año-mes-día, es decir se organiza del elemento más grande que anida a los otros.\nSi en cambio tuviese la forma en que usamos las fechas nosotros, usaríamos dmy().\n\ndmy(\"24-01-2024\")\n\n[1] \"2024-01-24\"\n\n\nComo se observa el formato de los caracteres de entrada pueden utilizar distintos separadores, como guión medio (-), punto (.), barra inclinada (/), guión bajo (_) o incluso espacios.\nLa clase de los objetos convertidos es Date.\n\nx &lt;- dmy(\"24/01/2024\")\n\nclass(x)\n\n[1] \"Date\"\n\n\n\n\n\nOrden de los elementos\nFunción\n\n\n\n\naño, mes y día\nymd()\n\n\naño, día y mes\nydm()\n\n\nmes, día y año\nmdy()\n\n\ndía, mes y año\ndmy()\n\n\nhora y minuto\nhm()\n\n\nhora, minuto y segundo\nhms()\n\n\naño, mes, día, hora, minuto y segundo\nymd_hms()\n\n\n\nLas funciones que tienen componente de hora crean objetos POSIXct.\nCuando una función dmy() se aplica a un vector de fechas, lubridate supone que todas las fechas tienen el mismo orden y los mismos separadores.\n\n\n\nCada estructura fecha-hora es una combinación de diferentes elementos, cada uno con su propio valor. Por ejemplo, la mayoría de las fechas incluyen un valor de año, un valor de mes, un valor de día, etc. Juntos estos elementos especifican el momento exacto al que se refiere la fecha y la hora.\nPodemos extraer fácilmente cada elemento de una fecha-hora con la función de acceso que tiene su nombre, como se muestra en la siguiente tabla.\n\n\n\nComponente de fecha\nFunción\n\n\n\n\nAño\nyear()\n\n\nMes\nmonth()\n\n\nSemana\nweek()\n\n\nDía del año\nyday()\n\n\nDía del mes\nmday()\n\n\nDía de la semana\nwday()\n\n\nHora\nhour()\n\n\nMinuto\nminute()\n\n\nSegundo\nsecond()\n\n\nZona horaria (huso horario)\ntz()\n\n\n\nPor ejemplo, si almacenamos la fecha y hora actual del sistema en un objeto:\n\nfecha &lt;- now()\n\nfecha\n\n[1] \"2025-07-03 13:29:10 -03\"\n\n\npodemos extraer cada uno de sus elementos.\nTengamos en cuenta que la función now(), perteneciente al mismo paquete lubridate, devolverá una fecha diferente cada vez que se ejecute.\n\nyear(fecha)\n\n[1] 2025\n\n\n\nmday(fecha)\n\n[1] 3\n\n\n\nhour(fecha)\n\n[1] 13\n\nminute(fecha)\n\n[1] 29\n\n\nPara los elementos de mes y día de la semana (wday), también podemos especificar si queremos extraer el valor numérico del elemento, una abreviatura del nombre del mes o día de la semana, o el nombre completo.\nPor ejemplo:\n\nmonth(fecha)\n\n[1] 7\n\n\n\nmonth(fecha, label = TRUE)\n\n[1] jul\n12 Levels: ene &lt; feb &lt; mar &lt; abr &lt; may &lt; jun &lt; jul &lt; ago &lt; sep &lt; ... &lt; dic\n\n\n\nmonth(fecha, label = TRUE, abbr = FALSE)\n\n[1] julio\n12 Levels: enero &lt; febrero &lt; marzo &lt; abril &lt; mayo &lt; junio &lt; ... &lt; diciembre\n\n\n\nwday(fecha, label = TRUE, abbr = FALSE)\n\n[1] jueves\n7 Levels: domingo &lt; lunes &lt; martes &lt; miércoles &lt; jueves &lt; ... &lt; sábado\n\n\nOtra buena noticia es que el paquete se adapta al formato regional del sistema operativo donde se encuentra funcionando, por lo que los nombres de los meses o los días de la semana, en este caso, figuran en español (si nuestro sistema operativo está instalado bajo ese idioma).\nPor otra parte, también podemos usar cualquiera de las funciones de acceso para establecer el valor de un elemento. Por ejemplo,\n\nfecha\n\n[1] \"2025-07-03 13:29:10 -03\"\n\nday(fecha) &lt;- 5\n\nfecha\n\n[1] \"2025-07-05 13:29:10 -03\"\n\n\ncambia nuestra fecha al quinto día del mes. También podemos configurar los elementos para más valores complicados, por ejemplo:\n\nfechas &lt;- ymd_hms(\"2017-01-01 01:00:00\", \"2017-01-01 01:30:00\")\n\nminute(fechas) &lt;- mean(minute(fechas))\n\nfechas # promedió los minutos en los dos casos\n\n[1] \"2017-01-01 01:15:00 UTC\" \"2017-01-01 01:15:00 UTC\"\n\n\nSi asignamos a un elemento un valor mayor de lo admitido, la diferencia se extenderá en el siguiente elemento superior (respetando la cantidad de días del mes de mayo adecuadamente en este caso.)\n\nfecha\n\n[1] \"2025-07-05 13:29:10 -03\"\n\nday(fecha) &lt;- 35 \n\nfecha\n\n[1] \"2025-08-04 13:29:10 -03\"\n\n\nFinalmente, también podemos cambiar las fechas agregando o restando unidades de tiempo.\n\nfecha\n\n[1] \"2025-08-04 13:29:10 -03\"\n\nfecha &lt;- fecha + hours(3)\n\nfecha\n\n[1] \"2025-08-04 16:29:10 -03\"\n\n\nObservemos que hours() (plural) no es la misma función que hour() (singular).\nPor último, algo muy útil para nuestro trabajo es poder extraer la semana epidemiologica, con la función epiweek(), en la que cae una fecha en particular o un conjunto de ellas dentro de una variable.\n\nepiweek(fecha)\n\n[1] 32\n\n\nJunto con la semana epidemiológica se puede obtener el año epidemiológico con la función epiyear()\nPor ejemplo, la fecha 01/01/2022 es el primer día de enero de 2022 pero pertenece a la semana epidemiológica 52 de año 2021. Veamos:\n\nfecha &lt;- dmy(\"01-01-2022\")\n\nfecha\n\n[1] \"2022-01-01\"\n\nepiweek(fecha)\n\n[1] 52\n\n\nSi uno obtiene el año al que pertenece, nos dice que 2022 pero si lo queremos asociar con su semana epidemiológica, nos quedaría que estamos en la semana 52 del año 2022, cosa que no es cierta.\n\nyear(fecha)\n\n[1] 2022\n\n\nEn estas situaciones que no coinciden el año de la fecha con el año epidemiológico de la semana es que se aplica epiyear().\n\nepiyear(fecha)\n\n[1] 2021\n\n\n\n\n\nLos cálculos con fechas y horas son más complicados que la aritmética con números, pero puede hacerse con precisión y facilidad mediante este paquete.\n¿Qué es lo que complica a la aritmética con datos de tiempo (fechas u horas)?\nEl tiempo que medimos en el reloj se calibra periódicamente para ajustar las condiciones astronómicas, por caso los años bisiestos o los horarios de verano que se utilizan en muchos países.\nEn diferentes momentos, la duración de meses, semanas, días, horas e incluso minutos puede variar. Por lo tanto, podemos considerar que son unidades relativas de tiempo; su longitud es relativa a cuando ocurren; por el contrario, los segundos siempre tienen una longitud constante (son unidades de tiempo exactas)\nlubridate permite cálculos con unidades relativas y exactas introduciendo cuatro nuevos elementos relacionados: instantes, intervalos, duraciones y períodos. Estos conceptos son tomados del proyecto Joda Time (Colebourne y O’Neill 2010). Conceptos similares para instantes, períodos y duraciones también aparecen en la biblioteca C++ Boost - Date Time (Garland 2011).\nlubridate proporciona funciones auxiliares, clases de objetos y métodos para usar los cuatro conceptos en el lenguaje R.\n\n\nUn instante es un momento específico en el tiempo, como el 1 de enero de 2024. Creamos un instante cada vez que convertimos una fecha a formato Date de R.\n\nstart_2024 &lt;- ymd_hms(\"2024-01-01 12:00:00\")\n\nlubridate no crea una nueva clase de objetos instantes. En cambio, reconoce cualquier objeto de fecha y hora como un instante. Podemos probar si un objeto es un instante usando el identificador is.instant(). Por ejemplo:\n\nis.instant(start_2024)\n\n[1] TRUE\n\n\n\n\n\nLos intervalos, duraciones y períodos son todas formas de registrar tiempos. De estos, los intervalos son los más simples. Un intervalo es un lapso de tiempo que ocurre entre dos instantes específicos.\nPodemos crear objetos de intervalo restando dos instantes, mediante %–% o usando la función new_interval().\n\nstart_2023 &lt;- ymd_hms(\"2023-01-01 12:00:00\")\nstart_2024 &lt;- ymd_hms(\"2024-01-01 12:00:00\")\nintervalo &lt;- start_2023 %--% start_2024\nintervalo\n\n[1] 2023-01-01 12:00:00 UTC--2024-01-01 12:00:00 UTC\n\n\nPodemos acceder a las fechas de inicio y finalización de un objeto de intervalo con int_start() e int_end().\nLos intervalos siempre comienzan en la fecha y hora que ocurre primero y finaliza en la fecha y hora que ocurre último. Por lo tanto, los intervalos siempre tienen una longitud positiva.\n\nint_start(intervalo)\n\n[1] \"2023-01-01 12:00:00 UTC\"\n\n\n\nint_end(intervalo)\n\n[1] \"2024-01-01 12:00:00 UTC\"\n\n\nDesafortunadamente, dado que los intervalos están anclados a sus fechas de inicio y finalización, no son muy útiles para cálculos de fecha y hora.\n\n\n\nSi eliminamos las fechas de inicio y finalización de un intervalo, tendremos un intervalo de tiempo genérico que podemos agregar a cualquier fecha. Pero, en que unidad es conveniente medir este período de tiempo? Como vimos anteriormente, si lo almacenamos en segundos, tendrá una longitud exacta ya que los segundos siempre tienen la misma longitud.\nLlamamos duraciones de estos lapsos de tiempo. Alternativamente, podemos registrar el lapso de tiempo en unidades más grandes, como minutos o años.\nDado que la longitud de estas unidades varía con el tiempo, la longitud exacta de el lapso de tiempo dependerá de cuándo comience. Estos períodos de tiempo no exactos se llaman períodos y será discutido en la siguiente sección.\nLa duración de una duración es invariable para saltar años, segundos intercalares y horario de verano porque las duraciones se miden en segundos.\nPor lo tanto, las duraciones tienen longitudes consistentes y se puede comparar fácilmente con otras duraciones. Las duraciones son el objeto apropiado para usar cuando se comparan atributos basados en tiempo, como velocidades, tasas y tiempos de vida.\nEl paquete base de R tiene definido a objetos de tipo duración en la clase difftime.\nlubridate incorpora un segundo tipo: objetos clase duration\nEstos objetos se pueden usar con otros objetos de fecha y hora sin preocuparse sobre en qué unidades se muestran. Se puede crear un objeto de duración con la función duration():\n\nduration(60)\n\n[1] \"60s (~1 minutes)\"\n\n\nPara duraciones grandes, resulta inconveniente describir la longitud en segundos. Por ejemplo, no muchas personas reconocerían que 31557600 segundos es la duración de un año estándar. Por esta razón, los objetos de gran duración son seguidos entre paréntesis por una longitud estimada. Un minuto son 60 segundos, una hora 3600 segundos, un día 86400, una semana 604800 y un año 31557600 (365.25 días).\nLos objetos de clase duration se pueden crear fácilmente con las funciones auxiliares dyears(), dweeks(), ddays(), dhours(), dminutes() y dseconds(). La d en el nombre representa duración.\nCada objeto se crea tomando como unidad los segundos usando las relaciones estimadas descriptas arriba. El argumento de cada función es el número de unidades estimadas que deseamos incluir en la duración.\n\ndminutes(1)\n\n[1] \"60s (~1 minutes)\"\n\n\n\ndseconds(60)\n\n[1] \"60s (~1 minutes)\"\n\n\n\ndminutes(2)\n\n[1] \"120s (~2 minutes)\"\n\n\n\n1:3 * dhours(1)\n\n[1] \"3600s (~1 hours)\"  \"7200s (~2 hours)\"  \"10800s (~3 hours)\"\n\n\nLas duraciones se pueden agregar o restar a cualquier objeto instante.\n\nstart_2024\n\n[1] \"2024-01-01 12:00:00 UTC\"\n\nstart_2024 + ddays(10)\n\n[1] \"2024-01-11 12:00:00 UTC\"\n\n\nLas duraciones también se pueden agregar o restar de intervalos y otras duraciones. Por ejemplo:\n\ndweeks(1) + ddays(6) + dhours(2) + dminutes(1.5) + dseconds(3)\n\n[1] \"1130493s (~1.87 weeks)\"\n\n\nTambién podemos crear duraciones a partir de objetos intervalo y períodos usando as.duration().\n\nas.duration(intervalo)\n\n[1] \"31536000s (~52.14 weeks)\"\n\n\n\n\n\nLos períodos registran un intervalo de tiempo en unidades mayores que segundos, como años, meses, semanas, días, horas y minutos. Para mayor comodidad, también podemos crear un período que solo use segundos, pero dicho período tendría las mismas propiedades que una duración. lubridate introduce la clase period para modelar períodos. Construimos objetos de período con las funciones auxiliares years(), months(), weeks(), days(), hours(), minutes() y seconds().\n\nmonths(3)\n\n[1] \"3m 0d 0H 0M 0S\"\n\n\n\nmonths(3) + days(2)\n\n[1] \"3m 2d 0H 0M 0S\"\n\n\nEstas funciones no contienen una d en su nombre, porque no crean duraciones; ya no tienen longitudes consistentes (medidas en segundos). Por ejemplo, meses (2) siempre tiene una duración de dos meses, aunque la duración de dos meses cambiará según cuando comienza el período (podrán ser meses de 30, 31 0 28 días).\nPor esta razón, no podemos calcular exactamente cuánto tiempo será un período en segundos hasta que sepamos cuándo ocurre. Sin embargo, aún podemos realizar cálculos de fecha y hora con períodos. Cuando agregamos o restamos un período a un instante, el período queda asociado al instante. El instante nos dice cuándo ocurre el período, lo que nos permite calcular su longitud exacta en segundos.\nPor ejemplo para un año bisiesto, primero sumamos un año con years():\n\nstart_2024 + years(1)\n\n[1] \"2025-01-01 12:00:00 UTC\"\n\n\nvs. sumar un año como duración con dyears()\n\nstart_2024 + dyears(1)\n\n[1] \"2024-12-31 18:00:00 UTC\"\n\n\nTambién podemos convertir otros objetos intervalo en períodos con la función as.period().\n\nas.period(intervalo)\n\n[1] \"1y 0m 0d 0H 0M 0S\"\n\n\nLos períodos se pueden agregar a instantes, intervalos y otros períodos, pero no a duraciones.\n\n\n\n\nA veces necesitamos responder preguntas que implican dividir un intervalo de tiempo por otro. Por ejemplo, ¿Cuántos años tiene una persona nacida el 26 de junio de 1976?\nObjetos de clase interval, duration y period pueden dividirse por otros objetos de las mismas clases. Los resultados de estas divisiones varían dependiendo de la naturaleza de los intervalos de tiempo involucrados. La división modular (%/%) también funciona con estas clases.\nPara ilustrar esto, hacemos un intervalo entre la fecha de nacimiento y la fecha actual.\n\nnacimiento &lt;- ymd(\"1976-06-26\")\n\nhoy &lt;- now()\n\nintervalo &lt;- interval(nacimiento, hoy)\n\nintervalo\n\n[1] 1976-06-26 UTC--2025-07-03 16:29:11 UTC\n\n\nComo las duraciones son una medida exacta de un intervalo de tiempo, podemos dividir este intervalo por una duración para obtener una respuesta exacta.\n\nintervalo / dyears(1)\n\n[1] 49.02036\n\n\nPodríamos utilizar un período en lugar de duración\n\nintervalo / years()\n\n[1] 49.02106\n\n\nPero lo más útil es la división modular para redondear y quedarnos solo con los años:\n\nintervalo %/% dyears()\n\n[1] 49\n\n\nEn resumen, la aritmética con tipos fecha-hora puede involucrar cuatro tipos de objetos: instantes, intervalos, duraciones y períodos.\nlubridate crea nuevas clases de objetos: interval, duration y period. Reconoce que las clases de fecha y hora más comunes, como POSIXt y Date, se refieren a instantes. La siguiente tabla describe qué objetos se pueden combinar con otro y qué tipo de objeto resultará.\n\n\n\n\ninstante\ninterval\nduration\nperiod\n\n\n\n\ninstante\nNA\ninstante\ninstante\ninstante\n\n\ninterval\ninstante\ninterval*\ninterval\ninterval\n\n\nduration\ninstante\ninterval\nduration\nperiod\n\n\nperiod\ninstante\ninterval\nperiod\nperiod\n\n\n\n*= clase duration si los intervalos no se alinean.\n\n\n\nAl igual que los números, las fechas se ordenan en forma creciente. Esto permite redondear los tipos de datos fecha-hora.\nlubridate proporciona tres métodos que ayudan a realizar este redondeo: round_date(), floor_date(), y ceiling_date().\nEl primer argumento de cada función es la fecha-hora a ser redondeada. El segundo argumento es la unidad tomada para redondear.\nPor ejemplo, podríamos redondear la siguiente fecha-hora a la unidad día:\n\nnov23 &lt;- ymd_hms(\"2023-11-23 09:38:29\")\n\nnov23\n\n[1] \"2023-11-23 09:38:29 UTC\"\n\nround_date(nov23, \"day\")\n\n[1] \"2023-11-23 UTC\"\n\n\nPero también podríamos desear redondear al comienzo de mes más próximo, asi:\n\nround_date(nov23, \"month\")\n\n[1] \"2023-12-01 UTC\"\n\n\nTenga en cuenta que al redondear un dato fecha-hora a una unidad determinada, se establece la fecha al inicio de esa unidad (al definir día, por ejemplo se establece la información de horas, minutos y segundos en 00).\nLas otras dos funciones de redondeo lo hacen al comienzo del mes menor (floor) o mayor (ceiling).\nPor ejemplo, con ceiling_date(), podemos hallar el último día de cada mes, sin importar la fecha que tengamos almacenada. Luego de ubicar el inicio del próximo mes, restamos un día.\n\nceiling_date(nov23, \"month\") - days(1)\n\n[1] \"2023-11-30 UTC\"\n\n\n\noct02 &lt;- ymd_hms(\"2023-10-02 00:00:00\")\n\nceiling_date(oct02, \"month\") - days(1)\n\n[1] \"2023-10-31 UTC\"\n\n\n\n\n\nLas zonas horarias complejizan a los datos fecha-hora, pero algunas veces nos encontramos con bases de datos o situaciones en que debemos lidiar con ellas. Cuando creamos instantes en R, la zona horaria estándar es la universal (UTC).\nlubridate ofrece dos formas de trabajar con zonas horarias.\nPodemos cambiar la zona horaria en la que se muestra un instante utilizando la función with_tz(). Esto cambia la forma en que se muestra el instante, pero continúa siendo el mismo. Por ejemplo, el objeto fecha tiene cargada una fecha-hora creada a partir de la función now() y al ejecutarse en un equipo con configuración regional de Argentina toma el uso horario de Buenos Aires (aparece -03 al final del día y horario)\n\nfecha\n\n[1] \"2022-01-01\"\n\n\nAl llevarlo a la zona horaria universal, le agrega 3 horas más, aunque sigue siendo el mismo instante.\n\nwith_tz(fecha, \"UTC\")\n\n[1] \"2022-01-01 UTC\"\n\n\nforce_tz() hace lo contrario de with_tz(): cambia el instante real de tiempo guardado en el objeto. Por ejemplo, el siguiente código nos mueve a un nuevo instante que ocurre 3 horas más temprano.\n\nforce_tz(fecha, \"UTC\")\n\n[1] \"2022-01-01 UTC\"\n\n\nEn este caso, un instante horario 11:32:01 UTC correponde al instante 08:32:01 -3\nwith_tz() y force_tz() solo funcionan con zonas horarias reconocidas por el sistema operativo de la computadora que aloja R. Esta lista de zonas horarias variará de una computadora a otra. Para más información ver la página de ayuda de R para Sys.timezone().\nEl código de nuestra zona horaria (es conocida como UTC-03:00 - Ciudad de Buenos Aires) para incorporar al argumento es America/Buenos_Aires",
    "crumbs": [
      "Unidad 4: Tratamiento de datos específicos"
    ]
  },
  {
    "objectID": "unidad4.html#variables-de-tiempo",
    "href": "unidad4.html#variables-de-tiempo",
    "title": "Unidad 4: Tratamiento de datos específicos",
    "section": "",
    "text": "Artwork por @allison_horst\n\n\n\nLos eventos epidemiológicos se presentan en algun momento del tiempo, por lo que las variables de tiempo son habituales componentes de las bases de datos con las que trabaja un epidemiólogo. Estas variables pueden presentarse en distintas unidades de medida, tales como horas, días, años, decadas, etc.\nA veces trabajar con datos tipo fecha y hora puede ser frustrante.Las fechas vienen en muchos formatos diferentes, que hace que reconocerlos y analizarlos sea un desafío.\nPrimero necesitamos que los datos sean reconocidos como formato fecha (Date) y luego debemos lidiar con operaciones específicas como extraer componentes de los horarios, como años, meses o segundos, o cambiar zonas horarias o hacer cálculos entres fechas.\nPara simplificar esta tarea tidyverse trae el paquete lubridate que proporciona herramientas para manipular variables fecha-hora.\nEspecíficamente, lubridate ayuda a los usuarios a:\n\nIdentificar y analizar los datos de fecha y hora.\nExtrer y modificar componentes de una fecha y hora, como años, meses, días, horas, minutos y segundos.\nRealizar cálculos precisos con fecha y hora.\nManejar zonas horarias y horario de verano.\n\nlubridate se instala y activa con tidyverse:\n\n\nPodemos leer fechas en R usando la serie de funciones ymd() proporcionada por este paquete. Estas funciones analizan el contenido de cadenas de caracteres y las transforman a fechas.\nLas letras y, m y d corresponden al año, mes y día de una fecha. Para leer una fecha, seleccionamos el nombre de la función que coincide con el orden de los elementos contenidos en el objeto original. Por ejemplo, en la siguiente fecha el elemento mes viene primero, seguido por el día y luego el año, al estilo estadounidense. Entonces usaríamos la función mdy():\n\nmdy(\"01-24-2024\")\n\n[1] \"2024-01-24\"\n\n\nEl formato de salida siempre año-mes-día, es decir se organiza del elemento más grande que anida a los otros.\nSi en cambio tuviese la forma en que usamos las fechas nosotros, usaríamos dmy().\n\ndmy(\"24-01-2024\")\n\n[1] \"2024-01-24\"\n\n\nComo se observa el formato de los caracteres de entrada pueden utilizar distintos separadores, como guión medio (-), punto (.), barra inclinada (/), guión bajo (_) o incluso espacios.\nLa clase de los objetos convertidos es Date.\n\nx &lt;- dmy(\"24/01/2024\")\n\nclass(x)\n\n[1] \"Date\"\n\n\n\n\n\nOrden de los elementos\nFunción\n\n\n\n\naño, mes y día\nymd()\n\n\naño, día y mes\nydm()\n\n\nmes, día y año\nmdy()\n\n\ndía, mes y año\ndmy()\n\n\nhora y minuto\nhm()\n\n\nhora, minuto y segundo\nhms()\n\n\naño, mes, día, hora, minuto y segundo\nymd_hms()\n\n\n\nLas funciones que tienen componente de hora crean objetos POSIXct.\nCuando una función dmy() se aplica a un vector de fechas, lubridate supone que todas las fechas tienen el mismo orden y los mismos separadores.\n\n\n\nCada estructura fecha-hora es una combinación de diferentes elementos, cada uno con su propio valor. Por ejemplo, la mayoría de las fechas incluyen un valor de año, un valor de mes, un valor de día, etc. Juntos estos elementos especifican el momento exacto al que se refiere la fecha y la hora.\nPodemos extraer fácilmente cada elemento de una fecha-hora con la función de acceso que tiene su nombre, como se muestra en la siguiente tabla.\n\n\n\nComponente de fecha\nFunción\n\n\n\n\nAño\nyear()\n\n\nMes\nmonth()\n\n\nSemana\nweek()\n\n\nDía del año\nyday()\n\n\nDía del mes\nmday()\n\n\nDía de la semana\nwday()\n\n\nHora\nhour()\n\n\nMinuto\nminute()\n\n\nSegundo\nsecond()\n\n\nZona horaria (huso horario)\ntz()\n\n\n\nPor ejemplo, si almacenamos la fecha y hora actual del sistema en un objeto:\n\nfecha &lt;- now()\n\nfecha\n\n[1] \"2025-07-03 13:29:10 -03\"\n\n\npodemos extraer cada uno de sus elementos.\nTengamos en cuenta que la función now(), perteneciente al mismo paquete lubridate, devolverá una fecha diferente cada vez que se ejecute.\n\nyear(fecha)\n\n[1] 2025\n\n\n\nmday(fecha)\n\n[1] 3\n\n\n\nhour(fecha)\n\n[1] 13\n\nminute(fecha)\n\n[1] 29\n\n\nPara los elementos de mes y día de la semana (wday), también podemos especificar si queremos extraer el valor numérico del elemento, una abreviatura del nombre del mes o día de la semana, o el nombre completo.\nPor ejemplo:\n\nmonth(fecha)\n\n[1] 7\n\n\n\nmonth(fecha, label = TRUE)\n\n[1] jul\n12 Levels: ene &lt; feb &lt; mar &lt; abr &lt; may &lt; jun &lt; jul &lt; ago &lt; sep &lt; ... &lt; dic\n\n\n\nmonth(fecha, label = TRUE, abbr = FALSE)\n\n[1] julio\n12 Levels: enero &lt; febrero &lt; marzo &lt; abril &lt; mayo &lt; junio &lt; ... &lt; diciembre\n\n\n\nwday(fecha, label = TRUE, abbr = FALSE)\n\n[1] jueves\n7 Levels: domingo &lt; lunes &lt; martes &lt; miércoles &lt; jueves &lt; ... &lt; sábado\n\n\nOtra buena noticia es que el paquete se adapta al formato regional del sistema operativo donde se encuentra funcionando, por lo que los nombres de los meses o los días de la semana, en este caso, figuran en español (si nuestro sistema operativo está instalado bajo ese idioma).\nPor otra parte, también podemos usar cualquiera de las funciones de acceso para establecer el valor de un elemento. Por ejemplo,\n\nfecha\n\n[1] \"2025-07-03 13:29:10 -03\"\n\nday(fecha) &lt;- 5\n\nfecha\n\n[1] \"2025-07-05 13:29:10 -03\"\n\n\ncambia nuestra fecha al quinto día del mes. También podemos configurar los elementos para más valores complicados, por ejemplo:\n\nfechas &lt;- ymd_hms(\"2017-01-01 01:00:00\", \"2017-01-01 01:30:00\")\n\nminute(fechas) &lt;- mean(minute(fechas))\n\nfechas # promedió los minutos en los dos casos\n\n[1] \"2017-01-01 01:15:00 UTC\" \"2017-01-01 01:15:00 UTC\"\n\n\nSi asignamos a un elemento un valor mayor de lo admitido, la diferencia se extenderá en el siguiente elemento superior (respetando la cantidad de días del mes de mayo adecuadamente en este caso.)\n\nfecha\n\n[1] \"2025-07-05 13:29:10 -03\"\n\nday(fecha) &lt;- 35 \n\nfecha\n\n[1] \"2025-08-04 13:29:10 -03\"\n\n\nFinalmente, también podemos cambiar las fechas agregando o restando unidades de tiempo.\n\nfecha\n\n[1] \"2025-08-04 13:29:10 -03\"\n\nfecha &lt;- fecha + hours(3)\n\nfecha\n\n[1] \"2025-08-04 16:29:10 -03\"\n\n\nObservemos que hours() (plural) no es la misma función que hour() (singular).\nPor último, algo muy útil para nuestro trabajo es poder extraer la semana epidemiologica, con la función epiweek(), en la que cae una fecha en particular o un conjunto de ellas dentro de una variable.\n\nepiweek(fecha)\n\n[1] 32\n\n\nJunto con la semana epidemiológica se puede obtener el año epidemiológico con la función epiyear()\nPor ejemplo, la fecha 01/01/2022 es el primer día de enero de 2022 pero pertenece a la semana epidemiológica 52 de año 2021. Veamos:\n\nfecha &lt;- dmy(\"01-01-2022\")\n\nfecha\n\n[1] \"2022-01-01\"\n\nepiweek(fecha)\n\n[1] 52\n\n\nSi uno obtiene el año al que pertenece, nos dice que 2022 pero si lo queremos asociar con su semana epidemiológica, nos quedaría que estamos en la semana 52 del año 2022, cosa que no es cierta.\n\nyear(fecha)\n\n[1] 2022\n\n\nEn estas situaciones que no coinciden el año de la fecha con el año epidemiológico de la semana es que se aplica epiyear().\n\nepiyear(fecha)\n\n[1] 2021\n\n\n\n\n\nLos cálculos con fechas y horas son más complicados que la aritmética con números, pero puede hacerse con precisión y facilidad mediante este paquete.\n¿Qué es lo que complica a la aritmética con datos de tiempo (fechas u horas)?\nEl tiempo que medimos en el reloj se calibra periódicamente para ajustar las condiciones astronómicas, por caso los años bisiestos o los horarios de verano que se utilizan en muchos países.\nEn diferentes momentos, la duración de meses, semanas, días, horas e incluso minutos puede variar. Por lo tanto, podemos considerar que son unidades relativas de tiempo; su longitud es relativa a cuando ocurren; por el contrario, los segundos siempre tienen una longitud constante (son unidades de tiempo exactas)\nlubridate permite cálculos con unidades relativas y exactas introduciendo cuatro nuevos elementos relacionados: instantes, intervalos, duraciones y períodos. Estos conceptos son tomados del proyecto Joda Time (Colebourne y O’Neill 2010). Conceptos similares para instantes, períodos y duraciones también aparecen en la biblioteca C++ Boost - Date Time (Garland 2011).\nlubridate proporciona funciones auxiliares, clases de objetos y métodos para usar los cuatro conceptos en el lenguaje R.\n\n\nUn instante es un momento específico en el tiempo, como el 1 de enero de 2024. Creamos un instante cada vez que convertimos una fecha a formato Date de R.\n\nstart_2024 &lt;- ymd_hms(\"2024-01-01 12:00:00\")\n\nlubridate no crea una nueva clase de objetos instantes. En cambio, reconoce cualquier objeto de fecha y hora como un instante. Podemos probar si un objeto es un instante usando el identificador is.instant(). Por ejemplo:\n\nis.instant(start_2024)\n\n[1] TRUE\n\n\n\n\n\nLos intervalos, duraciones y períodos son todas formas de registrar tiempos. De estos, los intervalos son los más simples. Un intervalo es un lapso de tiempo que ocurre entre dos instantes específicos.\nPodemos crear objetos de intervalo restando dos instantes, mediante %–% o usando la función new_interval().\n\nstart_2023 &lt;- ymd_hms(\"2023-01-01 12:00:00\")\nstart_2024 &lt;- ymd_hms(\"2024-01-01 12:00:00\")\nintervalo &lt;- start_2023 %--% start_2024\nintervalo\n\n[1] 2023-01-01 12:00:00 UTC--2024-01-01 12:00:00 UTC\n\n\nPodemos acceder a las fechas de inicio y finalización de un objeto de intervalo con int_start() e int_end().\nLos intervalos siempre comienzan en la fecha y hora que ocurre primero y finaliza en la fecha y hora que ocurre último. Por lo tanto, los intervalos siempre tienen una longitud positiva.\n\nint_start(intervalo)\n\n[1] \"2023-01-01 12:00:00 UTC\"\n\n\n\nint_end(intervalo)\n\n[1] \"2024-01-01 12:00:00 UTC\"\n\n\nDesafortunadamente, dado que los intervalos están anclados a sus fechas de inicio y finalización, no son muy útiles para cálculos de fecha y hora.\n\n\n\nSi eliminamos las fechas de inicio y finalización de un intervalo, tendremos un intervalo de tiempo genérico que podemos agregar a cualquier fecha. Pero, en que unidad es conveniente medir este período de tiempo? Como vimos anteriormente, si lo almacenamos en segundos, tendrá una longitud exacta ya que los segundos siempre tienen la misma longitud.\nLlamamos duraciones de estos lapsos de tiempo. Alternativamente, podemos registrar el lapso de tiempo en unidades más grandes, como minutos o años.\nDado que la longitud de estas unidades varía con el tiempo, la longitud exacta de el lapso de tiempo dependerá de cuándo comience. Estos períodos de tiempo no exactos se llaman períodos y será discutido en la siguiente sección.\nLa duración de una duración es invariable para saltar años, segundos intercalares y horario de verano porque las duraciones se miden en segundos.\nPor lo tanto, las duraciones tienen longitudes consistentes y se puede comparar fácilmente con otras duraciones. Las duraciones son el objeto apropiado para usar cuando se comparan atributos basados en tiempo, como velocidades, tasas y tiempos de vida.\nEl paquete base de R tiene definido a objetos de tipo duración en la clase difftime.\nlubridate incorpora un segundo tipo: objetos clase duration\nEstos objetos se pueden usar con otros objetos de fecha y hora sin preocuparse sobre en qué unidades se muestran. Se puede crear un objeto de duración con la función duration():\n\nduration(60)\n\n[1] \"60s (~1 minutes)\"\n\n\nPara duraciones grandes, resulta inconveniente describir la longitud en segundos. Por ejemplo, no muchas personas reconocerían que 31557600 segundos es la duración de un año estándar. Por esta razón, los objetos de gran duración son seguidos entre paréntesis por una longitud estimada. Un minuto son 60 segundos, una hora 3600 segundos, un día 86400, una semana 604800 y un año 31557600 (365.25 días).\nLos objetos de clase duration se pueden crear fácilmente con las funciones auxiliares dyears(), dweeks(), ddays(), dhours(), dminutes() y dseconds(). La d en el nombre representa duración.\nCada objeto se crea tomando como unidad los segundos usando las relaciones estimadas descriptas arriba. El argumento de cada función es el número de unidades estimadas que deseamos incluir en la duración.\n\ndminutes(1)\n\n[1] \"60s (~1 minutes)\"\n\n\n\ndseconds(60)\n\n[1] \"60s (~1 minutes)\"\n\n\n\ndminutes(2)\n\n[1] \"120s (~2 minutes)\"\n\n\n\n1:3 * dhours(1)\n\n[1] \"3600s (~1 hours)\"  \"7200s (~2 hours)\"  \"10800s (~3 hours)\"\n\n\nLas duraciones se pueden agregar o restar a cualquier objeto instante.\n\nstart_2024\n\n[1] \"2024-01-01 12:00:00 UTC\"\n\nstart_2024 + ddays(10)\n\n[1] \"2024-01-11 12:00:00 UTC\"\n\n\nLas duraciones también se pueden agregar o restar de intervalos y otras duraciones. Por ejemplo:\n\ndweeks(1) + ddays(6) + dhours(2) + dminutes(1.5) + dseconds(3)\n\n[1] \"1130493s (~1.87 weeks)\"\n\n\nTambién podemos crear duraciones a partir de objetos intervalo y períodos usando as.duration().\n\nas.duration(intervalo)\n\n[1] \"31536000s (~52.14 weeks)\"\n\n\n\n\n\nLos períodos registran un intervalo de tiempo en unidades mayores que segundos, como años, meses, semanas, días, horas y minutos. Para mayor comodidad, también podemos crear un período que solo use segundos, pero dicho período tendría las mismas propiedades que una duración. lubridate introduce la clase period para modelar períodos. Construimos objetos de período con las funciones auxiliares years(), months(), weeks(), days(), hours(), minutes() y seconds().\n\nmonths(3)\n\n[1] \"3m 0d 0H 0M 0S\"\n\n\n\nmonths(3) + days(2)\n\n[1] \"3m 2d 0H 0M 0S\"\n\n\nEstas funciones no contienen una d en su nombre, porque no crean duraciones; ya no tienen longitudes consistentes (medidas en segundos). Por ejemplo, meses (2) siempre tiene una duración de dos meses, aunque la duración de dos meses cambiará según cuando comienza el período (podrán ser meses de 30, 31 0 28 días).\nPor esta razón, no podemos calcular exactamente cuánto tiempo será un período en segundos hasta que sepamos cuándo ocurre. Sin embargo, aún podemos realizar cálculos de fecha y hora con períodos. Cuando agregamos o restamos un período a un instante, el período queda asociado al instante. El instante nos dice cuándo ocurre el período, lo que nos permite calcular su longitud exacta en segundos.\nPor ejemplo para un año bisiesto, primero sumamos un año con years():\n\nstart_2024 + years(1)\n\n[1] \"2025-01-01 12:00:00 UTC\"\n\n\nvs. sumar un año como duración con dyears()\n\nstart_2024 + dyears(1)\n\n[1] \"2024-12-31 18:00:00 UTC\"\n\n\nTambién podemos convertir otros objetos intervalo en períodos con la función as.period().\n\nas.period(intervalo)\n\n[1] \"1y 0m 0d 0H 0M 0S\"\n\n\nLos períodos se pueden agregar a instantes, intervalos y otros períodos, pero no a duraciones.\n\n\n\n\nA veces necesitamos responder preguntas que implican dividir un intervalo de tiempo por otro. Por ejemplo, ¿Cuántos años tiene una persona nacida el 26 de junio de 1976?\nObjetos de clase interval, duration y period pueden dividirse por otros objetos de las mismas clases. Los resultados de estas divisiones varían dependiendo de la naturaleza de los intervalos de tiempo involucrados. La división modular (%/%) también funciona con estas clases.\nPara ilustrar esto, hacemos un intervalo entre la fecha de nacimiento y la fecha actual.\n\nnacimiento &lt;- ymd(\"1976-06-26\")\n\nhoy &lt;- now()\n\nintervalo &lt;- interval(nacimiento, hoy)\n\nintervalo\n\n[1] 1976-06-26 UTC--2025-07-03 16:29:11 UTC\n\n\nComo las duraciones son una medida exacta de un intervalo de tiempo, podemos dividir este intervalo por una duración para obtener una respuesta exacta.\n\nintervalo / dyears(1)\n\n[1] 49.02036\n\n\nPodríamos utilizar un período en lugar de duración\n\nintervalo / years()\n\n[1] 49.02106\n\n\nPero lo más útil es la división modular para redondear y quedarnos solo con los años:\n\nintervalo %/% dyears()\n\n[1] 49\n\n\nEn resumen, la aritmética con tipos fecha-hora puede involucrar cuatro tipos de objetos: instantes, intervalos, duraciones y períodos.\nlubridate crea nuevas clases de objetos: interval, duration y period. Reconoce que las clases de fecha y hora más comunes, como POSIXt y Date, se refieren a instantes. La siguiente tabla describe qué objetos se pueden combinar con otro y qué tipo de objeto resultará.\n\n\n\n\ninstante\ninterval\nduration\nperiod\n\n\n\n\ninstante\nNA\ninstante\ninstante\ninstante\n\n\ninterval\ninstante\ninterval*\ninterval\ninterval\n\n\nduration\ninstante\ninterval\nduration\nperiod\n\n\nperiod\ninstante\ninterval\nperiod\nperiod\n\n\n\n*= clase duration si los intervalos no se alinean.\n\n\n\nAl igual que los números, las fechas se ordenan en forma creciente. Esto permite redondear los tipos de datos fecha-hora.\nlubridate proporciona tres métodos que ayudan a realizar este redondeo: round_date(), floor_date(), y ceiling_date().\nEl primer argumento de cada función es la fecha-hora a ser redondeada. El segundo argumento es la unidad tomada para redondear.\nPor ejemplo, podríamos redondear la siguiente fecha-hora a la unidad día:\n\nnov23 &lt;- ymd_hms(\"2023-11-23 09:38:29\")\n\nnov23\n\n[1] \"2023-11-23 09:38:29 UTC\"\n\nround_date(nov23, \"day\")\n\n[1] \"2023-11-23 UTC\"\n\n\nPero también podríamos desear redondear al comienzo de mes más próximo, asi:\n\nround_date(nov23, \"month\")\n\n[1] \"2023-12-01 UTC\"\n\n\nTenga en cuenta que al redondear un dato fecha-hora a una unidad determinada, se establece la fecha al inicio de esa unidad (al definir día, por ejemplo se establece la información de horas, minutos y segundos en 00).\nLas otras dos funciones de redondeo lo hacen al comienzo del mes menor (floor) o mayor (ceiling).\nPor ejemplo, con ceiling_date(), podemos hallar el último día de cada mes, sin importar la fecha que tengamos almacenada. Luego de ubicar el inicio del próximo mes, restamos un día.\n\nceiling_date(nov23, \"month\") - days(1)\n\n[1] \"2023-11-30 UTC\"\n\n\n\noct02 &lt;- ymd_hms(\"2023-10-02 00:00:00\")\n\nceiling_date(oct02, \"month\") - days(1)\n\n[1] \"2023-10-31 UTC\"\n\n\n\n\n\nLas zonas horarias complejizan a los datos fecha-hora, pero algunas veces nos encontramos con bases de datos o situaciones en que debemos lidiar con ellas. Cuando creamos instantes en R, la zona horaria estándar es la universal (UTC).\nlubridate ofrece dos formas de trabajar con zonas horarias.\nPodemos cambiar la zona horaria en la que se muestra un instante utilizando la función with_tz(). Esto cambia la forma en que se muestra el instante, pero continúa siendo el mismo. Por ejemplo, el objeto fecha tiene cargada una fecha-hora creada a partir de la función now() y al ejecutarse en un equipo con configuración regional de Argentina toma el uso horario de Buenos Aires (aparece -03 al final del día y horario)\n\nfecha\n\n[1] \"2022-01-01\"\n\n\nAl llevarlo a la zona horaria universal, le agrega 3 horas más, aunque sigue siendo el mismo instante.\n\nwith_tz(fecha, \"UTC\")\n\n[1] \"2022-01-01 UTC\"\n\n\nforce_tz() hace lo contrario de with_tz(): cambia el instante real de tiempo guardado en el objeto. Por ejemplo, el siguiente código nos mueve a un nuevo instante que ocurre 3 horas más temprano.\n\nforce_tz(fecha, \"UTC\")\n\n[1] \"2022-01-01 UTC\"\n\n\nEn este caso, un instante horario 11:32:01 UTC correponde al instante 08:32:01 -3\nwith_tz() y force_tz() solo funcionan con zonas horarias reconocidas por el sistema operativo de la computadora que aloja R. Esta lista de zonas horarias variará de una computadora a otra. Para más información ver la página de ayuda de R para Sys.timezone().\nEl código de nuestra zona horaria (es conocida como UTC-03:00 - Ciudad de Buenos Aires) para incorporar al argumento es America/Buenos_Aires",
    "crumbs": [
      "Unidad 4: Tratamiento de datos específicos"
    ]
  },
  {
    "objectID": "unidad4.html#cadena-de-caracteres",
    "href": "unidad4.html#cadena-de-caracteres",
    "title": "Unidad 4: Tratamiento de datos específicos",
    "section": "Cadena de caracteres",
    "text": "Cadena de caracteres\n\n\n\n\nArtwork por @allison_horst\n\n\n\nEl paquete encargado de trabajar con cadenas de caracteres dentro de tidyverse es stringr.\nTodas las funciones del paquete comienzan con str_ y trabajan sobre un vector de caracteres como primer argumento.\nHay tres grandes familias útiles de funciones en string:\nFunciones de manipulación de caracteres: estas funciones permiten manipular caracteres dentro de cadenas\nHerramientas para tratamiento de espacios en blanco: para agregar, eliminar y manipular espacios en blanco.\nFunciones de coincidencia de patrones: trabaja con motores de descripción de patrones, para funciones de busqueda, extracción, reemplazo, etc. Trabajan con expresiones regulares.\nstringr también se instala y activa junto a tidyverse.\n\nManipulación de caracteres\nPodemos obtener la longitud de la cadena con str_lenght()\n\nstr_length(\"abc\")\n\n[1] 3\n\n\nEsta función es equivalente a la función de R base nchar().\nPara acceder a un carácter individual se utiliza sub_str().\nSe necesitan tres argumentos: un vector de caracteres, una posición inicial y una posición final. Cualquiera de las posiciones puede ser un entero positivo, que cuenta a partir de la longitud, o un entero negativo que cuenta desde la derecha. Las posiciones son inclusivas, y si es más larga que la cadena, se truncarán silenciosamente.\n\nx &lt;- c(\"abcdef\", \"ghifjk\")\n\nla tercer letra de cada cadena\n\nstr_sub(x, 3, 3)\n\n[1] \"c\" \"i\"\n\n\ndesde la segunda letra hasta la anteúltima\n\nstr_sub(x, 2, -2)\n\n[1] \"bcde\" \"hifj\"\n\n\nTambién puede utilizar str_sub() para modificar cadenas de caracteres\n\nstr_sub(x, 3, 3) &lt;- \"X\"\n\nx\n\n[1] \"abXdef\" \"ghXfjk\"\n\n\nEl paquete stringr trae incorporado algunas funciones para manipulación de mayúsculas y minúsculas, similares a tolower() y toupper()\n\nx &lt;- \"Curso de lenguaje R\"\n\nconvierte a mayúsculas\n\nstr_to_upper(x)\n\n[1] \"CURSO DE LENGUAJE R\"\n\n\nconvierte a minúsculas\n\nstr_to_lower(x)\n\n[1] \"curso de lenguaje r\"\n\n\nconvierte a tipo título (la primer letra de cada palabra en mayúsculas)\n\nstr_to_title(x)\n\n[1] \"Curso De Lenguaje R\"\n\n\nTambién existen funciones para ordenar secuencias de caracteres\n\nx &lt;- c(\"y\", \"i\", \"k\")\n\nstr_order(x)\n\n[1] 2 3 1\n\n\ndevuelve el orden alfabético del índice de los elementos\n\nstr_sort(x)\n\n[1] \"i\" \"k\" \"y\"\n\n\ndevuelve los caracteres en orden alfabético\n\nstr_sort(x, decreasing = T)\n\n[1] \"y\" \"k\" \"i\"\n\n\nigual al anterior pero en orden decreciente\n\n\nEspacios en blanco\nHay tres funciones que añaden, eliminan o modifican espacios en blanco\nstr_pad() agrega espacio en blanco extra a una cadena a una longitud fija puede ser a izquierda, derecha o ambos lados.\n\nx &lt;- c (\"abc\", \"defghi\")\n\n\nstr_pad(x, 10)\n\n[1] \"       abc\" \"    defghi\"\n\n\nrellena con espacios en blanco hasta alcanzar la cantidad de 10 caracteres por cadena sin definir el argumento side= lo hace a la izquierda\n\nstr_pad(x, 10, side = \"both\")\n\n[1] \"   abc    \" \"  defghi  \"\n\n\naquí lo hacemos rellenando los espacios en blanco a ambos lados\nLo opuesto a rellenar de espacios en blanco es eliminarlos y esta tarea la realiza la función str_trim()\n\nx &lt;- c(\"  a   \", \"b   \",  \"   c\")\n\nstr_trim(x)\n\n[1] \"a\" \"b\" \"c\"\n\n\nelimina todos los espacios en blanco a ambos lados de la cadena\n\nstr_trim(x, side=\"left\")\n\n[1] \"a   \" \"b   \" \"c\"   \n\n\ncon el argumento side= le podemos indicar de que lado queremos eliminarlos\n\n\nPatrones\n\n\n\n\nArtwork por @allison_horst\n\n\n\nLa mayoría de las funciones de stringr para trabajo con patrones de caracteres funcionan con expresiones regulares (un lenguaje conciso para describir patrones de texto).\nBásicamente una expresión regular es una cadena de texto especial para describir un patrón de búsqueda que se puede utilizar para:\n\nlocalizar cadenas de caracteres (ubicar - filtrar)\nextraer una porción de los datos (extraer)\nmodificar los datos localizados (reemplazar)\n\nHabitualmente se construyen concatenando la especificación de caracteres secuenciados junto a otros metacaracteres.\nSon muy útiles cuando tenemos variables de alfanuméricas regulares, es decir con una estructura que se repite. Por ejemplo, los códigos internacionales de enfermedad, conocidos como CIE (actualmente en la versión CIE10/CIE11)\nAlgunos de los metacaracteres para construir expresiones regulares son:\n\n\n\n\n\n\n\nSímbolos y metacaracteres\nDescripción\n\n\n\n\n^\nInicio de la cadena\n\n\n$\nFinal de la cadena\n\n\n[ ]\nCualquier carácter del conjunto entre paréntesis\n\n\n[^]\nCualquier carácter no incluido en el conjunto\n\n\n?\nCero o una ocurrencia de lo que precede al símbolo\n\n\n+\nEl caracter que le precede debe aparecer al menos una vez\n\n\n*\nEl caracter que le precede debe aparecer cero, una o más veces\n\n\n{x}\nx ocurrencias del caracter que lo precede\n\n\n{x,z}\nEntre x y z ocurrencias del caracter que lo precede\n\n\n{x,}\nx o más ocurrencias de lo que lo precede\n\n\n\n\n\n\n\n\n\n\nSímbolos y metacaracteres\nDescripción\n\n\n\n\n|\nUne subexpresiones\n\n\n.\nConcuerda con cualquier carácter individual\n\n\n( )\nAgrupa subexpresiones\n\n\n0-9 a-z A-Z\nRangos de números, letras…\n\n\n\\\nMarca el carácter siguiente como un carácter especial\n\n\n.\nRepresenta un punto dentro del patrón\n\n\ns\nRepresenta un espacio en blanco dentro del patrón\n\n\nn\nRepresenta un salto de línea dentro del patrón\n\n\nd\nRepresenta un dígito numérico dentro del patrón\n\n\nw\nRepresenta un carácter alfanumérico dentro del patrón\n\n\n\n\nVeamos un ejemplo con un grupo de códigos CIE10 relacionados a la hepatitis B.\nTenemos una pequeña tabla de datos con 10 códigos en la variable hepb\n\ncodigos\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nSupongamos que se encuentran insertos en una tabla de datos con otros códigos y necesitamos detectarlos para extraerlos o contarlos.\nSi las expresiones regulares no existiesen deberíamos hacer algo así:\n\ncodigos %&gt;% \n  filter(hepb ==\"B16\" | hepb &gt;= \"B160\" & hepb &lt;= \"B162\" | hepb == \"B169\" | \n         hepb == \"B170\" | hepb ==\"B178\" | hepb ==\"B180\" | hepb ==\"B181\" | \n         hepb == \"B189\")\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nEs decir, concatenar una serie de operadores y conectores lógicos OR dentro de un filtro por ejemplo para lograr su extracción.\nCon las expresiones regulares tenemos una alternativa de hacer esta tarea dividiendo el trabajo en partes y aplicar la función str_detect() de stringr.\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B16[0-2|9]?$\"))  #  selecciona el grupo B16x\n\n  hepb\n1  B16\n2 B160\n3 B161\n4 B162\n5 B169\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B17[08]$\")) # selecciona el grupo B17x\n\n  hepb\n1 B170\n2 B178\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B18[019]$\")) # selecciona el grupo B18x\n\n  hepb\n1 B180\n2 B181\n3 B189\n\n\nY finalmente unirlo con conectores OR:\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B16[0-2|9]?$|^B17[08]$|^B18[019]$\"))\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nO mejor construir una expresión regular más sintética aprovechando los metadatos adecuados.\n\ncodigos %&gt;% \n  filter(str_detect(hepb, \"^B1[6-9][0-9]?$\"))\n\n   hepb\n1   B16\n2  B160\n3  B161\n4  B162\n5  B169\n6  B170\n7  B178\n8  B180\n9  B181\n10 B189\n\n\nAdemás de la función de detección str_detect() el paquete aporta str_extract() para extraer y str_replace() para reemplazar directamente",
    "crumbs": [
      "Unidad 4: Tratamiento de datos específicos"
    ]
  },
  {
    "objectID": "unidad4.html#factores",
    "href": "unidad4.html#factores",
    "title": "Unidad 4: Tratamiento de datos específicos",
    "section": "Factores",
    "text": "Factores\n\n\n\n\nArtwork por @allison_horst\n\n\n\nLos factores son simplemente el formato de datos que R reserva para las variables categóricas y estan compuesto por valores numéricos internos asociados a etiquetas que definen cada una de los niveles (categorías o niveles definidos).\nEl paquete forcats es parte del ecosistema tidyverse pensado para trabajar con este tipo de dato.\nEn función de que las herramientas del paquete son de aplicación práctica vamos a trabajar con un conjunto de datos ficticios creados con la finalidad de mostrar la potencialidad de forcats.\n\nglimpse(datos)\n\nRows: 19\nColumns: 6\n$ Enfermedad     &lt;chr&gt; \"Si\", \"Si\", \"No\", \"Si\", \"No\", \"No\", \"No\", \"Si\", \"Si\", \"…\n$ Sexo           &lt;chr&gt; \"Varon\", \"Mujer\", \"Mujer\", \"Mujer\", \"Masculino\", \"Varon…\n$ Civil          &lt;chr&gt; \"Soltero\", \"Viudo\", \"Casado\", \"Soltero\", \"Soltero\", \"Vi…\n$ Esalud         &lt;chr&gt; \"Mala\", \"Muy mala\", \"Buena\", \"Mala\", \"Buena\", \"Buena\", …\n$ Ciudad         &lt;chr&gt; \"Mar del Plata\", \"Mar del Plata\", \"Mar del Plata\", \"Mar…\n$ Comorbilidades &lt;chr&gt; \"EPOC\", \"Gastritis\", \"aterosclerosis\", \"TBC\", \"Neumonia…\n\n\nObservamos que el objeto llamado datos tiene 6 variables de tipo caracter y 19 observaciones.\nEstas variables de caracter tienen como característica representar variables cualitativas nominales y ordinales que para su mejor tratamiento dentro del R deberían ser convertidas a factores.\nComenzamos con la primer variable (Enfermedad). La función simple y de R base que conocemos para convertirla en factor es factor().\n\ndatos &lt;- datos |&gt; \n  mutate(Enfermedad = factor(Enfermedad))\n\nlevels(datos$Enfermedad)\n\n[1] \"No\" \"Si\"\n\n\nLa función del paquete forcats para realizar la misma tarea se llama as_factor(). No agrega ninguna funcionalidad extra por lo que es indistinto utilizar una forma u otra.\nAquí la utilizamos para convertir la variable Sexo\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = as_factor(Sexo))\n\nSi queremos visualizar los niveles del factor podemos usar levels() (función de R base):\n\nlevels(datos$Sexo)\n\n[1] \"Varon\"     \"Mujer\"     \"Masculino\" \"Femenino\" \n\n\nEncontramos uno de los problemas habituales cuando trabajamos con datos reales cargados por diferentes usuarios o cuando unimos bases de diverso origen. Las categorías se encuentran etiquetadas de manera diferente aunque conceptualmente se refieran a lo mismo (ejemplo: “Femenino” - “Mujer”)\nDebemos corregir este inconveniente y para esta tarea el paquete ofrece una función que recodifica los niveles. Se llama fct_recode() y la aplicamos así:\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = fct_recode(Sexo, \n                           Varon = \"Masculino\", \n                           Mujer = \"Femenino\"))\n\nlevels(datos$Sexo)\n\n[1] \"Varon\" \"Mujer\"\n\ndatos |&gt; \n  count(Sexo)\n\n# A tibble: 2 × 2\n  Sexo      n\n  &lt;fct&gt; &lt;int&gt;\n1 Varon    10\n2 Mujer     9\n\n\nVemos en los argumentos que le indicamos que “Masculino” es igual a Varon y “Femenino” igual a Mujer. Esto provoca que en todos los casos donde aparezca “Masculino” sea reemplazado por Varon y cuando aparezcan “Femenino” se cambie por Mujer.\nFinalmente verificamos que los niveles sean los dos que necesitamos y además podemos producir un listado de frecuencias de los niveles del factor con count().\nHasta aquí tenemos las dos primeras variables convertidas y podrían ser utilizadas en un análisis posterior para construir una tabla de contingencia de Sexo vs Enfermedad.\n\nlibrary(janitor)\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo No Si\n Varon  5  5\n Mujer  3  6\n\n\nObservemos que en esta tabla el orden de los niveles de Enfermedad quizás no sea el más conveniente para tablas 2x2 y sus cálculos asociados (razones o diferencias de razones), donde se necesita que la tabla tenga una forma y orden específico para que los valores e las ecuaciones sean los correctos.\nEsta situación causa que muchas veces tengamos que reordenar las categorías de las variables cualitativas y los niveles de los factores son ideales para esto. La función encargada de esta tarea en forcats es fct_relevel() que no es muy diferente al relevel() del R base.\n\ndatos &lt;- datos |&gt; \n  mutate(Enfermedad = fct_relevel(Enfermedad, \"Si\"))\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo Si No\n Varon  5  5\n Mujer  6  3\n\n\nAplicado sobre Enfermedad observamos, luego en la tabla 2x2, que la categoría Si aparece primera como necesitamos.\nLo mismo podríamos hacer con la variable Sexo si quisieramos que el nivel de referencia fuese Mujer en lugar de Varon.\n\ndatos &lt;- datos |&gt; \n  mutate(Sexo = fct_relevel(Sexo, \"Mujer\"))\n\ndatos |&gt; \n  tabyl(Sexo, Enfermedad)\n\n  Sexo Si No\n Mujer  6  3\n Varon  5  5\n\n\nContinuamos con la siguiente variable y luego de transformarla pedimos sus niveles.\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = factor(Civil))\n\nlevels(datos$Civil)\n\n[1] \"Casado\"     \"Divorciado\" \"Soltero\"    \"Viudo\"     \n\n\nAparecen 4 niveles para la variable. Para ver la frecuencia de aparición hacemos:\n\ndatos |&gt; \n  count(Civil)\n\n# A tibble: 5 × 2\n  Civil          n\n  &lt;fct&gt;      &lt;int&gt;\n1 Casado         5\n2 Divorciado     3\n3 Soltero        7\n4 Viudo          3\n5 &lt;NA&gt;           1\n\n\nEn la frecuencia aparecen los 4 niveles más un valor faltante (NA). Estos valores habitualmente se omiten en muchas de las operaciones que realiza el lenguaje.\nPero supongamos que deseamos mostrar dentro de una tabla de frecuencia la cantidad de valores perdidos o desconocidos que tenemos de la variable Estado Civil. Deberíamos etiquetar ese NA para poder visualizarlo.\nLa función del paquete encargada de la tarea es fct_na_value_to_level()\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = fct_na_value_to_level(Civil, \n                                       level = \"Desconocido\"))\n\ndatos |&gt; \n  count(Civil)\n\n# A tibble: 5 × 2\n  Civil           n\n  &lt;fct&gt;       &lt;int&gt;\n1 Casado          5\n2 Divorciado      3\n3 Soltero         7\n4 Viudo           3\n5 Desconocido     1\n\nlevels(datos$Civil)\n\n[1] \"Casado\"      \"Divorciado\"  \"Soltero\"     \"Viudo\"       \"Desconocido\"\n\n\nPensando en poder graficar esta variable construimos un gráfico de barras sencillo.\n\ndatos |&gt; \n  ggplot(aes(x = Civil, fill = Civil)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nUna mejor presentación sería si las barras se encuentran ordenadas (de mayor a menor) por la frecuencia de cada categoría.\nPodríamos ordenar mediante arrange() (del paquete dplyr de tidyverse) pero este ordenamiento sirve solo como prosentación, es decir el nuevo orden no se guarda dentro de los niveles del factor.\nPara poder hacer usamos fct_infreq():\n\ndatos &lt;- datos |&gt; \n  mutate(Civil = fct_infreq(Civil))\n\nlevels(datos$Civil)\n\n[1] \"Soltero\"     \"Casado\"      \"Divorciado\"  \"Viudo\"       \"Desconocido\"\n\n\nAhora el gráfico nos saldría como queremos:\n\ndatos |&gt; \n  ggplot(aes(x = Civil, fill = Civil)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nSigamos con otra de las variables. En este caso Esalud que tiene el estado de salud autoreportado por las personas. Como representa una variable categórica ordinal tenemos que estar atentos al orden de las categorías que R siempre forzará a que cumpla con el alfabético.\nPodemos usar directamente fct_relevel() con los niveles completos en el orden correcto.\n\nclass(datos$Esalud)\n\n[1] \"character\"\n\ndatos &lt;- datos |&gt; \n  mutate(Esalud = fct_relevel(Esalud,\n                              \"Muy buena\",\n                              \"Buena\",\n                              \"Regular\",\n                              \"Mala\",\n                              \"Muy mala\"))\n         \nlevels(datos$Esalud)\n\n[1] \"Muy buena\" \"Buena\"     \"Regular\"   \"Mala\"      \"Muy mala\" \n\n\nObservemos que no hizo falta primero convertir en factor y luego aplicar la función de forcats. Todas las funciones comenzadas con fct_ aplicadas a un tipo caracter convertiran a factor previamente a la operación que realicen.\nEn este caso además los niveles tienen un orden lógico que comienza en “Muy buena” salud y termina en “Muy mala”. Quizás el orden necesario sea inverso y fct_rev() hace la tarea.\n\ndatos &lt;- datos |&gt; \n  mutate(Esalud = fct_rev(Esalud))\n\nlevels(datos$Esalud)\n\n[1] \"Muy mala\"  \"Mala\"      \"Regular\"   \"Buena\"     \"Muy buena\"\n\n\nFinalmente conseguimos que el factor sea ordenado y que los niveles sigan el esquema de aumentar hacia la derecha.\nLa siguiente variable es Ciudad. Veamos su contenido:\n\ndatos |&gt; \n  count(Ciudad)\n\n# A tibble: 4 × 2\n  Ciudad            n\n  &lt;chr&gt;         &lt;int&gt;\n1 Batan             1\n2 Mar del Plata    16\n3 Miramar           1\n4 Santa Clara       1\n\n\nPosee 4 etiquetas con nombres de ciudades. Su frecuencia es:\nVemos que mayoritariamente las observaciones pertenecen a Mar del Plata. Muchas veces cuando estamos frente a situaciones como esta, donde hay varias categorías con poca frecuencia, es mejor agruparlas en un “Otras/os”. Eso mismo vamos a realizar con la función fct_other().\n\ndatos &lt;- datos |&gt; \n  mutate(Ciudad = fct_other(Ciudad, \n                            keep = \"Mar del Plata\", \n                            other_level = \"Otras\"))\n\nlevels(datos$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"        \n\ndatos |&gt; \n  count(Ciudad)\n\n# A tibble: 2 × 2\n  Ciudad            n\n  &lt;fct&gt;         &lt;int&gt;\n1 Mar del Plata    16\n2 Otras             3\n\n\nLa última de las variables de la tabla de datos es Comorbilidades.\n\ndatos |&gt; \n  count(Comorbilidades)\n\n# A tibble: 7 × 2\n  Comorbilidades     n\n  &lt;chr&gt;          &lt;int&gt;\n1 EPOC               4\n2 Gastritis          2\n3 Hepatitis          2\n4 Hipertensión       2\n5 Neumonia           3\n6 TBC                4\n7 aterosclerosis     2\n\n\nSus etiquetas son 7 y se trata de enfermedades que podemos vincular a distintos grupos, es decir, que nos va a servir de excusa para probar otra función de forcats.\nLa función es fct_collapse() y permite agrupar niveles a grupos que serían las nuevas etiquetas de nivel.\nLo vamos a hacer asignando a una nueva variable (Comor_agrupadas) y generando los niveles Respiratoria, Digestiva y Circulatorio, para enfermedades respiratorias, enfermedades del aparato digestivo y enfermedades del aparato circulatorio.\n\ndatos &lt;- datos |&gt; \n  mutate(Comor_agrupadas = fct_collapse(Comorbilidades,\n                                      Respiratoria = c(\"EPOC\",\n                                                       \"TBC\", \n                                                       \"Neumonia\"),\n                                      Digestiva = c(\"Hepatitis\",\n                                                    \"Gastritis\"),\n                                      Circulatorio  = c(\"aterosclerosis\",\n                                                        \"Hipertensión\")))\n\nlevels(datos$Comor_agrupadas)\n\n[1] \"Circulatorio\" \"Respiratoria\" \"Digestiva\"   \n\ndatos |&gt; \n  count(Comor_agrupadas)\n\n# A tibble: 3 × 2\n  Comor_agrupadas     n\n  &lt;fct&gt;           &lt;int&gt;\n1 Circulatorio        4\n2 Respiratoria       11\n3 Digestiva           4\n\n\nNos quedan para ver tres funciones más del paquete presentado.\nLa primera es fct_drop() que elimina los niveles que no se utilizan. Veamosla en acción.\nTomamos el caso de una selección de la tabla original datos filtrado por las observaciones que pertenecen a Mar del Plata, guardado en otro dataframe al que llamaremos datos_MdP\n\ndatos_MdP &lt;- datos  |&gt;  \n  filter(Ciudad == \"Mar del Plata\")\n\nSi vemos sus niveles confirmaremos que heredó los que tenía la variable en el tibble original. Pero una tabla nos mostraría que no hay datos para el nivel “Otras”.\n\nlevels(datos_MdP$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"        \n\ndatos_MdP |&gt; \n  tabyl(Ciudad)\n\n        Ciudad  n percent\n Mar del Plata 16       1\n         Otras  0       0\n\n\nAquí entra en juego la función fct_drop() que aplicada a la variable Ciudad de datos_MdP produce:\n\ndatos_MdP &lt;- datos_MdP |&gt; \n  mutate(Ciudad = fct_drop(Ciudad))\n\nlevels(datos_MdP$Ciudad)\n\n[1] \"Mar del Plata\"\n\ndatos_MdP |&gt; \n  tabyl(Ciudad)\n\n        Ciudad  n percent\n Mar del Plata 16       1\n\n\nA la inversa, la función fct_expand() incorpora niveles a la lista de niveles de un factor.\nVolvemos a trabajar con el dataframe datos y vamos a asignar nuevos niveles al factor de la variable Ciudad.\n\ndatos &lt;- datos |&gt; \n  mutate(Ciudad = fct_expand(Ciudad, \"La Plata\", \n                             \"Tandil\", \n                             \"CABA\"))\n\nlevels(datos$Ciudad)\n\n[1] \"Mar del Plata\" \"Otras\"         \"La Plata\"      \"Tandil\"       \n[5] \"CABA\"         \n\n\nEsto significa que tenemos tres categorías posibles más en el factor que están disponibles para nuevas observaciones, aunque en el conjunto de datos no esten siendo utilizadas por ahora.\nPor último, la función fct_c() concatena factores combinandos niveles. Para ejemplificar su uso vamos a construir dos factores tipo vector que finalmente uniremos.\nImaginemos que tenemos que unir dos variables pertenecientes a conjuntos de datos que queremos unificar. En la variable1 hay definidos dos niveles “Corrientes” y “Posadas” y en la variable2 tres niveles “Corrientes”, “Resistencia” y “Goya”.\n\nvar1 &lt;- factor(c(\"Corrientes\",\"Corrientes\",\"Posadas\",\"Corrientes\",\n                 \"Posadas\"))\n\nvar2 &lt;- factor(c(\"Resistencia\",\"Goya\",\"Goya\",\"Resistencia\",\"Resistencia\",\n                 \"Corrientes\",\"Goya\"))\n\nvar1\n\n[1] Corrientes Corrientes Posadas    Corrientes Posadas   \nLevels: Corrientes Posadas\n\nvar2\n\n[1] Resistencia Goya        Goya        Resistencia Resistencia Corrientes \n[7] Goya       \nLevels: Corrientes Goya Resistencia\n\n\nA continuación concatenamos aplicando fct_c():\n\nvar3 &lt;- fct_c(var1, var2)\n\nvar3\n\n [1] Corrientes  Corrientes  Posadas     Corrientes  Posadas     Resistencia\n [7] Goya        Goya        Resistencia Resistencia Corrientes  Goya       \nLevels: Corrientes Posadas Goya Resistencia\n\n\nObservamos que no solo une los datos de las variables sino que respeta los niveles definidos de cada uno fusionando las categorías.",
    "crumbs": [
      "Unidad 4: Tratamiento de datos específicos"
    ]
  },
  {
    "objectID": "unidad2.html",
    "href": "unidad2.html",
    "title": "Unidad 2: Procesamiento de datos",
    "section": "",
    "text": "El paquete dplyr es parte del universo tidyverse que fue desarrollado por Hadley Wickham a partir de optimizar una versión del paquete plyr.\nLa contribución significativa del paquete es proporcionar una “gramática” (funciones-verbos) para la manipulación y operaciones de datos que lo hace más fácil de entender.\nLas funciones clave del paquete, responden a las siguientes acciones (verbos):\n\nselect(): devuelve un conjunto de columnas (variables)\nrename(): renombra variables en una conjunto de datos\nfilter(): devuelve un conjunto de filas (observaciones) según una o varias condiciones lógicas\narrange(): reordena filas de un conjunto de datos\nmutate(): añade nuevas variables/columnas o transforma variables existentes\nsummarise()/summarize(): genera resúmenes estadísticos de diferentes variables en el conjunto de datos.\ngroup_by(): agrupa un conjunto de filas seleccionado, en un conjunto de filas de resumen de acuerdo con los valores de una o más columnas o expresiones.\ncount(): contabiliza valores que se repiten, es decir genera tabla de frecuencias.\n\n\n\nTodas las funciones, básicamente, tienen en común una serie de argumentos.\n\nEl primer argumento es el nombre del conjunto de datos (objeto donde esta nuestra tabla de datos)\nLos otros argumentos describen que hacer con el conjunto de datos especificado en el primer argumento, podemos referirnos a las columnas en el objeto directamente sin utilizar el operador $, es decir sólo con el nombre de la columna/variable.\nEl valor de retorno es un nuevo conjunto de datos.\nLos conjunto de datos deben estar bien organizados/estructurados, es decir debe existir una observación por columna y, cada columna representar una variable, medida o característica de esa observación. Es decir, debe cumplir con tidy data.\n\n\n\n\ndplyr está incluído en el paquete tidyverse, por lo que se encuentra disponible si tenemos activado a este último.\nTambién se puede activar en forma independiente, aunque no es necesario si ya activamos tidyverse:\n\nlibrary(dplyr)\n\n\n\n\nVisualizar y entender el funcionamiento de estos “verbos” de manipulación es posible si ejemplificamos su aplicación. Por este motivo vamos a leer un conjunto de datos que servirá para ejercitar las funciones del paquete.\n\ndatos &lt;- read_csv(\"datos/noti-vih.csv\") # asignamos la lectura a datos\n\nhead(datos) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 CABA          2015   901  3054237\n4 CABA          2016   427  3050000\n5 Catamarca     2015    69   396552\n6 Catamarca     2016    51   401575\n\n\nLa tabla de datos “noti-vih.csv” contiene datos de notificación de vih por jurisdicción de Argentina para los años 2015 y 2016.\n\n\n\nEsta función selecciona las variables que especificamos devolviendo un conjunto de datos “recortado por columna”.\nselect() utiliza un minilenguaje conciso que facilita hacer referencia a las variables según su nombre, ubicación, condición o tipo.\nAlguno de sus operadores son:\n\n: para seleccionar un rango de variables consecutivas.\n- para evitar seleccionar la variable que sigue al signo\n! para tomar el complemento de un conjunto de variables.\n\nVeamos algunas aplicaciones de estas “ayudas” para hacer selecciones.\nTodas las variables menos pob\n\ndatos |&gt;  \n  select(-pob)\n\n# A tibble: 48 × 3\n   jurisdiccion   año casos\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513\n 2 Buenos Aires  2016   957\n 3 CABA          2015   901\n 4 CABA          2016   427\n 5 Catamarca     2015    69\n 6 Catamarca     2016    51\n 7 Chaco         2015    15\n 8 Chaco         2016     9\n 9 Chubut        2015   110\n10 Chubut        2016    89\n# ℹ 38 more rows\n\n\nOtra forma para el mismo resultado anterior (mediante el operador rango :)\n\ndatos |&gt;  \n  select(jurisdiccion:casos)\n\n# A tibble: 48 × 3\n   jurisdiccion   año casos\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513\n 2 Buenos Aires  2016   957\n 3 CABA          2015   901\n 4 CABA          2016   427\n 5 Catamarca     2015    69\n 6 Catamarca     2016    51\n 7 Chaco         2015    15\n 8 Chaco         2016     9\n 9 Chubut        2015   110\n10 Chubut        2016    89\n# ℹ 38 more rows\n\n\nLas variables jurisdiccion y casos\n\ndatos |&gt;  \n  select(jurisdiccion, casos)\n\n# A tibble: 48 × 2\n   jurisdiccion casos\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Buenos Aires  1513\n 2 Buenos Aires   957\n 3 CABA           901\n 4 CABA           427\n 5 Catamarca       69\n 6 Catamarca       51\n 7 Chaco           15\n 8 Chaco            9\n 9 Chubut         110\n10 Chubut          89\n# ℹ 38 more rows\n\n\nOtra forma para el mismo resultado anterior (mediante números de columna):\n\ndatos |&gt;  \n  select(1, 3)\n\n# A tibble: 48 × 2\n   jurisdiccion casos\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Buenos Aires  1513\n 2 Buenos Aires   957\n 3 CABA           901\n 4 CABA           427\n 5 Catamarca       69\n 6 Catamarca       51\n 7 Chaco           15\n 8 Chaco            9\n 9 Chubut         110\n10 Chubut          89\n# ℹ 38 more rows\n\n\nTodas las variables pasando año a la primera columna\n\ndatos |&gt;  \n  select(\"año\", everything())\n\n# A tibble: 48 × 4\n     año jurisdiccion casos      pob\n   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  2015 Buenos Aires  1513 16626374\n 2  2016 Buenos Aires   957 16789474\n 3  2015 CABA           901  3054237\n 4  2016 CABA           427  3050000\n 5  2015 Catamarca       69   396552\n 6  2016 Catamarca       51   401575\n 7  2015 Chaco           15  1153846\n 8  2016 Chaco            9  1125000\n 9  2015 Chubut         110   567010\n10  2016 Chubut          89   577922\n# ℹ 38 more rows\n\n\nEsta última función everything(), pasada como argumento, es una de las posibles funciones llamadas “ayudantes de selección”, entre las cuales se encuentra:\n\nstarts_with(): selecciona todas las columnas que comiencen con el patrón indicado.\nends_with(): selecciona todas las columnas que terminen con el patrón indicado.\ncontains(): selecciona las columnas que posean el patrón indicado.\nmatches(): similar a contains(), pero permite poner una expresión regular.\nall_of(): selecciona las variables pasadas en un vector (todos los nombres deben estar presentes o devuelve un error)\nany_of(): idem anterior excepto que no se genera ningún error para los nombres que no existen.\nnum_range(): selecciona variables con nombre combinados con caracteres y números (ejemplo: num_range(“x”, 1:3) selecciona las variables x1, x2 y x3.\nwhere(): aplica una función a todas las variables y selecciona aquellas para las cuales la función regresa TRUE (por ejemplo: is.numeric() para seleccionar todas las variables numéricas)\ngroup_cols(): selecciona todas las columnas de agrupación.\n\nTodas estas funciones son muy útiles a la hora de seleccionar el conjunto de variables necesarias no solo para un select() básico sino también cuando necesitemos aplicar operaciones simultáneas y/o pivotear tablas de datos que necesiten garantizar formato ordenado (tidy-data).\n\n\n\nEsta función es una extensión de select(), dado que esta última permite cambiar el nombre de variables pero no es muy útil porque descarta todas las variables que no se mencionan explícitamente. En cambio rename() renombra variables mientras que mantiene las demás no mencionadas.\nPor ejemplo, cambiamos el nombre de la variable pob por población.\n\ndatos |&gt; \n  rename(\"población\" = pob)\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos población\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 Buenos Aires  2015  1513  16626374\n 2 Buenos Aires  2016   957  16789474\n 3 CABA          2015   901   3054237\n 4 CABA          2016   427   3050000\n 5 Catamarca     2015    69    396552\n 6 Catamarca     2016    51    401575\n 7 Chaco         2015    15   1153846\n 8 Chaco         2016     9   1125000\n 9 Chubut        2015   110    567010\n10 Chubut        2016    89    577922\n# ℹ 38 more rows\n\n\n\n\n\nAsí como la función select() es utilizada para seleccionar columnas, la función filter() hace lo propio con las filas del conjunto de datos, produciendo un subconjunto de observaciones.\nVeamos un ejemplo sencillo sobre nuestros datos:\n\ndatos |&gt; \n  filter(jurisdiccion == \"Tucuman\")\n\n# A tibble: 2 × 4\n  jurisdiccion   año casos     pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Tucuman       2015   258 1592593\n2 Tucuman       2016   246 1618421\n\n\nUtiliza los mismos operadores de comparación propios del lenguaje R\n\n\n\nComparación\n\n\n\n\n\n&lt;\nmenor a\n\n\n&gt;\nmayor a\n\n\n==\nigual a\n\n\n&lt;=\nmenor o igual a\n\n\n&gt;=\nmayor o igual a\n\n\n!=\nno igual a\n\n\n%in%\nes parte de\n\n\nis.na\nes NA\n\n\n!is.na\nno es NA\n\n\n\nLo mismo con los operadores lógicos que se utilizan como conectores entre las expresiones.\n\n\n\nLógicos\n\n\n\n\n\n&\nAND booleano\n\n\n|\nOR booleano\n\n\nxor\nOR exclusivo\n\n\n!\nNOT\n\n\nany\ncualquier TRUE\n\n\nall\ntodos TRUE\n\n\n\nCuando usamos múltiples argumentos separados por coma dentro de filter() se combinan con un conector AND, es decir cada expresión debe ser verdadera para que una fila sea incluida en la salida.\nPor ejemplo:\nFiltramos a las observaciones que cumplan con la condición que casos sea mayor a 100 y población sea menor a 1000000\n\ndatos |&gt; \n  filter(casos &gt; 100, pob &lt; 1000000)\n\n# A tibble: 7 × 4\n  jurisdiccion   año casos    pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Chubut        2015   110 567010\n2 Jujuy         2015   160 727273\n3 Jujuy         2016   133 734807\n4 Neuquen       2015   109 619318\n5 Neuquen       2016   101 627329\n6 Rio Negro     2015   112 700000\n7 Rio Negro     2016   105 709459\n\n\nPara combinaciones dentro de una misma variable debemos utilizar el conector OR (|) o más útil el operador %in%.\nFiltramos a las jurisdicciones “Buenos Aires” y “La Pampa”\n\ndatos |&gt; \n  filter(jurisdiccion == \"Buenos Aires\" | jurisdiccion == \"La Pampa\")\n\n# A tibble: 4 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 La Pampa      2015    57   343373\n4 La Pampa      2016    67   345361\n\n\n\ndatos |&gt; \n  filter(jurisdiccion %in% c(\"Buenos Aires\", \"La Pampa\"))\n\n# A tibble: 4 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 La Pampa      2015    57   343373\n4 La Pampa      2016    67   345361\n\n\nFiltramos las observaciones de 2016 con casos mayores a 200 utilizando el conector AND (&). Es el mismo resultado que si utilizamos una coma.\n\ndatos |&gt; \n  filter(año == \"2016\" & casos &gt; 200)\n\n# A tibble: 6 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2016   957 16789474\n2 CABA          2016   427  3050000\n3 Cordoba       2016   368  3607843\n4 Mendoza       2016   254  1909774\n5 Salta         2016   230  1352941\n6 Tucuman       2016   246  1618421\n\n\nFiltramos las observaciones inversas a la anterior mediante xor(), que selecciona los valores de año y casos exclusivos (es decir que no se den ambos en TRUE).\n\ndatos |&gt; \n  filter(xor(año == \"2016\", casos &gt; 200))\n\n# A tibble: 25 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374\n 2 CABA          2015   901  3054237\n 3 Catamarca     2016    51   401575\n 4 Chaco         2016     9  1125000\n 5 Chubut        2016    89   577922\n 6 Cordoba       2015   468  3572519\n 7 Corrientes    2016    99  1076087\n 8 Entre Rios    2016   109  1329268\n 9 Formosa       2016    60   582524\n10 Jujuy         2016   133   734807\n# ℹ 15 more rows\n\n\n\n\n\nLa función arrange() se utiliza para ordenar las filas de un conjunto de datos de acuerdo a una o varias columnas/variables. Por defecto, el ordenamiento es ascendente alfanumérico.\nOrdenamos la tabla datos por la variable pob (forma ascendente predeterminada):\n\ndatos |&gt; \n  arrange(pob)\n\n# A tibble: 48 × 4\n   jurisdiccion       año casos    pob\n   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Tierra del Fuego  2015    36 152542\n 2 Tierra del Fuego  2016    34 156682\n 3 Santa Cruz        2015    65 320197\n 4 Santa Cruz        2016    59 329609\n 5 La Pampa          2015    57 343373\n 6 La Pampa          2016    67 345361\n 7 La Rioja          2015    41 369369\n 8 La Rioja          2016     6 375000\n 9 Catamarca         2015    69 396552\n10 Catamarca         2016    51 401575\n# ℹ 38 more rows\n\n\nPara ordenar en forma descendente podemos utilizar desc() dentro de los argumentos de arrange():\n\ndatos |&gt; \n  arrange(desc(pob))\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2016   957 16789474\n 2 Buenos Aires  2015  1513 16626374\n 3 Cordoba       2016   368  3607843\n 4 Cordoba       2015   468  3572519\n 5 Santa Fe      2016   170  3400000\n 6 Santa Fe      2015   301  3382022\n 7 CABA          2015   901  3054237\n 8 CABA          2016   427  3050000\n 9 Mendoza       2016   254  1909774\n10 Mendoza       2015   316  1880952\n# ℹ 38 more rows\n\n\nPodemos combinar ordenamientos. Por ejemplo, en forma alfabética ascendente para jusrisdiccion y luego numérica descendente para casos.\n\ndatos |&gt; \n  arrange(jurisdiccion, desc(casos))\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374\n 2 Buenos Aires  2016   957 16789474\n 3 CABA          2015   901  3054237\n 4 CABA          2016   427  3050000\n 5 Catamarca     2015    69   396552\n 6 Catamarca     2016    51   401575\n 7 Chaco         2015    15  1153846\n 8 Chaco         2016     9  1125000\n 9 Chubut        2015   110   567010\n10 Chubut        2016    89   577922\n# ℹ 38 more rows\n\n\n\n\n\nEsta función nos proporciona computar tranformaciones de variables en un conjunto de datos. A menudo, tendremos la necesidad de modificar variables existentes o crear nuevas variables que se calculan a partir de las que tenemos, mutate() nos ofrece una interface clara para realizar este tipo de operaciones.\nPor ejemplo, nos puede interesar calcular tasas crudas para cada jurisdicción y año, en función de los casos y el total de población.\n\ndatos |&gt; \n  mutate(tasa = casos/pob*100000)\n\n# A tibble: 48 × 5\n   jurisdiccion   año casos      pob  tasa\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374  9.10\n 2 Buenos Aires  2016   957 16789474  5.70\n 3 CABA          2015   901  3054237 29.5 \n 4 CABA          2016   427  3050000 14   \n 5 Catamarca     2015    69   396552 17.4 \n 6 Catamarca     2016    51   401575 12.7 \n 7 Chaco         2015    15  1153846  1.30\n 8 Chaco         2016     9  1125000  0.8 \n 9 Chubut        2015   110   567010 19.4 \n10 Chubut        2016    89   577922 15.4 \n# ℹ 38 more rows\n\n\nObservemos que la función realiza el cálculo (en este caso tasas crudas por 100000 habitantes) e incorpora una nueva variable por cada observación con el resultado.\nTambién se pueden construir múltiples variables en la misma expresión, solamente separadas por comas.\n\ndatos |&gt; \n  mutate(tasaxcien_mil = casos/pob*100000, \n         tasaxdiez_mil = casos/pob*10000)\n\n# A tibble: 48 × 6\n   jurisdiccion   año casos      pob tasaxcien_mil tasaxdiez_mil\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374          9.10         0.910\n 2 Buenos Aires  2016   957 16789474          5.70         0.570\n 3 CABA          2015   901  3054237         29.5          2.95 \n 4 CABA          2016   427  3050000         14            1.4  \n 5 Catamarca     2015    69   396552         17.4          1.74 \n 6 Catamarca     2016    51   401575         12.7          1.27 \n 7 Chaco         2015    15  1153846          1.30         0.130\n 8 Chaco         2016     9  1125000          0.8          0.08 \n 9 Chubut        2015   110   567010         19.4          1.94 \n10 Chubut        2016    89   577922         15.4          1.54 \n# ℹ 38 more rows\n\n\nSi necesitemos que estas dos nuevas variables queden dentro de la tabla de datos y no solo mostrarla en consola como hasta ahora, debemos utilizar el operador de asignación:\n\ndatos &lt;- datos |&gt; \n  mutate(tasaxcien_mil = casos/pob*100000, \n         tasaxdiez_mil = casos/pob*10000)\n\nLa propiedad imprescindible es que la función debe poder vectorizar: debe tomar un vector de valores como entrada, y devolver un vector con el mismo número de valores que la salida.\nNo hay forma de enumerar todas las funciones posibles que se podría usar, pero mencionaremos algunas que pueden ser útiles:\n\nOperadores aritméticos: +, -, *, /, ^.\nAritmética modular: %/% (división entera) y %% (resto), donde \\(x == y * (x \\ \\%/\\% \\ y) + (x\\ \\%\\% \\ y)\\). La aritmética modular es una herramienta útil porque te permite dividir números enteros en porciones.\nFunciones matemáticas: log(), log2(), log10(), exp(), sqrt(), abs(), etc\nValores acumulados: R proporciona funciones para ejecutar sumas, productos, mínimos y máximos acumulados: cumsum(), cumprod(), cummin(), cummax(); y dplyr proporciona cummean() para promedios acumulados.\nClasificaciones (ranking): hay una serie de funciones de clasificación, por ejemplo min_rank(). Genera el tipo de clasificación habitual (1º, 2º, etc). El valor predeterminado relaciona los valores más pequeños a rangos pequeños; podemos usar desc(x) para invertir la relación (valores más grandes a rangos más pequeños)\n\nSi utilizamos el mismo nombre de una variable incluída dentro de la tabla de datos, estaremos sobrescribiendola (se usa cuando transformamos una variable, por ejemplo: le cambiamos su tipo de character a factor). Para que la variable sea nueva debe nombrarse con un nombre que no exista previamente dentro de la tabla de datos.\n\n\n\nDentro un mutate(), algunas veces vamos a necesitar agrupar, agregar o discretizar variables continuas donde generemos variables dicotómicas o politómicas.\nEstas funciones que llamaremos “condicionales”, dado que utilizan condiciones para decidir que valor tomar, no se limitan a la tarea de construir agrupamientos de variables cuantitativas sino que sirven para cualquier situación donde a partir de una o más condiciones se produzcan una o más valores como respuesta.\n\n\nPara salidas dicotómicas tenemos la función condicional if_else() derivada de la simplificación del IF condicional que existe en todos los lenguajes de programación.\nSupongamos que creamos una nueva variable dentro del dataframe datos que se llama variable_nueva de tipo cualitativa y queremos que la misma tome valores a partir del cumplimiento de una condición de una variable cuantitativa existente denominada var1.\nSi los valores de var1 son mayores a 10, entonces variable_nueva, tomará el valor “mayor a 10”, en caso contrario, tomará el valor “menor o igual a 10”\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"mayor a 10\", \n                                  false = \"menor o igual a 10\"))\n\nif_else() tiene tres argumentos obligatorios, el primero siempre es una condición, el segundo y el tercero son los valores que tomará la nueva variable si esa condición se cumple o no se cumple.\nHabitualmente decimos que en este proceso dicotomizamos una variable, dado que el resultado posible consta siempre de 2 valores.\nLos valores de salida de esta función pueden ser de variado tipo (caracter, numerico o logico) aunque si estamos discretizando una variable cuantitativa generalmente construimos una variable resultado cualitativa ordinal. Es común que esta variable salida sea tipo character (observar que las nuevas categorías van encerradas entre comillas).\nAhora bien, al ser ordinal estas categorías de la variable_nueva deben “ordenarse” en la forma de los valores de la variable, pero el lenguaje R no sabe con que estamos trabajando y respeta siempre el ordenamiento alfanumérico. Por lo tanto, en este ejemplo las categorías se van a estar ordenando al reves del orden numérico natural (de menor a mayor).\n“mayor a 10” se ordena alfabéticamente antes de “menor o igual a 10”, porque luego del empate de las letras m, le siguen la a en el primer caso y la e en el segundo.\nPara ordenar estas categorías debemos transformar la variable de caracter a factor. Esto se puede hacer en un solo paso dentro del mutate:\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"mayor a 10\", \n                                   false = \"menor o igual a 10\"),\n         variable_nueva = factor(variable_nueva, \n                                 levels = c(\"menor o igual a 10\",\n                                            \"mayor a 10\")))\n\nOtra forma más artesanal, igualmente válido, es “forzar” el ordenamiento con las categorías así:\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"2.mayor a 10\", \n                                  false = \"1.menor o igual a 10\"))\n\nAquí agregamos números iniciales a las etiquetas de las categorías para darle el orden que deseamos, sin necesidad de convertir a factor.\n\n\n\nEn salidas politómicas a partir de variables cuantitativas tenemos varias opciones dependiendo de si los intervalos de clase a construir son regulares o irregulares.\n\n\n\ntidyverse ofrece la función cut_interval() para la creación de intervalos regulares.\nEs una adptación de la función cut() de R base para tidy data y sus argumentos son similares.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = cut_interval(x = var1, \n                                  length = 10,\n                                  right = T,\n                                  labels = T,\n                                  ordered_result = F))\n\nLos argumentos obligatorios y opcionales de la función cut() son:\n\nx: [obligatorio] El conjunto de datos numéricos de entrada (variable cuantitativa continua)\nlength: [obligatorio] la longitud de cada intervalo regular\nright: [opcional] Indica si los intervalos son cerrados a la derecha o viceversa. Por defecto vale TRUE (cerrados a derecha)\nlabels: [opcional] Etiquetas de los intervalos automáticas o numéricas. Valor predeterminado TRUE (intervalos matemáticos)\nordered_result: [opcional] - determina si el resultado es un factor ordenado. Por defecto vale FALSE (la salida es tipo caracter)\n\nLos argumentos opcionales no son necesarios definirlos siempre y cuando los valores por defecto son los que sirven para la tarea.\n\n\n\nCuando las condiciones no son simples, es decir, el resultado no es dicotómico y además los intervalos son irregulares, utilizamos la función case_when() que es una vectorización de la función if_else().\nSupongamos que no queremos agrupar la variable en dos valores, sino en 3 grupos irregulares.\nEsquema básico de funcionamiento:\n\n# var1 es una variable cuantitativa de números enteros \n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n    var1 &gt;= 0 & var1 &lt; 25  ~  \"Grupo1\", \n    var1 &gt; 24 & var1 &lt; 65  ~    \"Grupo 2\", \n    var1 &gt;= 65             ~    \"Grupo 3\"))\n\nExiste una condición por cada grupo creado, como si fuese un if_else() donde el valor declarado siempre es el verdadero. Se utilizan operadores de comparación como mayor ( &gt; ), menor ( &lt; ) y/o igual ( = ) y conectores lógicos como & ( AND ). En cada línea va una virgulilla similar a la usada en la sintaxis formula ( ~ ) y luego la etiqueta que tomarán las observaciones que cumplan con esa condición en la nueva variable (grupo_var).\nEsta evaluación es secuencial y su funcionamiento provoca que el usuario del lenguaje tenga el control de lo que esta sucediendo, por lo que cualquier mala definición de las condiciones puede provocar resultados incorrectos.\nSi incorporamos el argumento .default podemos indicar que valor toma si no se cumple ninguna de las condiciones anteriores.\nPor ejemplo, podríamos tener algun valor perdido (NA) en var1 y queremos que la variable grupo_var etiquete esos valores perdidos como “Sin dato”:\n\n# var1 es una variable cuantitativa de números enteros con algun valor NA\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n        var1 &gt;= 0 & var1 &lt; 25  ~  \"Grupo1\", \n        var1 &gt; 24 & var1 &lt; 65  ~    \"Grupo 2\", \n        var1 &gt;= 65             ~    \"Grupo 3\",\n        .default = \"Sin dato\"))\n\nLas salidas son de tipo carácter (chr) y debemos manejar el ordenamiento de las etiquetas como vimos anteriormente, por medio de factores o comenzando con caracteres ordenados alfabeticamente.\nPara simplificar el trabajo de estos intervalos de clase irregulares y no provocar errores en la confección de las condiciones, tidyverse tiene a la función between().\n\n\n\nBáicamente opera como un atajo para condiciones de intervalos. Define dentro de los argumentos los límites inferior y superior de un intervalo y se utiliza dentro de una función de condición tipo if_else() o case_when().\nAplicado sobre el ejemplo anterior se vería así:\n\n# var1 es una variable cuantitativa de números enteros con algun valor NA\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n    between(var1, 0, 24)   ~  \"Grupo1\", \n        between(var1, 25, 64)  ~    \"Grupo 2\", \n        between(var1, 65, Inf) ~    \"Grupo 3\",\n        .default = \"Sin dato\"))\n\nLos valores declarados como límites quedan incluídos siempre dentro del intervalo (son cerrados ambos). También podemos utilizar valores reservados como Inf o -Inf cuando desconocemos con que valor máximo o mínimo nos vamos a encontrar en la variable cuantitativa original.\n\n\n\nTomemos un caso clásico como la variable edad medida en años, variable que generalmente tenemos en toda tabla de datos vinculada a personas. En este ejemplo la variable tiene 106 observaciones.\nUna posibilidad es dicotomizarla usando el valor de la mediana que divide 2 dos partes toda la distribución.\n\ndatos |&gt; \n  summarise(mediana = median(edad))\n\n# A tibble: 1 × 1\n  mediana\n    &lt;dbl&gt;\n1      56\n\n\nAplicando el valor 56 dentro de un if_else podriamos hacer:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"mayor a la mediana\", \n                                  false = \"menor o igual a la mediana\"))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                    n\n  &lt;chr&gt;                      &lt;int&gt;\n1 mayor a la mediana            52\n2 menor o igual a la mediana    54\n\n\nObservamos en el conteo que grupo_edad1 se construyó adecuadamente pero el orden de los niveles no es correcto si queremos que siga el ordenamiento natural de edad (de menor a mayor).\nUna de las formas que vimos es convertir a factor:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"mayor a la mediana\", \n                                  false = \"menor o igual a la mediana\"),\n         grupo_edad1 = factor(grupo_edad1, \n                                 levels = c(\"menor o igual a la mediana\",\n                                            \"mayor a la mediana\")))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                    n\n  &lt;fct&gt;                      &lt;int&gt;\n1 menor o igual a la mediana    54\n2 mayor a la mediana            52\n\n\nVemos que en el conteo el formato de la variable ya no es chr sino fct y el orden de las etiquetas siguen la forma “menor a mayor”.\nOtra forma es:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"2.mayor a la mediana\", \n                                  false = \"1.menor o igual a la mediana\"))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                      n\n  &lt;chr&gt;                        &lt;int&gt;\n1 1.menor o igual a la mediana    54\n2 2.mayor a la mediana            52\n\n\nSi en cambio necesitamos que los grupos sean mas de dos y que estos intervalos de clase sean regulares, podemos usar cut_interval\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;fct&gt;       &lt;int&gt;\n1 [0,10]          3\n2 (10,20]         3\n3 (20,30]         2\n4 (30,40]         3\n5 (40,50]        13\n6 (50,60]        52\n7 (60,70]        27\n8 (70,80]         3\n\n\nLa salida muestra 8 grupos etarios con etiquetas ordenadas con notación matemática, donde un corchete indica que el límite del intervalo es cerrado, es decir contiene el valor y un paréntesis es abierto y no lo hace.Así es que el primer grupo va de 0 a 10 años y el segundo de 11 a 20.\nEstos sucede así porque en forma predeterminada el argumento right está en TRUE. Veamos que pasa si lo cambiamos a FALSE:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    right = F))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;fct&gt;       &lt;int&gt;\n1 [0,10)          3\n2 [10,20)         3\n3 [20,30)         2\n4 [30,40)         3\n5 [40,50)        10\n6 [50,60)        48\n7 [60,70)        32\n8 [70,80]         5\n\n\nEn esta salida el primer grupo va de 0 a 9 y el segundo de 10 a 19.\nHasta ahora la variable grupo_edad2 es de tipo caracter, pero si deseamos que la salida sea factor podemos incorporar el argumento ordered_result en TRUE.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    ordered_result = T))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;ord&gt;       &lt;int&gt;\n1 [0,10]          3\n2 (10,20]         3\n3 (20,30]         2\n4 (30,40]         3\n5 (40,50]        13\n6 (50,60]        52\n7 (60,70]        27\n8 (70,80]         3\n\n\nConstruimos así una variable factor ordenada .\nPor último, con el argumento labels en FALSE hacemos que las etiquetas de los 8 grupos sean numéricas.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    labels = F))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n        &lt;int&gt; &lt;int&gt;\n1           1     3\n2           2     3\n3           3     2\n4           4     3\n5           5    13\n6           6    52\n7           7    27\n8           8     3\n\n\nOtro ejemplo, podría ser aplicando case_when() donde discretizamos la edad en 4 grupos irregulares, forzando sus etiquetas para lograr el orden adecuado.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo3 = case_when(\n    edad &lt; 13              ~ \"1.Niño\",\n    edad &gt; 12 & edad &lt; 26  ~ \"2.Adolescente\",\n    edad &gt; 25 & edad &lt; 65  ~ \"3.Adulto_joven\",\n    edad &gt; 64              ~ \"4.Adulto_mayor\"\n  ))\n\ndatos |&gt; \n  count(grupo3)   \n\n# A tibble: 4 × 2\n  grupo3             n\n  &lt;chr&gt;          &lt;int&gt;\n1 1.Niño             3\n2 2.Adolescente      5\n3 3.Adulto_joven    86\n4 4.Adulto_mayor    12\n\n\nSi no hubiesemos etiquetado con los numeros por delante el orden alfabético hacía que Niño fuese a parar al final del conteo.\nDe la misma forma pero más sencillo y controlado es:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo3 = case_when(\n    between(edad, 0, 12)   ~ \"1.Niño\",\n    between(edad, 13, 25)  ~ \"2.Adolescente\",\n    between(edad, 26, 64)  ~ \"3.Adulto_joven\",\n    between(edad, 65, Inf) ~ \"4.Adulto_mayor\"\n  ))\n\ndatos |&gt; \n  count(grupo3)  \n\n# A tibble: 4 × 2\n  grupo3             n\n  &lt;chr&gt;          &lt;int&gt;\n1 1.Niño             3\n2 2.Adolescente      5\n3 3.Adulto_joven    86\n4 4.Adulto_mayor    12\n\n\n\n\n\n\nLa función summarise() (se puede escribir también summarize()) resume variables de un conjunto de datos.\n\ndatos |&gt; \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos))\n\n# A tibble: 1 × 2\n  promedio_casos casos_totales\n           &lt;dbl&gt;         &lt;dbl&gt;\n1           192.          9211\n\n\nSu uso es muy interesante cuando la combinamos con group_by() (función que detallaremos luego). Esta situación permite estratificar los resultados por grupos específicos.\nPor ejemplo, podemos agrupar el por año y simultáneamente aplicar el mismo summarise() anterior.\n\ndatos |&gt;  \n  group_by(año) |&gt;  \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos))\n\n# A tibble: 2 × 3\n    año promedio_casos casos_totales\n  &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1  2015           224.          5369\n2  2016           160.          3842\n\n\nEl resultado es una tabla con dos filas, una para cada grupo (año 2015 y año 2016) con los valores promedio y casos totales respectivos.\nAlgunas de las funciones del R base que se pueden utilizar dentro de los argumentos de esta función son:\n\nmin() mínimo\nmax() máximo\nmean() media\nmedian() mediana\nvar() varianza\nsd() desvío\nsum() sumatoria\n\nOtras funciones que se pueden incorporar las provee el mismo paquete dplyr, por ejemplo:\n\nfirst() primer valor en el vector\nlast() último valor en el vector\nn() número de valores en el vector\nn_distinct() números de valores distintos en el vector\n\nDesde la versión 1.4.0 de dplyr la función summarise() incorpora un nuevo argumento para agrupamientos temporales. El argumento .by = trabaja igual que un group_by() previo pero lo hace solo para realizar el calculo definido dentro del resumen evitando que el dataframe de salida mantenga el agrupamiento.\nLa estructura básica de la función actualizada es:\n\ndatos |&gt; \n  summarise(\n    var_resumen = funcion(var),\n    .by = var_grupo\n  )\n\nAplicada en el ejemplo previo:\n\ndatos |&gt;  \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos),\n            .by = año)\n\n# A tibble: 2 × 3\n    año promedio_casos casos_totales\n  &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1  2015           224.          5369\n2  2016           160.          3842\n\n\n\n\n\nDecíamos recién que la función group_by() es útil cuando trabaja conjuntamente con summarise() dado que agrupa un conjunto de filas seleccionado en un conjunto de filas de resumen de acuerdo con los valores de una o más columnas o expresiones.\nPara ejemplificar su trabajo asociado obtendremos una nueva tabla con el cálculo de las tasas crudas para cada jurisdicción por año (similar al ejemplo de la aplicación de mutate():\n\ndatos |&gt; \n  group_by(jurisdiccion, año) |&gt;  \n  summarise(tasa = casos/pob*100000)\n\n# A tibble: 48 × 3\n# Groups:   jurisdiccion [24]\n   jurisdiccion   año  tasa\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  9.10\n 2 Buenos Aires  2016  5.70\n 3 CABA          2015 29.5 \n 4 CABA          2016 14   \n 5 Catamarca     2015 17.4 \n 6 Catamarca     2016 12.7 \n 7 Chaco         2015  1.30\n 8 Chaco         2016  0.8 \n 9 Chubut        2015 19.4 \n10 Chubut        2016 15.4 \n# ℹ 38 more rows\n\n\nEn la mayoría de estos ejemplos la salida es directa, es decir no construimos nuevos objetos contenedores de los datos producidos y vemos los resultados en consola o en el visualizador de RStudio. Pero en muchas situaciones vamos a necesitar generar nuevos conjunto de datos con las transformaciones realizadas. Si en alguna de estas ocasiones llegamos a agrupar datos mediante group_by() y posteriormente necesitamos volver a tener la información desagrupada existe una función vinculada denominada ungroup() que vamos a necesitar aplicar o bien si no se desea tener el agrupamiento de forma fija se puede usar el argumento .by = del summarise() como mostramos anteriormente.\n\n\n\nEn los ejemplos anteriores vimos como se van integrando alguna de las funciones mediante el uso de la tubería %&gt;% o |&gt;. La idea detrás de la búsqueda gramatical del paquete es poder enlazar las acciones para construir oraciones más complejas.\nUn ejemplo que podría integrar gran parte de los visto sería:\nObtener una nueva tabla con las tasas crudas de casos notificados de VIH, por año y jurisdicción, mayores a 20 x 100000 habitantes ordenadas de mayor a menor.\n\ndatos |&gt;                                   # siempre partimos de los datos\n  group_by(año, jurisdiccion) |&gt;           # agrupamos\n  summarise(tasa = casos/pob*100000) |&gt;    # resumimos\n  filter(tasa &gt; 20) |&gt;                     # filtramos\n  arrange(desc(tasa))                       # ordenamos   \n\n# A tibble: 5 × 3\n# Groups:   año [2]\n    año jurisdiccion      tasa\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1  2015 CABA              29.5\n2  2015 Tierra del Fuego  23.6\n3  2015 Jujuy             22.0\n4  2016 Tierra del Fuego  21.7\n5  2015 Santa Cruz        20.3\n\n\nObservemos que una buena manera de construir el código es respetar un salto de línea para cada término de la oración para una lectura más clara.\nDemostramos así la potencialidad que tienen estas funciones combinadas donde en esta situación integramos las funciones group_by(), summarise() , filter() y arrange() en una misma operación.\n\n\n\nEsta última función que presentamos permite contar rápidamente los valores únicos de una o más variables.\nProduce fácilmente tablas de frecuencias absolutas que luego posibilitan construir frecuencias relativas.\nLa aplicamos sobre la variable jurisdiccion de datos\n\ndatos |&gt; \n  count(jurisdiccion)\n\n# A tibble: 24 × 2\n   jurisdiccion     n\n   &lt;chr&gt;        &lt;int&gt;\n 1 Buenos Aires     2\n 2 CABA             2\n 3 Catamarca        2\n 4 Chaco            2\n 5 Chubut           2\n 6 Cordoba          2\n 7 Corrientes       2\n 8 Entre Rios       2\n 9 Formosa          2\n10 Jujuy            2\n# ℹ 14 more rows\n\n\nTiene un par de argumentos opcionales:\n\nname: es el nombre de la columna con el conteo. Por defecto se llama n\nsort: ordena la tabla de frecuencia de mayor a menor\nwt: se puede opcionalmente incorporar una variable con la ponderación (factor de expansión) para el calculo de la frecuencia.",
    "crumbs": [
      "Unidad 2: Procesamiento de datos"
    ]
  },
  {
    "objectID": "unidad2.html#gestión-de-datos-con-el-paquete-dplyr",
    "href": "unidad2.html#gestión-de-datos-con-el-paquete-dplyr",
    "title": "Unidad 2: Procesamiento de datos",
    "section": "",
    "text": "El paquete dplyr es parte del universo tidyverse que fue desarrollado por Hadley Wickham a partir de optimizar una versión del paquete plyr.\nLa contribución significativa del paquete es proporcionar una “gramática” (funciones-verbos) para la manipulación y operaciones de datos que lo hace más fácil de entender.\nLas funciones clave del paquete, responden a las siguientes acciones (verbos):\n\nselect(): devuelve un conjunto de columnas (variables)\nrename(): renombra variables en una conjunto de datos\nfilter(): devuelve un conjunto de filas (observaciones) según una o varias condiciones lógicas\narrange(): reordena filas de un conjunto de datos\nmutate(): añade nuevas variables/columnas o transforma variables existentes\nsummarise()/summarize(): genera resúmenes estadísticos de diferentes variables en el conjunto de datos.\ngroup_by(): agrupa un conjunto de filas seleccionado, en un conjunto de filas de resumen de acuerdo con los valores de una o más columnas o expresiones.\ncount(): contabiliza valores que se repiten, es decir genera tabla de frecuencias.\n\n\n\nTodas las funciones, básicamente, tienen en común una serie de argumentos.\n\nEl primer argumento es el nombre del conjunto de datos (objeto donde esta nuestra tabla de datos)\nLos otros argumentos describen que hacer con el conjunto de datos especificado en el primer argumento, podemos referirnos a las columnas en el objeto directamente sin utilizar el operador $, es decir sólo con el nombre de la columna/variable.\nEl valor de retorno es un nuevo conjunto de datos.\nLos conjunto de datos deben estar bien organizados/estructurados, es decir debe existir una observación por columna y, cada columna representar una variable, medida o característica de esa observación. Es decir, debe cumplir con tidy data.\n\n\n\n\ndplyr está incluído en el paquete tidyverse, por lo que se encuentra disponible si tenemos activado a este último.\nTambién se puede activar en forma independiente, aunque no es necesario si ya activamos tidyverse:\n\nlibrary(dplyr)\n\n\n\n\nVisualizar y entender el funcionamiento de estos “verbos” de manipulación es posible si ejemplificamos su aplicación. Por este motivo vamos a leer un conjunto de datos que servirá para ejercitar las funciones del paquete.\n\ndatos &lt;- read_csv(\"datos/noti-vih.csv\") # asignamos la lectura a datos\n\nhead(datos) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 CABA          2015   901  3054237\n4 CABA          2016   427  3050000\n5 Catamarca     2015    69   396552\n6 Catamarca     2016    51   401575\n\n\nLa tabla de datos “noti-vih.csv” contiene datos de notificación de vih por jurisdicción de Argentina para los años 2015 y 2016.\n\n\n\nEsta función selecciona las variables que especificamos devolviendo un conjunto de datos “recortado por columna”.\nselect() utiliza un minilenguaje conciso que facilita hacer referencia a las variables según su nombre, ubicación, condición o tipo.\nAlguno de sus operadores son:\n\n: para seleccionar un rango de variables consecutivas.\n- para evitar seleccionar la variable que sigue al signo\n! para tomar el complemento de un conjunto de variables.\n\nVeamos algunas aplicaciones de estas “ayudas” para hacer selecciones.\nTodas las variables menos pob\n\ndatos |&gt;  \n  select(-pob)\n\n# A tibble: 48 × 3\n   jurisdiccion   año casos\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513\n 2 Buenos Aires  2016   957\n 3 CABA          2015   901\n 4 CABA          2016   427\n 5 Catamarca     2015    69\n 6 Catamarca     2016    51\n 7 Chaco         2015    15\n 8 Chaco         2016     9\n 9 Chubut        2015   110\n10 Chubut        2016    89\n# ℹ 38 more rows\n\n\nOtra forma para el mismo resultado anterior (mediante el operador rango :)\n\ndatos |&gt;  \n  select(jurisdiccion:casos)\n\n# A tibble: 48 × 3\n   jurisdiccion   año casos\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513\n 2 Buenos Aires  2016   957\n 3 CABA          2015   901\n 4 CABA          2016   427\n 5 Catamarca     2015    69\n 6 Catamarca     2016    51\n 7 Chaco         2015    15\n 8 Chaco         2016     9\n 9 Chubut        2015   110\n10 Chubut        2016    89\n# ℹ 38 more rows\n\n\nLas variables jurisdiccion y casos\n\ndatos |&gt;  \n  select(jurisdiccion, casos)\n\n# A tibble: 48 × 2\n   jurisdiccion casos\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Buenos Aires  1513\n 2 Buenos Aires   957\n 3 CABA           901\n 4 CABA           427\n 5 Catamarca       69\n 6 Catamarca       51\n 7 Chaco           15\n 8 Chaco            9\n 9 Chubut         110\n10 Chubut          89\n# ℹ 38 more rows\n\n\nOtra forma para el mismo resultado anterior (mediante números de columna):\n\ndatos |&gt;  \n  select(1, 3)\n\n# A tibble: 48 × 2\n   jurisdiccion casos\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Buenos Aires  1513\n 2 Buenos Aires   957\n 3 CABA           901\n 4 CABA           427\n 5 Catamarca       69\n 6 Catamarca       51\n 7 Chaco           15\n 8 Chaco            9\n 9 Chubut         110\n10 Chubut          89\n# ℹ 38 more rows\n\n\nTodas las variables pasando año a la primera columna\n\ndatos |&gt;  \n  select(\"año\", everything())\n\n# A tibble: 48 × 4\n     año jurisdiccion casos      pob\n   &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  2015 Buenos Aires  1513 16626374\n 2  2016 Buenos Aires   957 16789474\n 3  2015 CABA           901  3054237\n 4  2016 CABA           427  3050000\n 5  2015 Catamarca       69   396552\n 6  2016 Catamarca       51   401575\n 7  2015 Chaco           15  1153846\n 8  2016 Chaco            9  1125000\n 9  2015 Chubut         110   567010\n10  2016 Chubut          89   577922\n# ℹ 38 more rows\n\n\nEsta última función everything(), pasada como argumento, es una de las posibles funciones llamadas “ayudantes de selección”, entre las cuales se encuentra:\n\nstarts_with(): selecciona todas las columnas que comiencen con el patrón indicado.\nends_with(): selecciona todas las columnas que terminen con el patrón indicado.\ncontains(): selecciona las columnas que posean el patrón indicado.\nmatches(): similar a contains(), pero permite poner una expresión regular.\nall_of(): selecciona las variables pasadas en un vector (todos los nombres deben estar presentes o devuelve un error)\nany_of(): idem anterior excepto que no se genera ningún error para los nombres que no existen.\nnum_range(): selecciona variables con nombre combinados con caracteres y números (ejemplo: num_range(“x”, 1:3) selecciona las variables x1, x2 y x3.\nwhere(): aplica una función a todas las variables y selecciona aquellas para las cuales la función regresa TRUE (por ejemplo: is.numeric() para seleccionar todas las variables numéricas)\ngroup_cols(): selecciona todas las columnas de agrupación.\n\nTodas estas funciones son muy útiles a la hora de seleccionar el conjunto de variables necesarias no solo para un select() básico sino también cuando necesitemos aplicar operaciones simultáneas y/o pivotear tablas de datos que necesiten garantizar formato ordenado (tidy-data).\n\n\n\nEsta función es una extensión de select(), dado que esta última permite cambiar el nombre de variables pero no es muy útil porque descarta todas las variables que no se mencionan explícitamente. En cambio rename() renombra variables mientras que mantiene las demás no mencionadas.\nPor ejemplo, cambiamos el nombre de la variable pob por población.\n\ndatos |&gt; \n  rename(\"población\" = pob)\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos población\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 Buenos Aires  2015  1513  16626374\n 2 Buenos Aires  2016   957  16789474\n 3 CABA          2015   901   3054237\n 4 CABA          2016   427   3050000\n 5 Catamarca     2015    69    396552\n 6 Catamarca     2016    51    401575\n 7 Chaco         2015    15   1153846\n 8 Chaco         2016     9   1125000\n 9 Chubut        2015   110    567010\n10 Chubut        2016    89    577922\n# ℹ 38 more rows\n\n\n\n\n\nAsí como la función select() es utilizada para seleccionar columnas, la función filter() hace lo propio con las filas del conjunto de datos, produciendo un subconjunto de observaciones.\nVeamos un ejemplo sencillo sobre nuestros datos:\n\ndatos |&gt; \n  filter(jurisdiccion == \"Tucuman\")\n\n# A tibble: 2 × 4\n  jurisdiccion   año casos     pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Tucuman       2015   258 1592593\n2 Tucuman       2016   246 1618421\n\n\nUtiliza los mismos operadores de comparación propios del lenguaje R\n\n\n\nComparación\n\n\n\n\n\n&lt;\nmenor a\n\n\n&gt;\nmayor a\n\n\n==\nigual a\n\n\n&lt;=\nmenor o igual a\n\n\n&gt;=\nmayor o igual a\n\n\n!=\nno igual a\n\n\n%in%\nes parte de\n\n\nis.na\nes NA\n\n\n!is.na\nno es NA\n\n\n\nLo mismo con los operadores lógicos que se utilizan como conectores entre las expresiones.\n\n\n\nLógicos\n\n\n\n\n\n&\nAND booleano\n\n\n|\nOR booleano\n\n\nxor\nOR exclusivo\n\n\n!\nNOT\n\n\nany\ncualquier TRUE\n\n\nall\ntodos TRUE\n\n\n\nCuando usamos múltiples argumentos separados por coma dentro de filter() se combinan con un conector AND, es decir cada expresión debe ser verdadera para que una fila sea incluida en la salida.\nPor ejemplo:\nFiltramos a las observaciones que cumplan con la condición que casos sea mayor a 100 y población sea menor a 1000000\n\ndatos |&gt; \n  filter(casos &gt; 100, pob &lt; 1000000)\n\n# A tibble: 7 × 4\n  jurisdiccion   año casos    pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Chubut        2015   110 567010\n2 Jujuy         2015   160 727273\n3 Jujuy         2016   133 734807\n4 Neuquen       2015   109 619318\n5 Neuquen       2016   101 627329\n6 Rio Negro     2015   112 700000\n7 Rio Negro     2016   105 709459\n\n\nPara combinaciones dentro de una misma variable debemos utilizar el conector OR (|) o más útil el operador %in%.\nFiltramos a las jurisdicciones “Buenos Aires” y “La Pampa”\n\ndatos |&gt; \n  filter(jurisdiccion == \"Buenos Aires\" | jurisdiccion == \"La Pampa\")\n\n# A tibble: 4 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 La Pampa      2015    57   343373\n4 La Pampa      2016    67   345361\n\n\n\ndatos |&gt; \n  filter(jurisdiccion %in% c(\"Buenos Aires\", \"La Pampa\"))\n\n# A tibble: 4 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2015  1513 16626374\n2 Buenos Aires  2016   957 16789474\n3 La Pampa      2015    57   343373\n4 La Pampa      2016    67   345361\n\n\nFiltramos las observaciones de 2016 con casos mayores a 200 utilizando el conector AND (&). Es el mismo resultado que si utilizamos una coma.\n\ndatos |&gt; \n  filter(año == \"2016\" & casos &gt; 200)\n\n# A tibble: 6 × 4\n  jurisdiccion   año casos      pob\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Buenos Aires  2016   957 16789474\n2 CABA          2016   427  3050000\n3 Cordoba       2016   368  3607843\n4 Mendoza       2016   254  1909774\n5 Salta         2016   230  1352941\n6 Tucuman       2016   246  1618421\n\n\nFiltramos las observaciones inversas a la anterior mediante xor(), que selecciona los valores de año y casos exclusivos (es decir que no se den ambos en TRUE).\n\ndatos |&gt; \n  filter(xor(año == \"2016\", casos &gt; 200))\n\n# A tibble: 25 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374\n 2 CABA          2015   901  3054237\n 3 Catamarca     2016    51   401575\n 4 Chaco         2016     9  1125000\n 5 Chubut        2016    89   577922\n 6 Cordoba       2015   468  3572519\n 7 Corrientes    2016    99  1076087\n 8 Entre Rios    2016   109  1329268\n 9 Formosa       2016    60   582524\n10 Jujuy         2016   133   734807\n# ℹ 15 more rows\n\n\n\n\n\nLa función arrange() se utiliza para ordenar las filas de un conjunto de datos de acuerdo a una o varias columnas/variables. Por defecto, el ordenamiento es ascendente alfanumérico.\nOrdenamos la tabla datos por la variable pob (forma ascendente predeterminada):\n\ndatos |&gt; \n  arrange(pob)\n\n# A tibble: 48 × 4\n   jurisdiccion       año casos    pob\n   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Tierra del Fuego  2015    36 152542\n 2 Tierra del Fuego  2016    34 156682\n 3 Santa Cruz        2015    65 320197\n 4 Santa Cruz        2016    59 329609\n 5 La Pampa          2015    57 343373\n 6 La Pampa          2016    67 345361\n 7 La Rioja          2015    41 369369\n 8 La Rioja          2016     6 375000\n 9 Catamarca         2015    69 396552\n10 Catamarca         2016    51 401575\n# ℹ 38 more rows\n\n\nPara ordenar en forma descendente podemos utilizar desc() dentro de los argumentos de arrange():\n\ndatos |&gt; \n  arrange(desc(pob))\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2016   957 16789474\n 2 Buenos Aires  2015  1513 16626374\n 3 Cordoba       2016   368  3607843\n 4 Cordoba       2015   468  3572519\n 5 Santa Fe      2016   170  3400000\n 6 Santa Fe      2015   301  3382022\n 7 CABA          2015   901  3054237\n 8 CABA          2016   427  3050000\n 9 Mendoza       2016   254  1909774\n10 Mendoza       2015   316  1880952\n# ℹ 38 more rows\n\n\nPodemos combinar ordenamientos. Por ejemplo, en forma alfabética ascendente para jusrisdiccion y luego numérica descendente para casos.\n\ndatos |&gt; \n  arrange(jurisdiccion, desc(casos))\n\n# A tibble: 48 × 4\n   jurisdiccion   año casos      pob\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374\n 2 Buenos Aires  2016   957 16789474\n 3 CABA          2015   901  3054237\n 4 CABA          2016   427  3050000\n 5 Catamarca     2015    69   396552\n 6 Catamarca     2016    51   401575\n 7 Chaco         2015    15  1153846\n 8 Chaco         2016     9  1125000\n 9 Chubut        2015   110   567010\n10 Chubut        2016    89   577922\n# ℹ 38 more rows\n\n\n\n\n\nEsta función nos proporciona computar tranformaciones de variables en un conjunto de datos. A menudo, tendremos la necesidad de modificar variables existentes o crear nuevas variables que se calculan a partir de las que tenemos, mutate() nos ofrece una interface clara para realizar este tipo de operaciones.\nPor ejemplo, nos puede interesar calcular tasas crudas para cada jurisdicción y año, en función de los casos y el total de población.\n\ndatos |&gt; \n  mutate(tasa = casos/pob*100000)\n\n# A tibble: 48 × 5\n   jurisdiccion   año casos      pob  tasa\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374  9.10\n 2 Buenos Aires  2016   957 16789474  5.70\n 3 CABA          2015   901  3054237 29.5 \n 4 CABA          2016   427  3050000 14   \n 5 Catamarca     2015    69   396552 17.4 \n 6 Catamarca     2016    51   401575 12.7 \n 7 Chaco         2015    15  1153846  1.30\n 8 Chaco         2016     9  1125000  0.8 \n 9 Chubut        2015   110   567010 19.4 \n10 Chubut        2016    89   577922 15.4 \n# ℹ 38 more rows\n\n\nObservemos que la función realiza el cálculo (en este caso tasas crudas por 100000 habitantes) e incorpora una nueva variable por cada observación con el resultado.\nTambién se pueden construir múltiples variables en la misma expresión, solamente separadas por comas.\n\ndatos |&gt; \n  mutate(tasaxcien_mil = casos/pob*100000, \n         tasaxdiez_mil = casos/pob*10000)\n\n# A tibble: 48 × 6\n   jurisdiccion   año casos      pob tasaxcien_mil tasaxdiez_mil\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 Buenos Aires  2015  1513 16626374          9.10         0.910\n 2 Buenos Aires  2016   957 16789474          5.70         0.570\n 3 CABA          2015   901  3054237         29.5          2.95 \n 4 CABA          2016   427  3050000         14            1.4  \n 5 Catamarca     2015    69   396552         17.4          1.74 \n 6 Catamarca     2016    51   401575         12.7          1.27 \n 7 Chaco         2015    15  1153846          1.30         0.130\n 8 Chaco         2016     9  1125000          0.8          0.08 \n 9 Chubut        2015   110   567010         19.4          1.94 \n10 Chubut        2016    89   577922         15.4          1.54 \n# ℹ 38 more rows\n\n\nSi necesitemos que estas dos nuevas variables queden dentro de la tabla de datos y no solo mostrarla en consola como hasta ahora, debemos utilizar el operador de asignación:\n\ndatos &lt;- datos |&gt; \n  mutate(tasaxcien_mil = casos/pob*100000, \n         tasaxdiez_mil = casos/pob*10000)\n\nLa propiedad imprescindible es que la función debe poder vectorizar: debe tomar un vector de valores como entrada, y devolver un vector con el mismo número de valores que la salida.\nNo hay forma de enumerar todas las funciones posibles que se podría usar, pero mencionaremos algunas que pueden ser útiles:\n\nOperadores aritméticos: +, -, *, /, ^.\nAritmética modular: %/% (división entera) y %% (resto), donde \\(x == y * (x \\ \\%/\\% \\ y) + (x\\ \\%\\% \\ y)\\). La aritmética modular es una herramienta útil porque te permite dividir números enteros en porciones.\nFunciones matemáticas: log(), log2(), log10(), exp(), sqrt(), abs(), etc\nValores acumulados: R proporciona funciones para ejecutar sumas, productos, mínimos y máximos acumulados: cumsum(), cumprod(), cummin(), cummax(); y dplyr proporciona cummean() para promedios acumulados.\nClasificaciones (ranking): hay una serie de funciones de clasificación, por ejemplo min_rank(). Genera el tipo de clasificación habitual (1º, 2º, etc). El valor predeterminado relaciona los valores más pequeños a rangos pequeños; podemos usar desc(x) para invertir la relación (valores más grandes a rangos más pequeños)\n\nSi utilizamos el mismo nombre de una variable incluída dentro de la tabla de datos, estaremos sobrescribiendola (se usa cuando transformamos una variable, por ejemplo: le cambiamos su tipo de character a factor). Para que la variable sea nueva debe nombrarse con un nombre que no exista previamente dentro de la tabla de datos.\n\n\n\nDentro un mutate(), algunas veces vamos a necesitar agrupar, agregar o discretizar variables continuas donde generemos variables dicotómicas o politómicas.\nEstas funciones que llamaremos “condicionales”, dado que utilizan condiciones para decidir que valor tomar, no se limitan a la tarea de construir agrupamientos de variables cuantitativas sino que sirven para cualquier situación donde a partir de una o más condiciones se produzcan una o más valores como respuesta.\n\n\nPara salidas dicotómicas tenemos la función condicional if_else() derivada de la simplificación del IF condicional que existe en todos los lenguajes de programación.\nSupongamos que creamos una nueva variable dentro del dataframe datos que se llama variable_nueva de tipo cualitativa y queremos que la misma tome valores a partir del cumplimiento de una condición de una variable cuantitativa existente denominada var1.\nSi los valores de var1 son mayores a 10, entonces variable_nueva, tomará el valor “mayor a 10”, en caso contrario, tomará el valor “menor o igual a 10”\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"mayor a 10\", \n                                  false = \"menor o igual a 10\"))\n\nif_else() tiene tres argumentos obligatorios, el primero siempre es una condición, el segundo y el tercero son los valores que tomará la nueva variable si esa condición se cumple o no se cumple.\nHabitualmente decimos que en este proceso dicotomizamos una variable, dado que el resultado posible consta siempre de 2 valores.\nLos valores de salida de esta función pueden ser de variado tipo (caracter, numerico o logico) aunque si estamos discretizando una variable cuantitativa generalmente construimos una variable resultado cualitativa ordinal. Es común que esta variable salida sea tipo character (observar que las nuevas categorías van encerradas entre comillas).\nAhora bien, al ser ordinal estas categorías de la variable_nueva deben “ordenarse” en la forma de los valores de la variable, pero el lenguaje R no sabe con que estamos trabajando y respeta siempre el ordenamiento alfanumérico. Por lo tanto, en este ejemplo las categorías se van a estar ordenando al reves del orden numérico natural (de menor a mayor).\n“mayor a 10” se ordena alfabéticamente antes de “menor o igual a 10”, porque luego del empate de las letras m, le siguen la a en el primer caso y la e en el segundo.\nPara ordenar estas categorías debemos transformar la variable de caracter a factor. Esto se puede hacer en un solo paso dentro del mutate:\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"mayor a 10\", \n                                   false = \"menor o igual a 10\"),\n         variable_nueva = factor(variable_nueva, \n                                 levels = c(\"menor o igual a 10\",\n                                            \"mayor a 10\")))\n\nOtra forma más artesanal, igualmente válido, es “forzar” el ordenamiento con las categorías así:\n\ndatos &lt;- datos |&gt; \n  mutate(variable_nueva = if_else(condition = var1 &gt; 10, \n                                  true = \"2.mayor a 10\", \n                                  false = \"1.menor o igual a 10\"))\n\nAquí agregamos números iniciales a las etiquetas de las categorías para darle el orden que deseamos, sin necesidad de convertir a factor.\n\n\n\nEn salidas politómicas a partir de variables cuantitativas tenemos varias opciones dependiendo de si los intervalos de clase a construir son regulares o irregulares.\n\n\n\ntidyverse ofrece la función cut_interval() para la creación de intervalos regulares.\nEs una adptación de la función cut() de R base para tidy data y sus argumentos son similares.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = cut_interval(x = var1, \n                                  length = 10,\n                                  right = T,\n                                  labels = T,\n                                  ordered_result = F))\n\nLos argumentos obligatorios y opcionales de la función cut() son:\n\nx: [obligatorio] El conjunto de datos numéricos de entrada (variable cuantitativa continua)\nlength: [obligatorio] la longitud de cada intervalo regular\nright: [opcional] Indica si los intervalos son cerrados a la derecha o viceversa. Por defecto vale TRUE (cerrados a derecha)\nlabels: [opcional] Etiquetas de los intervalos automáticas o numéricas. Valor predeterminado TRUE (intervalos matemáticos)\nordered_result: [opcional] - determina si el resultado es un factor ordenado. Por defecto vale FALSE (la salida es tipo caracter)\n\nLos argumentos opcionales no son necesarios definirlos siempre y cuando los valores por defecto son los que sirven para la tarea.\n\n\n\nCuando las condiciones no son simples, es decir, el resultado no es dicotómico y además los intervalos son irregulares, utilizamos la función case_when() que es una vectorización de la función if_else().\nSupongamos que no queremos agrupar la variable en dos valores, sino en 3 grupos irregulares.\nEsquema básico de funcionamiento:\n\n# var1 es una variable cuantitativa de números enteros \n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n    var1 &gt;= 0 & var1 &lt; 25  ~  \"Grupo1\", \n    var1 &gt; 24 & var1 &lt; 65  ~    \"Grupo 2\", \n    var1 &gt;= 65             ~    \"Grupo 3\"))\n\nExiste una condición por cada grupo creado, como si fuese un if_else() donde el valor declarado siempre es el verdadero. Se utilizan operadores de comparación como mayor ( &gt; ), menor ( &lt; ) y/o igual ( = ) y conectores lógicos como & ( AND ). En cada línea va una virgulilla similar a la usada en la sintaxis formula ( ~ ) y luego la etiqueta que tomarán las observaciones que cumplan con esa condición en la nueva variable (grupo_var).\nEsta evaluación es secuencial y su funcionamiento provoca que el usuario del lenguaje tenga el control de lo que esta sucediendo, por lo que cualquier mala definición de las condiciones puede provocar resultados incorrectos.\nSi incorporamos el argumento .default podemos indicar que valor toma si no se cumple ninguna de las condiciones anteriores.\nPor ejemplo, podríamos tener algun valor perdido (NA) en var1 y queremos que la variable grupo_var etiquete esos valores perdidos como “Sin dato”:\n\n# var1 es una variable cuantitativa de números enteros con algun valor NA\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n        var1 &gt;= 0 & var1 &lt; 25  ~  \"Grupo1\", \n        var1 &gt; 24 & var1 &lt; 65  ~    \"Grupo 2\", \n        var1 &gt;= 65             ~    \"Grupo 3\",\n        .default = \"Sin dato\"))\n\nLas salidas son de tipo carácter (chr) y debemos manejar el ordenamiento de las etiquetas como vimos anteriormente, por medio de factores o comenzando con caracteres ordenados alfabeticamente.\nPara simplificar el trabajo de estos intervalos de clase irregulares y no provocar errores en la confección de las condiciones, tidyverse tiene a la función between().\n\n\n\nBáicamente opera como un atajo para condiciones de intervalos. Define dentro de los argumentos los límites inferior y superior de un intervalo y se utiliza dentro de una función de condición tipo if_else() o case_when().\nAplicado sobre el ejemplo anterior se vería así:\n\n# var1 es una variable cuantitativa de números enteros con algun valor NA\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_var = case_when( \n    between(var1, 0, 24)   ~  \"Grupo1\", \n        between(var1, 25, 64)  ~    \"Grupo 2\", \n        between(var1, 65, Inf) ~    \"Grupo 3\",\n        .default = \"Sin dato\"))\n\nLos valores declarados como límites quedan incluídos siempre dentro del intervalo (son cerrados ambos). También podemos utilizar valores reservados como Inf o -Inf cuando desconocemos con que valor máximo o mínimo nos vamos a encontrar en la variable cuantitativa original.\n\n\n\nTomemos un caso clásico como la variable edad medida en años, variable que generalmente tenemos en toda tabla de datos vinculada a personas. En este ejemplo la variable tiene 106 observaciones.\nUna posibilidad es dicotomizarla usando el valor de la mediana que divide 2 dos partes toda la distribución.\n\ndatos |&gt; \n  summarise(mediana = median(edad))\n\n# A tibble: 1 × 1\n  mediana\n    &lt;dbl&gt;\n1      56\n\n\nAplicando el valor 56 dentro de un if_else podriamos hacer:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"mayor a la mediana\", \n                                  false = \"menor o igual a la mediana\"))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                    n\n  &lt;chr&gt;                      &lt;int&gt;\n1 mayor a la mediana            52\n2 menor o igual a la mediana    54\n\n\nObservamos en el conteo que grupo_edad1 se construyó adecuadamente pero el orden de los niveles no es correcto si queremos que siga el ordenamiento natural de edad (de menor a mayor).\nUna de las formas que vimos es convertir a factor:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"mayor a la mediana\", \n                                  false = \"menor o igual a la mediana\"),\n         grupo_edad1 = factor(grupo_edad1, \n                                 levels = c(\"menor o igual a la mediana\",\n                                            \"mayor a la mediana\")))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                    n\n  &lt;fct&gt;                      &lt;int&gt;\n1 menor o igual a la mediana    54\n2 mayor a la mediana            52\n\n\nVemos que en el conteo el formato de la variable ya no es chr sino fct y el orden de las etiquetas siguen la forma “menor a mayor”.\nOtra forma es:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad1 = if_else(condition = edad &gt; 56, \n                                  true = \"2.mayor a la mediana\", \n                                  false = \"1.menor o igual a la mediana\"))\n\ndatos |&gt; \n  count(grupo_edad1)\n\n# A tibble: 2 × 2\n  grupo_edad1                      n\n  &lt;chr&gt;                        &lt;int&gt;\n1 1.menor o igual a la mediana    54\n2 2.mayor a la mediana            52\n\n\nSi en cambio necesitamos que los grupos sean mas de dos y que estos intervalos de clase sean regulares, podemos usar cut_interval\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;fct&gt;       &lt;int&gt;\n1 [0,10]          3\n2 (10,20]         3\n3 (20,30]         2\n4 (30,40]         3\n5 (40,50]        13\n6 (50,60]        52\n7 (60,70]        27\n8 (70,80]         3\n\n\nLa salida muestra 8 grupos etarios con etiquetas ordenadas con notación matemática, donde un corchete indica que el límite del intervalo es cerrado, es decir contiene el valor y un paréntesis es abierto y no lo hace.Así es que el primer grupo va de 0 a 10 años y el segundo de 11 a 20.\nEstos sucede así porque en forma predeterminada el argumento right está en TRUE. Veamos que pasa si lo cambiamos a FALSE:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    right = F))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;fct&gt;       &lt;int&gt;\n1 [0,10)          3\n2 [10,20)         3\n3 [20,30)         2\n4 [30,40)         3\n5 [40,50)        10\n6 [50,60)        48\n7 [60,70)        32\n8 [70,80]         5\n\n\nEn esta salida el primer grupo va de 0 a 9 y el segundo de 10 a 19.\nHasta ahora la variable grupo_edad2 es de tipo caracter, pero si deseamos que la salida sea factor podemos incorporar el argumento ordered_result en TRUE.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    ordered_result = T))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n  &lt;ord&gt;       &lt;int&gt;\n1 [0,10]          3\n2 (10,20]         3\n3 (20,30]         2\n4 (30,40]         3\n5 (40,50]        13\n6 (50,60]        52\n7 (60,70]        27\n8 (70,80]         3\n\n\nConstruimos así una variable factor ordenada .\nPor último, con el argumento labels en FALSE hacemos que las etiquetas de los 8 grupos sean numéricas.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo_edad2 = cut_interval(x = edad, \n                                    length = 10,\n                                    labels = F))\n\ndatos |&gt; \n  count(grupo_edad2)\n\n# A tibble: 8 × 2\n  grupo_edad2     n\n        &lt;int&gt; &lt;int&gt;\n1           1     3\n2           2     3\n3           3     2\n4           4     3\n5           5    13\n6           6    52\n7           7    27\n8           8     3\n\n\nOtro ejemplo, podría ser aplicando case_when() donde discretizamos la edad en 4 grupos irregulares, forzando sus etiquetas para lograr el orden adecuado.\n\ndatos &lt;- datos |&gt; \n  mutate(grupo3 = case_when(\n    edad &lt; 13              ~ \"1.Niño\",\n    edad &gt; 12 & edad &lt; 26  ~ \"2.Adolescente\",\n    edad &gt; 25 & edad &lt; 65  ~ \"3.Adulto_joven\",\n    edad &gt; 64              ~ \"4.Adulto_mayor\"\n  ))\n\ndatos |&gt; \n  count(grupo3)   \n\n# A tibble: 4 × 2\n  grupo3             n\n  &lt;chr&gt;          &lt;int&gt;\n1 1.Niño             3\n2 2.Adolescente      5\n3 3.Adulto_joven    86\n4 4.Adulto_mayor    12\n\n\nSi no hubiesemos etiquetado con los numeros por delante el orden alfabético hacía que Niño fuese a parar al final del conteo.\nDe la misma forma pero más sencillo y controlado es:\n\ndatos &lt;- datos |&gt; \n  mutate(grupo3 = case_when(\n    between(edad, 0, 12)   ~ \"1.Niño\",\n    between(edad, 13, 25)  ~ \"2.Adolescente\",\n    between(edad, 26, 64)  ~ \"3.Adulto_joven\",\n    between(edad, 65, Inf) ~ \"4.Adulto_mayor\"\n  ))\n\ndatos |&gt; \n  count(grupo3)  \n\n# A tibble: 4 × 2\n  grupo3             n\n  &lt;chr&gt;          &lt;int&gt;\n1 1.Niño             3\n2 2.Adolescente      5\n3 3.Adulto_joven    86\n4 4.Adulto_mayor    12\n\n\n\n\n\n\nLa función summarise() (se puede escribir también summarize()) resume variables de un conjunto de datos.\n\ndatos |&gt; \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos))\n\n# A tibble: 1 × 2\n  promedio_casos casos_totales\n           &lt;dbl&gt;         &lt;dbl&gt;\n1           192.          9211\n\n\nSu uso es muy interesante cuando la combinamos con group_by() (función que detallaremos luego). Esta situación permite estratificar los resultados por grupos específicos.\nPor ejemplo, podemos agrupar el por año y simultáneamente aplicar el mismo summarise() anterior.\n\ndatos |&gt;  \n  group_by(año) |&gt;  \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos))\n\n# A tibble: 2 × 3\n    año promedio_casos casos_totales\n  &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1  2015           224.          5369\n2  2016           160.          3842\n\n\nEl resultado es una tabla con dos filas, una para cada grupo (año 2015 y año 2016) con los valores promedio y casos totales respectivos.\nAlgunas de las funciones del R base que se pueden utilizar dentro de los argumentos de esta función son:\n\nmin() mínimo\nmax() máximo\nmean() media\nmedian() mediana\nvar() varianza\nsd() desvío\nsum() sumatoria\n\nOtras funciones que se pueden incorporar las provee el mismo paquete dplyr, por ejemplo:\n\nfirst() primer valor en el vector\nlast() último valor en el vector\nn() número de valores en el vector\nn_distinct() números de valores distintos en el vector\n\nDesde la versión 1.4.0 de dplyr la función summarise() incorpora un nuevo argumento para agrupamientos temporales. El argumento .by = trabaja igual que un group_by() previo pero lo hace solo para realizar el calculo definido dentro del resumen evitando que el dataframe de salida mantenga el agrupamiento.\nLa estructura básica de la función actualizada es:\n\ndatos |&gt; \n  summarise(\n    var_resumen = funcion(var),\n    .by = var_grupo\n  )\n\nAplicada en el ejemplo previo:\n\ndatos |&gt;  \n  summarise(promedio_casos = mean(casos), \n            casos_totales = sum(casos),\n            .by = año)\n\n# A tibble: 2 × 3\n    año promedio_casos casos_totales\n  &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;\n1  2015           224.          5369\n2  2016           160.          3842\n\n\n\n\n\nDecíamos recién que la función group_by() es útil cuando trabaja conjuntamente con summarise() dado que agrupa un conjunto de filas seleccionado en un conjunto de filas de resumen de acuerdo con los valores de una o más columnas o expresiones.\nPara ejemplificar su trabajo asociado obtendremos una nueva tabla con el cálculo de las tasas crudas para cada jurisdicción por año (similar al ejemplo de la aplicación de mutate():\n\ndatos |&gt; \n  group_by(jurisdiccion, año) |&gt;  \n  summarise(tasa = casos/pob*100000)\n\n# A tibble: 48 × 3\n# Groups:   jurisdiccion [24]\n   jurisdiccion   año  tasa\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1 Buenos Aires  2015  9.10\n 2 Buenos Aires  2016  5.70\n 3 CABA          2015 29.5 \n 4 CABA          2016 14   \n 5 Catamarca     2015 17.4 \n 6 Catamarca     2016 12.7 \n 7 Chaco         2015  1.30\n 8 Chaco         2016  0.8 \n 9 Chubut        2015 19.4 \n10 Chubut        2016 15.4 \n# ℹ 38 more rows\n\n\nEn la mayoría de estos ejemplos la salida es directa, es decir no construimos nuevos objetos contenedores de los datos producidos y vemos los resultados en consola o en el visualizador de RStudio. Pero en muchas situaciones vamos a necesitar generar nuevos conjunto de datos con las transformaciones realizadas. Si en alguna de estas ocasiones llegamos a agrupar datos mediante group_by() y posteriormente necesitamos volver a tener la información desagrupada existe una función vinculada denominada ungroup() que vamos a necesitar aplicar o bien si no se desea tener el agrupamiento de forma fija se puede usar el argumento .by = del summarise() como mostramos anteriormente.\n\n\n\nEn los ejemplos anteriores vimos como se van integrando alguna de las funciones mediante el uso de la tubería %&gt;% o |&gt;. La idea detrás de la búsqueda gramatical del paquete es poder enlazar las acciones para construir oraciones más complejas.\nUn ejemplo que podría integrar gran parte de los visto sería:\nObtener una nueva tabla con las tasas crudas de casos notificados de VIH, por año y jurisdicción, mayores a 20 x 100000 habitantes ordenadas de mayor a menor.\n\ndatos |&gt;                                   # siempre partimos de los datos\n  group_by(año, jurisdiccion) |&gt;           # agrupamos\n  summarise(tasa = casos/pob*100000) |&gt;    # resumimos\n  filter(tasa &gt; 20) |&gt;                     # filtramos\n  arrange(desc(tasa))                       # ordenamos   \n\n# A tibble: 5 × 3\n# Groups:   año [2]\n    año jurisdiccion      tasa\n  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;\n1  2015 CABA              29.5\n2  2015 Tierra del Fuego  23.6\n3  2015 Jujuy             22.0\n4  2016 Tierra del Fuego  21.7\n5  2015 Santa Cruz        20.3\n\n\nObservemos que una buena manera de construir el código es respetar un salto de línea para cada término de la oración para una lectura más clara.\nDemostramos así la potencialidad que tienen estas funciones combinadas donde en esta situación integramos las funciones group_by(), summarise() , filter() y arrange() en una misma operación.\n\n\n\nEsta última función que presentamos permite contar rápidamente los valores únicos de una o más variables.\nProduce fácilmente tablas de frecuencias absolutas que luego posibilitan construir frecuencias relativas.\nLa aplicamos sobre la variable jurisdiccion de datos\n\ndatos |&gt; \n  count(jurisdiccion)\n\n# A tibble: 24 × 2\n   jurisdiccion     n\n   &lt;chr&gt;        &lt;int&gt;\n 1 Buenos Aires     2\n 2 CABA             2\n 3 Catamarca        2\n 4 Chaco            2\n 5 Chubut           2\n 6 Cordoba          2\n 7 Corrientes       2\n 8 Entre Rios       2\n 9 Formosa          2\n10 Jujuy            2\n# ℹ 14 more rows\n\n\nTiene un par de argumentos opcionales:\n\nname: es el nombre de la columna con el conteo. Por defecto se llama n\nsort: ordena la tabla de frecuencia de mayor a menor\nwt: se puede opcionalmente incorporar una variable con la ponderación (factor de expansión) para el calculo de la frecuencia.",
    "crumbs": [
      "Unidad 2: Procesamiento de datos"
    ]
  },
  {
    "objectID": "unidad2.html#uniones-en-datos-relacionales",
    "href": "unidad2.html#uniones-en-datos-relacionales",
    "title": "Unidad 2: Procesamiento de datos",
    "section": "Uniones en datos relacionales",
    "text": "Uniones en datos relacionales\nExisten situaciones donde debemos analizar datos que se encuentran en diferentes tablas.\nCon el fin de responder a nuestras preguntas de interés en ocasiones deberemos unirlas previamente.\nDe manera general, se le llama datos relacionales a esas múltiples tablas de datos que provienen muchas veces de sistemas de bases de datos construidas bajo el modelo relacional o bien cuando las tablas de datos tienen fuentes distintas pero comparten alguna variable común que permita “conectarlas”.\nUn ejemplo recurrente sucede cuando necesitamos calcular la tasa de algún evento de salud y tenemos en una tabla el conteo (dato agregado) del evento (numerador) y en otra el conteo de la población en riesgo (denominador).\n\nTipos de operaciones\nPara trabajar con datos relacionales necesitamos de funciones-verbos que vinculen pares de tablas.\nLas tres familias de funciones del paquete dplyr diseñadas para trabajar con datos relacionales son:\n\nUniones de transformación (del inglés mutating joins), agregan nuevas variables a una tabla a partir de observaciones coincidentes de otra tabla.\nUniones de filtro (del inglés filtering joins), filtran observaciones de una tabla en función de la coincidencia o no coincidencia de otra tabla.\nOperaciones en filas y columnas, sirven para unir tablas por columnas o por filas.\n\n\n\nClaves\n\nLas variables usadas para conectar cada par de variables se llaman claves (del inglés key)\nUna clave es una variable (o un conjunto de variables) que identifican de manera única una observación.\n\nExisten dos tipos de claves:\n\nUna clave primaria identifica únicamente una observación en su propia tabla.\nUna clave foránea únicamente identifica una observación en otra tabla.\n\nUna vez que identificadas las claves primarias en las tablas, es una buena práctica verificar que identifican de forma única cada observación. Una forma de hacerlo es usar count() con las claves primarias y buscar las entradas con n mayor a uno:\n\ndatos |&gt; \n  count(clave_primaria) |&gt; \n  filter(n &gt; 1)\n\nLa salida debería mostrar que no hay ninguna observación que cumpla la condición de n &gt; 1, es decir todas las observaciones tienen una sola clave primaria unívoca.\nEn ocasiones podemos tener claves primarias compuestas por más de una variable. Tendremos que utilizar entonces esta combinación de variables a la vez en las uniones que realicemos.\nOtra situación inversa es no tener ninguna variable como clave primaria, aunque sepamos que cada observación pertenece a una misma unidad de análisis pero de elementos (sujetos, etc) diferentes. Aquí se puede usar la función row_number() que numera en orden ascendente las observaciones de la tabla y almacena esta numeración en una variable, creando una clave subrogada.\n\ndatos &lt;- datos |&gt; \n  mutate(clave = row_number()) \n\n\n\nUniones de transformación\nLa forma más simple de unión es la unión interior (del inglés inner join). Una unión interior une pares de observaciones siempre que sus claves sean iguales.\nUnión interior\nUna unión interior mantiene las observaciones que aparecen en ambas tablas. La estructura del código sirve de base para las demás uniones:\n\ndatos_x |&gt; \n  inner_join(datos_y, by = \"variable_clave\") \n\n\n\n\n\n\nLa propiedad más importante de una unión interior es que las filas no coincidentes no se incluyen en el resultado\nUniones exteriores\nUna unión exterior mantiene las observaciones que aparecen en al menos una de las tablas.\n\nUna unión izquierda (left join) mantiene todas las observaciones en x.\n\n\n\n\n\n\n\nUna unión derecha (right join) mantiene todas las observaciones en y.\n\n\n\n\n\n\n\nUna unión completa (full join) mantiene todas las observaciones en x e y.\n\n\n\n\n\n\nEstas uniones funcionan agregando una observación “virtual” adicional a cada tabla. Esta observación tiene una clave que siempre coincide (de no haber otras claves coincidentes) y un valor que se llena con NA.\nOtra forma de ilustrar diferentes tipos de uniones es mediante un diagrama de Venn.\n\n\n\n\n\nSin embargo, tiene una limitante importante: un diagrama de Venn no puede mostrar qué ocurre con las claves que no identifican de manera única una observación.\n\n\nClaves duplicadas\nHasta ahora todas las situaciones han asumido que las claves son únicas. Pero esto no siempre es así.\nExisten dos posibilidades habituales:\n\nUna tabla tiene claves duplicadas producto de una relación uno a varios.\n\n\n\n\n\n\n\nAmbas tablas tienen claves duplicadas (producto de una relación real varios a varios o por algún “error”)\n\n\n\n\n\n\nSiempre que unimos claves duplicadas, obtenemos todas las posibles combinaciones, es decir, el producto cartesiano\n\n\nVariables claves\nLa forma común del argumento by = donde se define/n la/s variable/s clave/s es igualarlo al nombre la variable o variables concatenadas con c() que deberán tener el mismo nombre en las dos tablas a unir.\nOtra maneras de conectar las tablas sería:\n\nSin definir by = o bien by = NULL, que de forma predeterminada utiliza todas las variables que se llamen de la misma forma (respetando mayúsculas y minúsculas). Esta se denomina unión natural.\nUtilizar la función join_by() en el argumento by = que nos da la posibilidad de declarar cuales son las variables de unión cuando estas tengan nombres distintos en cada tabla.\n\n\ndatos_x |&gt; \n  inner_join(datos_y, \n             by = join_by(var_clave_x == var_clave_y)) \n\nObserven que la igualdad de las variables claves de x e y es un operador de comaparación ==\nEn caso que hubiese más de una variable clave de unión se puede hacer:\n\ndatos_x |&gt; \n  inner_join(datos_y, \n             by = join_by(var1_clave_x == var1_clave_y,\n                          var2_clave_x == var2_clave_y,)) \n\n\n\nUniones de filtro\nLa función semi_join() mantiene todas las observaciones de la tabla x donde la clave coincide con la clave de la tabla y\n\n\n\n\n\nPara hacer lo inverso, anti_join() descarta todas las observaciones de la tabla x donde la clave coincide con la clave de la tabla y\n\n\n\n\n\n\n\nUnión por filas y por columnas\nEn algunas ocasiones necesitamos unir tablas que tienen formatos particulares por medio de filas o por medio de columnas.\nLas funciones de dplyr para esta tarea son:\n\nbind_rows() Une una tabla debajo de otra. Aplica cuando tenemos la misma estructura en tabla de datos divida en varios archivos (por ejemplo, producto de carga simultánea de datos en diferentes computadoras con diferentes data-entry)\nbind_cols() Une una tabla al lado de la otra. Es peligroso su uso si la confundimos con las uniones de transformación porque perdemos integridad de datos en las observaciones. Sirve sólo si el “orden” de las observaciones pueden garantizar la misma identidad de las partes a unir.",
    "crumbs": [
      "Unidad 2: Procesamiento de datos"
    ]
  },
  {
    "objectID": "unidad2.html#datos-ordenados",
    "href": "unidad2.html#datos-ordenados",
    "title": "Unidad 2: Procesamiento de datos",
    "section": "Datos ordenados",
    "text": "Datos ordenados\nLas tablas de datos con la que trabajamos dentro de tidyverse deben cumplir con ciertas características de los “datos ordenados” (tidy data).\nLlamamos tidy data cuando:\n\nCada variable está en una columna\nCada observación está en una fila\nCada celda del cruce entre una columna y una fila es un valor\nCada tabla pertenece a una unidad de observación\n\n\n\n\n\n\nA veces las tablas se parecen a esto:\n\n\n\n\n\ncountry\n2010\n2011\n2012\n2013\n\n\n\n\nArgentina\n40374224\n40728738\n41086927\n41446246\n\n\nBrazil\n195210154\n196935134\n198656019\n200361925\n\n\nUruguay\n3371982\n3383486\n3395253\n3407062\n\n\n\n\n\nCumple con las reglas de “datos ordenados”?\nNo. \nNo lo hace porque lo que vemos como cabecera de columnas en 2010, 2011, etc. son categorías de la variable año (year) y no nombres de variables.\nEn cambio esta tabla, aunque tenga la misma información, si cumple con el formato ordenado.\n\n\n\n\n\ncountry\nyear\npopulation\n\n\n\n\nArgentina\n2010\n40374224\n\n\nArgentina\n2011\n40728738\n\n\nArgentina\n2012\n41086927\n\n\nArgentina\n2013\n41446246\n\n\nBrazil\n2010\n195210154\n\n\nBrazil\n2011\n196935134\n\n\nBrazil\n2012\n198656019\n\n\nBrazil\n2013\n200361925\n\n\nUruguay\n2010\n3371982\n\n\nUruguay\n2011\n3383486\n\n\nUruguay\n2012\n3395253\n\n\nUruguay\n2013\n3407062\n\n\n\n\n\nGeneralmente los problemas comunes en tabla “desordenadas” de datos son:\n\nUna variable se extiende por varias columnas.\nUna observación está dispersa entre múltiples filas\n\nEl paquete tidyr de tidyverse resuelve estos problemas y mediante sus funciones pivot_ nos permite pivotear las tablas a lo “ancho” o “largo”.\n\nFunción pivot_longer() - Convierte nombres de columnas en valores de una nueva variable.\nFunción pivot_wider() - Convierte valores de una variable en columnas nuevas.\n\nPara pasar de formato ancho a largo, es decir cuando los valores de una variable se extiende por varias columnas, se utilizan como mínimo estos argumentos:\n\ntabla_ancho |&gt; \n  pivot_longer(cols = -paises,        # todas las columnas -paises\n               names_to = \"anio\",     # nombre de la columna de los nombres\n               values_to = \"casos\")   # nombre la columna de los valores\n\n\n\n\n\n\nEl formato inverso, cuando una observación está dispersa entre múltiples filas, sería:\n\ntabla_largo |&gt; \n  pivot_wider(names_from = tipo,    # nombres de los valores de tipo\n              values_from = casos)  # valores de los valores de casos",
    "crumbs": [
      "Unidad 2: Procesamiento de datos"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción al lenguaje R + RStudio",
    "section": "",
    "text": "I. ORIENTACIONES GENERALES\nFortalecimiento de capacidades del Departamento de Epidemiología e Información Estratégica del Hospital Hospital de Alta Complejidad El Calafate-SAMIC.\nII. ELEMENTOS DEL DISEÑO\nNombre de la actividad: Introducción al lenguaje R aplicado a sistemas y servicios de salud\n2. Fundamentación\nEl Departamento de Epidemiología e Información Estratégica en Salud del Hospital Hospital de Alta Complejidad El Calafate-SAMIC (DEIES) trabaja procesando datos provenientes de diferentes fuentes digitales con el fin de resumir la información y presentarla en informes técnicos que faciliten la toma de decisiones.\nEl adecuado manejo de los sistemas de información requiere de recursos humanos calificados en el procesamiento y análisis de datos, capaces de identificar necesidades y problemas relevantes en la materia, y de lidiar con la complejidad creciente de los sistemas de información en salud. A su vez, es necesario dar respuesta a la demanda global de actualización en el análisis de datos, en paralelo a los adelantos tecnológicos y a la modernización de los procesos de trabajo.\nActualmente es necesario dotar con estas competencias a los integrantes del DEIES, estandarizar sus procesos de trabajo aumentando su eficiencia, facilitar el intercambio de información útil y su visualización ante requerimientos externos al departamento, y mantener organizadamente el cúmulo de datos que posee. También aplicar herramientas modernas como Quarto para la elaboración de informes técnicos y la creación de presentaciones gráficas interactivas en formato HTML, útiles para la construcción de salas de situación de salud, tanto coyunturales como de tendencias, así como también representar visualmente indicadores epidemiológicos con precisión y claridad, identificar tendencias críticas en salud pública de forma oportuna y optimizar el flujo de trabajo mediante procesos reproducibles y automatizados.\nLa adopción de software gratuito y de código abierto como el lenguaje R y Quarto, un sistema de publicación técnica de código abierto, ofrece una solución moderna y eficiente para abordar las necesidades mencionadas. Estas herramientas permiten el tratamiento y manipulación de datos con alta reproducibilidad, una capacidad estadística avanzada y una forma de publicación versátil y adaptable a diversos contextos\n3. Contribución esperada\nMejora en la estandarización de procesos de limpieza, procesamiento y análisis de las bases de datos generando así un flujo de intercambio de información dinámico y de calidad entre los y las agentes del DEIES , permitiendo la reproducibilidad y mejora de todos los procesos. Producción de informes técnicos, documentos estáticos y tableros dinámicos con información epidemiológica del Hospital\n4. Perfil del participante y requisitos\nPerfil del participante: Integrantes del DEIES que se desempeñen en áreas vinculadas al análisis de datos y que deseen adquirir conocimientos para el procesamiento y análisis de datos con R/ RStudio.\nRequisitos Obligatorios: competencias intermedias en gestión de archivos y software en sistema operativo Windows. Utilización básica de Microsoft Excel. Conocimientos básicos de estadística descriptiva.\nDeseables: conocimientos básicos-intermedios de bases de datos y de lectura de idioma inglés. Equipamiento necesario: Se recomienda contar con computadoras que tengan al menos procesadores I5, 8GB de Memoria RAM o superior y sistema operativo Windows 10/11 con conexión a internet, micrófono y parlantes para la realización de los sincrónicos y prácticas del curso.\n5. Objetivos\nSe espera que al finalizar este curso los participantes puedan:\n\nComprender los fundamentos del lenguaje R\nUtilizar adecuadamente las herramientas de RStudio\nImportar y exportar bases de datos de diferentes formatos\nEntender y aplicar código de R base, tidyverse y otros paquetes específcos.\nRealizar análisis descriptivo utilizando funciones estadísticas\nProcesar y transformar datos utilizando funciones específicas\nDepurar, ordenar y unir tablas de datos.\nRealizar gráficos descriptivos\nProducir informes y tableros mediante Quarto (HTML, Word, etc)\n\n6. Contenidos\nUnidad 1: Instalación e introducción al lenguaje R\n1.1 Descarga e instalación de R, Rtools y RStudio\n1.2 Introducción al lenguaje R: Scripts. Objetos. Funciones y argumentos. Librerías y dependencias. Tipos de datos. Estructuras de datos. Asignación. Errores y advertencias. Operadores. Tuberías. Filosofía tidyverse.\n1.3 Rstudio: Característica del entorno de desarrollo integrado. Proyectos. Consola. Memoria. Historial. Ayuda. Paquetes. Atajos de teclado\n1.4 Sintaxis en R. Scripts. Documentación. Hoja de estilo del lenguaje. Buenas prácticas\n1.5 Lectura de datos. Texto plano, Excel y otros formatos específicos.\nUnidad 2: Procesamiento de datos\n2.1 Gestión de datos con tidyverse. Paquete dplyr.\n2.2 Uniones de tablas de datos. Familia de join’s y bind’s\n2.3 Datos “tidy” y “no-tidy”. Pivoteos. Paquete tidyr.\nUnidad 3: Exploración, diagnóstico y limpieza de datos\n3.1 Exploración de tipos de datos y diagnóstico con paquetes skimr y dlookr\n3.2 Manejo de duplicados. Limpieza de datos\n3.3 Diagnóstico de valores perdidos (NA). Paquete naniar\n3.4 Exportación de datos limpios en diferentes formatos.\nUnidad 4: Tratamiento de datos específicos\n4.1 Variables de tiempo. Librería Lubridate.\n4.2 Cadenas de caracteres y factores. Paquete stringr y forcats\nUnidad 5: Estadísticos, operaciones múltiples y resúmenes\n5.1 Cálculos: Proporciones, razones y tasas.\n5.2 Resumen estadístico. Medidas de tendencia central, posición y dispersión.\n5.3 Cálculos masivos. Función across() y rowwise()\n5.4 Paquete rstatix y gtsummary.\nUnidad 6: Visualización de datos\n6.1 Gramática de gráficos con ggplot2. Gráficos estadísticos.\n6.2 Capas geométricas de líneas, puntos, barras, histogramas y boxplots. Facetas\n6.3 Pirámides poblacionales. Curvas epidémicas y corredores endémicos.\n6.4 Exportación en diferentes formatos (raster y vectorial)\nUnidad 7: Control de flujo y funciones\n7.1 Bucles y condicionales\n7.2 Creación de funciones\nUnidad 8: Comunicar con Quarto\n8.1 Quarto. Paquete tinytext.\n8.2 Lenguaje de marcas markdown. Cabeceras YAML. Paquete flextable. Personalización estética\n8.3 Documentos estáticos PDF y Word\n8.4 Páginas HTML y tableros dinámicos\n7. Estrategias metodológicas y recursos didácticos\nRealización de trabajos prácticos (TP) semanales. Se utilizará de apoyo un aula virtual alojada dentro de la plataforma educativa moodle de ANLIS.\nActividades de desarrollo: cada semana se abordará una unidad, en un primer encuentro sincrónico el docente explicará los puntos temáticos, en un segundo encuentro se llevará a cabo la práctica relacionada. Las clases teóricas y prácticas serán virtuales, de una duración aproximada máxima de dos horas, mediante Webex, que luego quedarán disponibles en la plataforma de aprendizaje. Cada unidad se acompañará de materiales de apoyo, prácticas y recursos en el aula virtual. Las actividades serán monitoreadas por el docente a través de la plataforma educativa, a la vez que ofrecerá apoyo a través de un foro de consultas.\n8. Descripción de la modalidad\nVirtual\n9. Bibliografía para el participante\nHadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund (2023) R for Data Science (2e). Disponible en https://r4ds.hadley.nz/\nHadley Wickham, Danielle Navarro, and Thomas Lin Pedersen (2023) ggplot2: Elegant graphics for data analysis (3e). https://ggplot2-book.org/\nTipos de gráficos https://www.data-to-viz.com/\nNeale Batra y otros (2022) R para epidemiología aplicada y salud pública. https://epirhandbook.com/es/index.html\n10. Evaluación de los aprendizajes\nSe requerirá la entrega y aprobación de 7 trabajos prácticos. Los trabajos prácticos evaluativos parciales serán individuales y estarán relacionados a las unidades 2 a la 8. Se publicará una consigna en el aula virtual con puntos a resolver mediante código en lenguaje R que deberán entregar a la semana siguiente. La evaluación final consistirá en un trabajo práctico grupal que consistirá en procesar datos crudos y obtener un producto final con una serie de resultados a visualizar con tablas y gráficos. Los pasos a considerar en el trabajo práctico final son: Creación de un proyecto RStudio Lectura de datos Exploración y diagnóstico. Formateo y depuración de datos crudos a datos limpios Obtención de resúmenes descriptivos y creación de nuevas variables Elaboración de tablas y gráficos Creación de documento o tablero dinámico\n11. Instrumentos para la evaluación\nInstrumentos para la evaluación de los aprendizajes Registro de Asistencia de las/os participantes.\nGrilla para la corrección de TPs. Grilla para la corrección del TP grupal final Instrumentos para la evaluación de la actividad\nEncuesta de satisfacción de la actividad de carácter anónimo\n12. Perfil del instructor\nEspecialista en Sistemas / Datos con orientación a la epidemiología y salud pública\n13. Requisitos de asistencia y aprobación\nPara la aprobación se requiere asistencia en el 80% de las clases sincrónicas (teóricas y prácticas).\nRealización de la totalidad de TP´s planteados\n14. Duración en horas\nEl curso tendrá una duración total de 76 horas distribuidas a lo largo de 10 semanas.\n15. Detalle de la duración\n32 horas sincrónicas distribuidas en 16 encuentros de 2 horas cada uno (2 veces por semana durante 8 semanas) y 44 horas asincrónicas, calculadas 4 horas por semana durante las 8 semanas del curso para la lectura del material (1 hora), la realización de los trabajos prácticos (3 horas) y la elaboración del TP integrador final (12 horas)\n16. Lugar\nLas clases virtuales se realizarán a través de la plataforma Webex. Se contará con un campus virtual para la publicación de material y recursos, consultas y entrega y corrección de TPs: http://capacitacion.anlis.gob.ar/\n17. Cronograma tentativo\nComienzo jueves 3 de abril y finalización viernes 6 de junio de 2025.\nEncuentros sincrónicos teóricos: los jueves 3, 10, 17, 24 de abril, 1 de mayo (se sube al aula grabado), 8, 15, 22 de mayo de 10 a 12 hs.\nEncuentros sincrónicos prácticos: los viernes 4, 11, 18, 25 de abril, 2, 9, 16, 23 de mayo de 9 a 11 hs.\nPráctico integrador final: del 23 de mayo al 6 de junio de 2025.\n\n\n\n Volver arriba",
    "crumbs": [
      "Fundamentos"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n Volver arriba"
  },
  {
    "objectID": "extra.html",
    "href": "extra.html",
    "title": "Extra: Control de flujo y funciones",
    "section": "",
    "text": "Un bucle es una estructura de control que permite ejecutar un conjunto de instrucciones repetidamente mientras se cumple una condición específica. Los bucles, se encuentran en todos los lenguajes de programación y se utilizan para automatizar tareas repetitivas (iterar).\nEl lenguaje R también los implementa en sus paquetes base y dispone de tres de ellos:\n\nfor(): estructura de control de flujo de iteración a partir de una secuencia de elementos\n\n\nwhile(): estructura de control de flujo de iteración mientras una condición es verdadera\n\n\nrepeat(): estructura de control de flujo de iteración de repetición y control manual con break\n\n\n\nLa idea principal de este bucle es repetir un bloque de código un número específico de veces o para cada elemento en objeto (vector, etc).\nSu esquema de funcionamiento es el siguiente:\n\n\n\n\n\nLa estructura sintáctica viene dada por un snippet que RStudio escribe por nosotros:\n\nfor (variable in vector) {\n  \n}\n\nUn ejemplo sencillo que muestra su funcionamiento puede ser.\n\nfor (i in 1:5) {\n  cat(\"El valor de i es:\", i, \"\\n\")\n}\n\nEl valor de i es: 1 \nEl valor de i es: 2 \nEl valor de i es: 3 \nEl valor de i es: 4 \nEl valor de i es: 5 \n\n\nLo que estamos haciendo es recorriendo un vector numérico de 5 posiciones, declarado bajo el nombre de i y luego entre llaves se encuentra el código que escribe en pantalla un texto fijo que incluye a los valores de i en cada repetición.\nEl mismo formato de bucle puede recorrer posiciones y/o elementos de un objeto de la siguiente forma:\n\nx &lt;- c(6, 4, 3, 8)\n\nfor (i in 1:length(x)) {\n  print(x[i]*4)     # utiliza la i para recorrer los elementos de x por su indice\n}\n\n[1] 24\n[1] 16\n[1] 12\n[1] 32\n\n\nRecorre el vector x y multiplica cada elemento por 4. Lo mismo que hace R vectorizadamente de manera simple.\n\nx * 4\n\n[1] 24 16 12 32\n\n\nPor supuesto que la mayoría de las tareas que R ejecuta de forma vectorizada hace que no tengamos que usar esta forma de bucle para operaciones comunes pero, a veces cuando el código dentro de las llaves es extenso y complejo será necesario.\n\n\n\nEste bucle se repite mientras la condición especificada es evaluada como verdadera (TRUE). Si en algún momento la condición se evalúa como falsa (FALSE), el bucle se detiene y la ejecución continúa con el código después del bucle.\nSu esquema de funcionamiento es el siguiente:\n\n\n\n\n\nSu snippet es:\n\nwhile (condition) {\n  \n}\n\nUn ejemplo posible muestra que primero inicializamos una variable i que servirá como contador, luego escribimos una condición en el inicio del bucle indicando que recién saldremos de él cuando esta variable sea igual a 6 y finalmente dentro de las llaves armamos el código que se va a repetir no olvidando de la sumatoria del contador i.\n\ni &lt;- 1\n\nwhile (i &lt;= 5) {\n  cat(\"El valor de i es:\", i, \"\\n\")\n  i &lt;- i + 1\n}\n\nEl valor de i es: 1 \nEl valor de i es: 2 \nEl valor de i es: 3 \nEl valor de i es: 4 \nEl valor de i es: 5 \n\n\nEl último de los bucles, repeat() no tiene automatizada su salida y necesita que incorporemos dentro de su cuerpo entre llaves la función break a partir de alguna condición (se suele utilizar la estructura condicional if()). Esta forma de trabajo lo hace peligroso porque suelen generar bucles infinitos de donde no hay salida, salvo la interrupción abrupta del interprete.\nDado que su construcción es muy artesanal no vamos a mostrarlo en este documento. Su uso no será necesario durante el curso y probablemente no lo necesiten aplicar en el futuro.",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#bucles-tradicionales",
    "href": "extra.html#bucles-tradicionales",
    "title": "Extra: Control de flujo y funciones",
    "section": "",
    "text": "Un bucle es una estructura de control que permite ejecutar un conjunto de instrucciones repetidamente mientras se cumple una condición específica. Los bucles, se encuentran en todos los lenguajes de programación y se utilizan para automatizar tareas repetitivas (iterar).\nEl lenguaje R también los implementa en sus paquetes base y dispone de tres de ellos:\n\nfor(): estructura de control de flujo de iteración a partir de una secuencia de elementos\n\n\nwhile(): estructura de control de flujo de iteración mientras una condición es verdadera\n\n\nrepeat(): estructura de control de flujo de iteración de repetición y control manual con break\n\n\n\nLa idea principal de este bucle es repetir un bloque de código un número específico de veces o para cada elemento en objeto (vector, etc).\nSu esquema de funcionamiento es el siguiente:\n\n\n\n\n\nLa estructura sintáctica viene dada por un snippet que RStudio escribe por nosotros:\n\nfor (variable in vector) {\n  \n}\n\nUn ejemplo sencillo que muestra su funcionamiento puede ser.\n\nfor (i in 1:5) {\n  cat(\"El valor de i es:\", i, \"\\n\")\n}\n\nEl valor de i es: 1 \nEl valor de i es: 2 \nEl valor de i es: 3 \nEl valor de i es: 4 \nEl valor de i es: 5 \n\n\nLo que estamos haciendo es recorriendo un vector numérico de 5 posiciones, declarado bajo el nombre de i y luego entre llaves se encuentra el código que escribe en pantalla un texto fijo que incluye a los valores de i en cada repetición.\nEl mismo formato de bucle puede recorrer posiciones y/o elementos de un objeto de la siguiente forma:\n\nx &lt;- c(6, 4, 3, 8)\n\nfor (i in 1:length(x)) {\n  print(x[i]*4)     # utiliza la i para recorrer los elementos de x por su indice\n}\n\n[1] 24\n[1] 16\n[1] 12\n[1] 32\n\n\nRecorre el vector x y multiplica cada elemento por 4. Lo mismo que hace R vectorizadamente de manera simple.\n\nx * 4\n\n[1] 24 16 12 32\n\n\nPor supuesto que la mayoría de las tareas que R ejecuta de forma vectorizada hace que no tengamos que usar esta forma de bucle para operaciones comunes pero, a veces cuando el código dentro de las llaves es extenso y complejo será necesario.\n\n\n\nEste bucle se repite mientras la condición especificada es evaluada como verdadera (TRUE). Si en algún momento la condición se evalúa como falsa (FALSE), el bucle se detiene y la ejecución continúa con el código después del bucle.\nSu esquema de funcionamiento es el siguiente:\n\n\n\n\n\nSu snippet es:\n\nwhile (condition) {\n  \n}\n\nUn ejemplo posible muestra que primero inicializamos una variable i que servirá como contador, luego escribimos una condición en el inicio del bucle indicando que recién saldremos de él cuando esta variable sea igual a 6 y finalmente dentro de las llaves armamos el código que se va a repetir no olvidando de la sumatoria del contador i.\n\ni &lt;- 1\n\nwhile (i &lt;= 5) {\n  cat(\"El valor de i es:\", i, \"\\n\")\n  i &lt;- i + 1\n}\n\nEl valor de i es: 1 \nEl valor de i es: 2 \nEl valor de i es: 3 \nEl valor de i es: 4 \nEl valor de i es: 5 \n\n\nEl último de los bucles, repeat() no tiene automatizada su salida y necesita que incorporemos dentro de su cuerpo entre llaves la función break a partir de alguna condición (se suele utilizar la estructura condicional if()). Esta forma de trabajo lo hace peligroso porque suelen generar bucles infinitos de donde no hay salida, salvo la interrupción abrupta del interprete.\nDado que su construcción es muy artesanal no vamos a mostrarlo en este documento. Su uso no será necesario durante el curso y probablemente no lo necesiten aplicar en el futuro.",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#mapeos-con-purrr",
    "href": "extra.html#mapeos-con-purrr",
    "title": "Extra: Control de flujo y funciones",
    "section": "Mapeos con purrr",
    "text": "Mapeos con purrr\nEl patrón de iterar sobre un vector o variable, hacer algo con cada elemento u observación y almacenar los resultados es tan común que el paquete purrr incluído en tidyverse aporta una familia de funciones dedicadas a esta tarea.\nHay una función para cada tipo de output:\nmap() crea una lista. map_lgl() crea un vector lógico. map_int() crea un vector de enteros. map_dbl() crea un vector de numérico (double). map_chr() crea un vector de caracteres. map_df() crea un dataframe\nCada función map, mapea, es decir, toma un vector como input, aplica una función a cada elemento y luego devuelve un nuevo vector que tiene la misma longitud (y los mismos nombres) que el input. El tipo de vector está determinado por el sufijo de la función map.\n\n\n\n\n\nSu estructura sintáctica es:\n\nmap(.x = , \n    .f = , \n    ... = )\n\nDonde en .x es un vector, un data-frame o lista, .f es la función a aplicar y ... son otros argumentos opcionales.\nLas funciones map tienen un nivel superior de abstracción y puede llevar mucho tiempo entender cómo funcionan.\nAlgunos usuarios evitan los bucles tradicionales porque son lentos o “viejos”, pero esto no es así. Las principales ventajas de usar funciones como map() no es la velocidad, sino la claridad: hacen que tu código sea más fácil de escribir y leer.\nUnos ejemplos simples de uso son:\n\n# a partir de un datframe con variables numéricas\n\ndatos\n\n# A tibble: 10 × 5\n   grupo        a      b       c       d\n   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 B      0.579   -0.660  0.467  -0.0680\n 2 A      0.500   -0.870  0.402   0.541 \n 3 A     -1.33     0.861  0.115  -1.31  \n 4 B     -0.267    0.175  1.09   -0.194 \n 5 A      0.464   -1.72   0.362  -0.635 \n 6 B      1.44    -1.82  -0.212   2.54  \n 7 B      0.830    0.574 -1.06    0.139 \n 8 A      0.00399 -0.527  1.20    0.155 \n 9 B     -0.111   -0.516 -0.0924 -0.361 \n10 B      0.827   -0.509 -0.282  -0.544 \n\nmap_dbl(.x = datos, .f = mean)\n\n      grupo           a           b           c           d \n         NA  0.29355547 -0.50099908  0.19936133  0.02666104 \n\n\nCalcula la media por cada una de las variables numéricas. Como la variable grupo no lo es me devuelve una advertencia y un NA como resultado.\nSi quisiera evitarlo podemos hacer.\n\nmap_dbl(.x = datos |&gt; select(-grupo), \n        .f = mean)\n\n          a           b           c           d \n 0.29355547 -0.50099908  0.19936133  0.02666104 \n\n\nObserven que dentro del argumento .x construimos una estructura con tuberías donde seleccionamos a todas las variables menos a grupo (esto se puede hacer en los argumentos de muchas funciones).",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#aplicación-de-un-bucle-tradicional",
    "href": "extra.html#aplicación-de-un-bucle-tradicional",
    "title": "Extra: Control de flujo y funciones",
    "section": "Aplicación de un bucle tradicional",
    "text": "Aplicación de un bucle tradicional\nMostramos un ejemplo posible donde necesitamos aplicar un bucle para iterar una serie de repeticiones.\nEste ejemplo consiste en leer un archivo habitual en el trabajo epidemiológico como son las proyecciones poblacionales que publica el INDEC luego de cada censo. En este caso particular son proyecciones que van desde 2010 a 2040 para las 24 provincias de Argentina por quinquenios y sexo.\nLa tabla tiene este formato:\n\n\n\n\n\nCada provincia se ubica en una hoja del archivo Excel y la estructura de las proyecciones no tiene un formato que reconozcamos como ordenado. El objetivo es producir un dataframe donde nos queden 4 variables (Edad, Sexo, Provincia, Poblacion) con los datos de las proyecciones para 2024.\nLo primero que vamos hacer es almacenar en un vector los nombres de las hojas del archivo. Usando la función excel_sheets() extraemos estos codigo-nombres (la expresión de índices [-(1:2)] sirve para omitir los nombres de la primera hoja oculta que tiene el archivo llamada “GraphData” y la segunda donde esta el total país).\n\nlibrary(readxl)\n\nhojas &lt;- excel_sheets(\"datos/c2_proyecciones_prov_2010_2040.xls\")[-(1:2)]\n\nNos va a quedar el vector hojas con los nombres de las 24 provincias que figuran en las hojas Excel.\n\nhojas\n\n [1] \"02-CABA\"                \"06-BUENOS AIRES\"        \"10-CATAMARCA\"          \n [4] \"14-CÓRDOBA\"             \"18-CORRIENTES\"          \"22-CHACO\"              \n [7] \"26-CHUBUT\"              \"30-ENTRE RÍOS\"          \"34-FORMOSA\"            \n[10] \"38-JUJUY\"               \"42-LA PAMPA\"            \"46-LA RIOJA\"           \n[13] \"50-MENDOZA\"             \"54-MISIONES\"            \"58-NEUQUÉN\"            \n[16] \"62-RÍO NEGRO\"           \"66-SALTA\"               \"70-SAN JUAN\"           \n[19] \"74-SAN LUIS\"            \"78-SANTA CRUZ\"          \"82-SANTE FE\"           \n[22] \"86-SANTIAGO DEL ESTERO\" \"90-TUCUMÁN\"             \"94-TIERRA DEL FUEGO\"   \n\n\nPara aprovechar el contenido vamos a construir otro vector con los códigos solos. Aplicamos la función str_sub() sobre hojas.\n\nprovincias &lt;- str_sub(hojas, start = 1, end = 2)\n\n\nprovincias \n\n [1] \"02\" \"06\" \"10\" \"14\" \"18\" \"22\" \"26\" \"30\" \"34\" \"38\" \"42\" \"46\" \"50\" \"54\" \"58\"\n[16] \"62\" \"66\" \"70\" \"74\" \"78\" \"82\" \"86\" \"90\" \"94\"\n\n\nA continuación vamos a necesitar separar la parte que no se repite y la parte que si. Por ejemplo, la columna donde está la edad cada 5 años es una parte fija que no necesaria volver a leer en cada hoja del archivo, en cambio las poblaciones si varían entre provincia y provincia.\n\ngrupo_edad &lt;- read_excel(\"datos/c2_proyecciones_prov_2010_2040.xls\", \n                         sheet = 2, range = \"A36:A56\", col_names = F)  |&gt;  \n  rename(\"Edad\" = \"...1\")\n\nLeemos el archivo “c2_proyecciones_prov_2010_2040.xls” en su segunda hoja (la primera era la occulta) y con el rango “A36:A56”. Desactivamos nombres de columnas y renombramos con el nombre Edad. Podríamos haber leído cualquiera de las 24 hojas porque la columna de edad es la misma para todas.\n\ngrupo_edad\n\n# A tibble: 21 × 1\n   Edad \n   &lt;chr&gt;\n 1 0-4  \n 2 5-9  \n 3 10-14\n 4 15-19\n 5 20-24\n 6 25-29\n 7 30-34\n 8 35-39\n 9 40-44\n10 45-49\n# ℹ 11 more rows\n\n\nNos queda un dataframe de nombre grupo_edad con 1 variable (Edad) y 21 observaciones.\nAhora, antes de comenzar con las repeticiones del bucle, debemos estructurar el dataframe contenedor de estas lecturas iterativas.\n\npoblacion &lt;- data.frame(Varon = NA, Mujer = NA, Provincia = NA, Edad = NA)\n\nCreamos poblacion como un dataframe con 4 variables Varon, Mujer, Provincia y Edad con datos vacíos (NA).\n\npoblacion\n\n  Varon Mujer Provincia Edad\n1    NA    NA        NA   NA\n\n\nEstamos en condiciones de utilizar un bucle for para ir rellenando el dataframe poblacion con las lecturas del archivo Excel.\n\nfor (i in 1:length(hojas)) {\n  datai &lt;- read_excel(\"datos/c2_proyecciones_prov_2010_2040.xls\", \n                     sheet = hojas[i], range = \"K64:L84\", col_names = F)\n  \n  datai &lt;- datai |&gt; mutate(Provincia = provincias[i]) |&gt; \n             rename(\"Varon\" = \"...1\",\n                    \"Mujer\" = \"...2\") |&gt; \n             bind_cols(grupo_edad) \n  \n  poblacion &lt;- poblacion  |&gt;  bind_rows(datai)\n}\n\nAnalicemos la estructura del for() y el contenido del cuerpo encerrado entre llaves:\n\nUtilizamos la longitud del vector hojas para que la cantidad de repeticiones del bucle sea igual a la cantidad de hojas del archivo (serán 24 repeticiones, 1 por hoja)\n\n\n1:length(hojas)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n\n\n\nLa primera línea del cuerpo crea el objeto datai que lee las poblaciones para el año 2024 de varones y mujeres usando un rango que deberemos construir mirando las ubicaciones dentro del archivo Excel. Además usamos la variable i del for() para recorrer el vector hojas que tiene el nombre de cada una de las 24 provincias idénticas a las hojas del archivo, por lo que en la vuelta 1 leera el rango de la hoja 02-CABA, en la segunda la de 06-BUENOS AIRES y así hasta la última (94-TIERRA DEL FUEGO).\nLa segunda estructura de código agrega a datai el código de la provincia en cada repetición recorriendo con la variable i el vector provincias. Luego renombra las cabeceras sin nombre para Varon y Mujer y finalmente une por columna con bind_cols() las edades. Esta forma es la misma en nombre de variables, posición y tipo de datos que el contenedor creado previamente (poblacion).\nPor último, une por filas con bind_rows() a datai con poblacion.\n\nLa operación construye un dataframe con dimensiones [ 505, 4 ], es decir, 505 observaciones por 4 variables.\nHay dos problemas finales para resolver, uno es que la primera observación es la de valores NA que usamos cuando creamos el contenedor.\n\npoblacion |&gt; slice(1:4)\n\n   Varon Mujer Provincia  Edad\n1     NA    NA      &lt;NA&gt;  &lt;NA&gt;\n2 101130 95310        02   0-4\n3 101700 96044        02   5-9\n4 100390 95056        02 10-14\n\n\nCon drop_na() la podemos eliminar sin mayores problemas.\n\npoblacion &lt;- poblacion |&gt; drop_na() # eliminamos primera linea con NA\n\nEl otro inconveniente es que la tabla final no cumple con los datos ordenados, porque Varon y Mujer no deberían ser nombres de variables sino categorías de la variable Sexo.\nAplicamos lo que sabemos de pivoteos con tidyr para arreglarlo.\n\npoblacion &lt;- poblacion |&gt; \n               pivot_longer(cols = c(Varon, Mujer), \n                            names_to = \"Sexo\",\n                            values_to = \"Poblacion\")\n\nEl resultado final es la tabla buscada con poblaciones proyectada por el INDEC de las 24 provincias por sexo y grupos de edades quinquenales en formato tidy-data:\n\npoblacion\n\n# A tibble: 1,008 × 4\n   Provincia Edad  Sexo  Poblacion\n   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n 1 02        0-4   Varon    101130\n 2 02        0-4   Mujer     95310\n 3 02        5-9   Varon    101700\n 4 02        5-9   Mujer     96044\n 5 02        10-14 Varon    100390\n 6 02        10-14 Mujer     95056\n 7 02        15-19 Varon    101138\n 8 02        15-19 Mujer     96827\n 9 02        20-24 Varon     97411\n10 02        20-24 Mujer     96051\n# ℹ 998 more rows",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#aplicación-de-una-iteración-map",
    "href": "extra.html#aplicación-de-una-iteración-map",
    "title": "Extra: Control de flujo y funciones",
    "section": "Aplicación de una iteración map",
    "text": "Aplicación de una iteración map\nImaginemos que tenemos varios archivos de datos con la misma estructura producto de la vigilancia epidemiológica o de un estudio de cohorte donde cada uno de ellos pertenece a un mes. Para analizar todo un año en una sola tabla final, deberíamos leer 12 archivos de nombres diferentes y luego unir los datos uno debajo del otro.\nQueremos hacer este trabajo pero simplificando el proceso agilizando el proceso de lectura y obtener una sola tabla con todas las observaciones generando un id que almacene el mes al que pertenece.\nVamos a hacer uso de la función dis_ls() del paquete fs (file system) que es muy útil cuando debemos hacer operaciones con carpetas y archivos de sistema desde el código (en este caso Windows).\n\nlibrary(fs)\n\nCon la función dir_ls() obtenemos listados de directorio (similar a dir() de la línea de comandos de Windows).\nSi en la carpeta están solos los archivos de datos no hay que aclarar nada más pero si hay otros se puede usar el argumento glob para definir un patrón de búsqueda. Para que esto funcione bien los archivos tienen que tener un mismo formato en su nombre. Por ejemplo, aprovechando el formato de estos archivos vamos a usar el patrón “datos/datos_*_vigilancia.csv”.\n\narchivos &lt;- dir_ls(path = \"datos\", glob = \"datos/datos_*_vigilancia.csv\") \n  \narchivos\n\ndatos/datos_abril_vigilancia.csv      datos/datos_agosto_vigilancia.csv     \ndatos/datos_diciembre_vigilancia.csv  datos/datos_enero_vigilancia.csv      \ndatos/datos_febrero_vigilancia.csv    datos/datos_julio_vigilancia.csv      \ndatos/datos_junio_vigilancia.csv      datos/datos_marzo_vigilancia.csv      \ndatos/datos_mayo_vigilancia.csv       datos/datos_noviembre_vigilancia.csv  \ndatos/datos_octubre_vigilancia.csv    datos/datos_septiembre_vigilancia.csv \n\n\nQuedaron almacenados en el vector archivos los 12 nombres de los archivos mensuales. Observemos que tienen el formato “datos/datos_mes_vigilancia.csv” y además nos dicen que son de texto plano con separador coma.\nA continuación aplicaremos la función map_df() del paquete purrr junto a la función read_csv() para repetir las lecturas de estos archivos agregando el nombre de cada uno a las observaciones de la tabla final.\n\ndatos &lt;- archivos |&gt; \n           map_df(read_csv, .id = \"archivo\")\n\nLa primera variable que tendrá el mismo nombre que definimos en el argumento .id es el nombre completo del archivo fuente.\n\ndatos |&gt; count(archivo)\n\n# A tibble: 12 × 2\n   archivo                                   n\n   &lt;chr&gt;                                 &lt;int&gt;\n 1 datos/datos_abril_vigilancia.csv        157\n 2 datos/datos_agosto_vigilancia.csv       157\n 3 datos/datos_diciembre_vigilancia.csv    157\n 4 datos/datos_enero_vigilancia.csv        157\n 5 datos/datos_febrero_vigilancia.csv      157\n 6 datos/datos_julio_vigilancia.csv        157\n 7 datos/datos_junio_vigilancia.csv        157\n 8 datos/datos_marzo_vigilancia.csv        157\n 9 datos/datos_mayo_vigilancia.csv         157\n10 datos/datos_noviembre_vigilancia.csv    157\n11 datos/datos_octubre_vigilancia.csv      157\n12 datos/datos_septiembre_vigilancia.csv   157\n\n\nEn estos datos de ejemplo ficticios hay 157 observaciones de cada uno de los meses, pero en la realidad estas cantidades seguramente son variantes.\nPara resolver el problema de que nos quede solamente el nombre del mes usaremos la función separate_wider_delim() de tidyr indicando que separe el nombre con el delimitador “_” y con el argumento names me quede la parte del medio con nombre mes y se deshaga de las constantes “datos/datos” y “vigilancia”.\n\ndatos |&gt; \n  separate_wider_delim(cols = archivo, \n                       delim = \"_\", \n                       names = c(NA, \"mes\", NA)) |&gt; \n  count(mes)\n\n# A tibble: 12 × 2\n   mes            n\n   &lt;chr&gt;      &lt;int&gt;\n 1 abril        157\n 2 agosto       157\n 3 diciembre    157\n 4 enero        157\n 5 febrero      157\n 6 julio        157\n 7 junio        157\n 8 marzo        157\n 9 mayo         157\n10 noviembre    157\n11 octubre      157\n12 septiembre   157\n\n\nLa estructura completa unida por tuberías nos quedaría:\n\ndatos &lt;- dir_ls(path = \"datos\", glob = \"datos/datos_*_vigilancia.csv\") |&gt; \n  map_df(read_csv, .id = \"archivo\") |&gt; \n  separate_wider_delim(cols = archivo, \n                       delim = \"_\", \n                       names = c(NA, \"mes\", NA)) \n\nEl resultado final es que leímos 12 archivos (podrían ser muchos más, todos los que quisiéramos) en tan solo 3 líneas de código unidas por dos tuberías.\n\ndatos\n\n# A tibble: 1,884 × 19\n   mes      HC SEXO   EDAD ANT_DIABETES ANT_TBC ANT_CANCER ANT_OBESIDAD ANT_ECV\n   &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;  \n 1 abril 26880 M        17 NO           NO      NO         SI           NO     \n 2 abril 26775 M        18 SI           NO      NO         NO           NO     \n 3 abril 26877 M        18 SI           NO      SI         NO           NO     \n 4 abril 26776 M        18 NO           NO      NO         SI           SI     \n 5 abril 26718 M        18 NO           NO      NO         NO           NO     \n 6 abril 26738 M        18 NO           NO      NO         NO           NO     \n 7 abril 26836 M        18 NO           NO      NO         NO           NO     \n 8 abril 26823 M        18 NO           NO      SI         NO           SI     \n 9 abril 26711 M        18 NO           NO      SI         SI           NO     \n10 abril 26852 M        18 NO           NO      SI         NO           NO     \n# ℹ 1,874 more rows\n# ℹ 10 more variables: ANT_HT &lt;chr&gt;, ANT_COL &lt;chr&gt;, FUMA &lt;chr&gt;, EDADINI &lt;dbl&gt;,\n#   CANTIDAD &lt;dbl&gt;, COL &lt;dbl&gt;, PESO &lt;dbl&gt;, TALLA &lt;dbl&gt;, SIST &lt;dbl&gt;, DIAST &lt;dbl&gt;",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#creación-de-funciones",
    "href": "extra.html#creación-de-funciones",
    "title": "Extra: Control de flujo y funciones",
    "section": "Creación de funciones",
    "text": "Creación de funciones\nUna de las ventajas de usar lenguajes abiertos como el R es poder crear funciones.\nLas funciones nos permiten automatizar tareas comunes de una manera más potente y general que copiar y pegar.\nEscribir una función tiene tres grandes ventajas sobre usar copiar y pegar:\n\nA medida que cambian los requisitos, solo necesitamos actualizar el código en un solo lugar.\nElimina la posibilidad de cometer errores incidentales al copiar y pegar (es decir, actualizar el nombre de una variable en un lugar, pero no en otro).\nFacilita la reutilización del trabajo de un proyecto a otro, aumentando su productividad con el tiempo.\n\nSi bien hay muchas tareas que puede hacer una función, existen tres tipos muy útiles:\n\nFunciones vectoriales que toman uno o más vectores como entrada y devuelven un vector como salida.\n\n\nFunciones de tablas de datos que toman un dataframe como entrada y devuelven un dataframe como salida.\n\n\nFunciones gráficas que toman un dataframe como entrada y devuelven un gráfico como salida.",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#esqueleto-de-una-función",
    "href": "extra.html#esqueleto-de-una-función",
    "title": "Extra: Control de flujo y funciones",
    "section": "Esqueleto de una función",
    "text": "Esqueleto de una función\nCualquier función construida en R tiene una estructura o esqueleto similar, no importa lo que haga cuando la ejecutemos.\nTodas ellas tienen:\n\nUn nombre, que deberá cumplir con las caraterísticas que nos impone el lenguaje para nombres (no debe comenzar con un número, no debe utilizar palabras reservadas del lenguaje, no debe tener espacios entre los caracteres, etc.)\nArgumentos, puede no haber o haber varios, dependiendo de lo que se necesite para que la función trabaje. Van encerrados entre paréntesis y separados por coma.\nUn cuerpo, donde se desarrolla el código en cuestión, que se va a repetir cada vez que llamemos a la función. Este código deberá ser una abstracción generalizada de la solución al problema que abordemos para lograr que funcione en cualquier situación.\n\nLa sintaxis de creación en R es:\n\nnombre_funcion &lt;- function(variables) {\n  &lt; cuerpo de la función &gt;\n}  \n\ndonde:\n\nnombre_funcion: es el nombre que le queremos dar a la función creada\nfunction(): es la palabra reservada por el lenguaje para crear funciones\nvariables: es el espacio donde se declaran el o los argumentos con los que trabajemos. Puede, en ocasiones, no haber ninguno.\n{}: entre estas llaves se encuentra el cuerpo de la función",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#funciones-vectoriales",
    "href": "extra.html#funciones-vectoriales",
    "title": "Extra: Control de flujo y funciones",
    "section": "Funciones vectoriales",
    "text": "Funciones vectoriales\nPara explicar su funcionamiento hagamos un ejemplo sencillo:\nSupongamos que una labor habitual en nuestro trabajo sea convertir en años la diferencia entre dos fechas, por ejemplo entre la fecha de nacimiento y otra, para calcular la edad.\nQueremos construir una función que realice este trabajo, recibiendo dos fechas como vectores y devolviendo una cantidad de años como vector.\nRecurriendo a la documentación de semanas anteriores se puede ver que ejecutando la siguiente línea con funciones de lubridate se podía obtener los años en número entero:\n\ninterval(fecha_nacimiento, fecha) %/% dyears()\n\nUsemos eso para crear la función, a la que podemos llamar calculo_edad. Además le vamos a incorporar en la primera línea la activación del paquete lubridate, que necesitaremos dentro del cuerpo de la función. Para esta tarea, en lugar de library() usaremos require().\n\ncalculo_edad &lt;- function(fecha_nacimiento, fecha) {\n\nrequire(lubridate)\n  \ninterval(fecha_nacimiento, fecha) %/% dyears()\n  \n}\n\nPara probar la función creada, la aplicamos a unos datos.\n\ndatos\n\n# A tibble: 2 × 2\n  FECNAC     FECREG    \n  &lt;date&gt;     &lt;date&gt;    \n1 1954-05-23 2023-08-17\n2 2003-01-24 2023-12-04\n\n\nEsta tabla tiene dos variables de tipo Date con dos observaciones de fecha, en la primera la fecha de nacimiento y en la segunda la fecha de registro. Para crear la nueva variable Edad pondremos dentro de un mutate() la función calculo_edad escrita anteriormente.\n\ndatos |&gt; \n  mutate(Edad = calculo_edad(fecha_nacimiento = FECNAC, fecha = FECREG))\n\n# A tibble: 2 × 3\n  FECNAC     FECREG      Edad\n  &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt;\n1 1954-05-23 2023-08-17    69\n2 2003-01-24 2023-12-04    20\n\n\nObservemos que nos calcula la edad como queríamos y que los nombres de las variables con los datos no importa que no coincidan con los nombres internos definidos en los argumentos.\nQue otras consideraciones tenemos que tener en cuenta para que funcione bien? Por ejemplo que las fechas ya estén en formato Date. Que pasará si esto no sucede y son de tipo character:\n\ndatos\n\n# A tibble: 2 × 2\n  FECNAC     FECREG    \n  &lt;chr&gt;      &lt;chr&gt;     \n1 23/05/1954 17/08/2023\n2 24/01/2003 04/12/2023\n\n\n\ndatos |&gt; \n  mutate(Edad = calculo_edad(FECNAC, FECREG))\n\n# A tibble: 2 × 3\n  FECNAC     FECREG      Edad\n  &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt;\n1 23/05/1954 17/08/2023    NA\n2 24/01/2003 04/12/2023    NA\n\n\nNos devuelve valores NA en Edad producto de un error esperable porque la función interval(), que escribimos dentro de nuestra función, necesita que los valores de fecha sean de tipo Date o date-time.\nEntonces podemos complejizar el cuerpo del código agregando algo para que resuelva este problema:\n\ncalculo_edad &lt;- function(fecha_nacimiento, fecha) {\n\nrequire(lubridate)\n  \nif (is.character(fecha_nacimiento)) {\n  fecha_nacimiento &lt;- dmy(fecha_nacimiento)\n}  \n  \nif (is.character(fecha)) {\n  fecha &lt;- dmy(fecha)\n}  \n  \ninterval(fecha_nacimiento, fecha)%/% dyears()\n  \n}\n\nVolvemos a correr la función sobre los datos con las variables en formato character:\n\ndatos |&gt; \n  mutate(Edad = calculo_edad(FECNAC, FECREG))\n\n# A tibble: 2 × 3\n  FECNAC     FECREG      Edad\n  &lt;chr&gt;      &lt;chr&gt;      &lt;dbl&gt;\n1 23/05/1954 17/08/2023    69\n2 24/01/2003 04/12/2023    20\n\n\nAhora funciona bien pero así como solucionamos el tema del tipo de dato podríamos enfrentarnos a otros más, como la estructura de la fecha (si es dmy o mdy o ymd) o si el paquete lubridate no se encuentra instalado en mi sesión de R, etc.\nGeneralmente para que una función se pueda aplicar generalizadamente, como suelen ser las funciones de los paquetes publicados, necesitaremos que tenga controladas sus salidas de error lo mejor posible.\nQue vimos hasta ahora de nuevo en el código previo:\n\nFunción require() en lugar de library(): hacen lo mismo (activar un paquete) pero es preferible require() porque si un paquete no está instalado solo generará una advertencia y luego continuará ejecutando el código.\nFunción if(): es la función condicional, hermana de ifelse(), que conviene utilizar en casos donde ante una condición debemos tomar caminos diferentes. Se suelen usar en cuerpos de funciones y dentro de bucles tradicionales.\n\nUna posibilidad para manejar errores por falta de instalación de paquetes es agregar una línea inicial con un condicional que consulte si la librería lubridate se encuentra instalada, y si no es así que la instale previamente.\n\ncalculo_edad &lt;- function(fecha_nacimiento, fecha) {\n\nif (!\"lubridate\" %in% installed.packages()) {\n  install.packages(\"lubridate\")  \n}  \n  \nrequire(lubridate)\n  \nif (is.character(fecha_nacimiento)) {\n  fecha_nacimiento &lt;- dmy(fecha_nacimiento)\n}  \n  \nif (is.character(fecha)) {\n  fecha &lt;- dmy(fecha)\n}  \n  \ninterval(fecha_nacimiento, fecha)%/% dyears()\n  \n}",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#funciones-de-tablas-de-datos",
    "href": "extra.html#funciones-de-tablas-de-datos",
    "title": "Extra: Control de flujo y funciones",
    "section": "Funciones de tablas de datos",
    "text": "Funciones de tablas de datos\nRecordemos que las funciones de tablas de datos funcionan como funciones-verbos dplyr: toman un dataframe como primer argumento, algunos argumentos adicionales que dicen qué hacer con él y devuelven generalmente un dataframe.\nA diferencia del proceso para funciones vectoriales, donde los nombre de las funciones declaradas en los argumento eran reemplazados por cualquier otro nombre de las variables externas de la función, aquí necesitamos utilizar unos operadores de evaluación especiales.\nSe denomina “embracing” (abrazar) una variable al hecho de envolverla entre llaves {{ nombre_variable }}.\nAbrazar una variable le dice a dplyr que use el valor almacenado dentro del argumento y no el argumento como el nombre “literal” de la variable.\nVeamos un ejemplo de este tipo de funciones:\nCreamos una función que realice un resumen de variables cuantitativas, calculando su mínimo, máximo, media, mediana, cantidad de NA y cantidad de observaciones totales.\n\nresumen &lt;- function(datos, var) {\n\nif (!\"dplyr\" %in% installed.packages()) {\n  install.packages(\"dplyr\")  \n}  \n  \nrequire(dplyr)\n    \ndatos |&gt; summarise(\n    min = min({{ var }}, na.rm = TRUE),\n    media = mean({{ var }}, na.rm = TRUE),\n    mediana = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_NA = sum(is.na({{ var }}))\n  )\n}\n\nLo aplicamos sobre la variable Edad de unos datos de prueba.\n\ndatos |&gt; resumen(Edad)\n\n# A tibble: 1 × 6\n    min media mediana   max     n  n_NA\n  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1    18  58.6    62.5    99    67     5\n\n\nObservemos que el código principal del cuerpo de la función tiene una estructura tidyverse con funciones propias de dplyr y R base, donde el nombre de la variable declarada en los argumentos (var) se encuentra abrazada por las llaves.\n\ndatos |&gt; summarise(\n    min = min({{ var }}, na.rm = TRUE),\n    media = mean({{ var }}, na.rm = TRUE),\n    mediana = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_NA = sum(is.na({{ var }}))\n  )\n\nLa función también se puede aplicar combinada con un agrupamiento (group_by()).\n\ndatos |&gt; \n  group_by(Sexo) |&gt; \n  resumen(Edad)\n\n# A tibble: 2 × 7\n  Sexo    min media mediana   max     n  n_NA\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n1 Mujer    18  55.7      57    93    31     2\n2 Varon    19  61.1      63    99    36     3",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#funciones-para-gráficos",
    "href": "extra.html#funciones-para-gráficos",
    "title": "Extra: Control de flujo y funciones",
    "section": "Funciones para gráficos",
    "text": "Funciones para gráficos\nLas funciones para gráficos son muy parecidas a las de tablas de datos, dado que utilizamos funciones de ggplot2 para graficar. La única diferencia es que la salida es un gráfico en lugar de un dataframe.\nVamos a ejemplificar creando un gráfico de barras para aprovechar a introducir un nuevo operador, necesario cuando queremos reutilizar el nombre de una variable definida por el usuario que aplica la función a la izquierda de una asignación de argumentos de tidyverse.\nEl nuevo operador, llamada morsa, se escribe := y significa igual (=). Veamoslo en acción:\n\nif (!\"tidyverse\" %in% installed.packages()) {\n  install.packages(\"tidyverse\")  \n}  \n  \nrequire(tidyverse)\n\nbarras_ordenadas &lt;- function(datos, var) {\n  datos |&gt; \n    mutate({{ var }} := fct_infreq({{ var }}))  |&gt;\n    ggplot(aes(x = {{ var }}, fill = {{ var }})) +\n    geom_bar() +\n    theme(legend.position = \"bottom\")\n}\n\nObservemos que en la línea en que usamos el mutate(), el interprete espera que definamos literalmente el nombre de la variable que recibe la operación fct_infreq() y para que esta sea igual a la variable ingresada es útil el operador morsa. (sino nos devuelve Error)\nAplicado a una variable cualitativa con varias categorías nos genera:\n\nlibrary(datos)  # activamos el paquete datos para usar el dataset encuesta\n\nencuesta |&gt; barras_ordenadas(estado_civil)",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "extra.html#importar-funciones-propias",
    "href": "extra.html#importar-funciones-propias",
    "title": "Extra: Control de flujo y funciones",
    "section": "Importar funciones propias",
    "text": "Importar funciones propias\nUna de características más interesantes de las funciones creadas es que las podemos introducir en un script que llamaremos en nuestro sesión cada vez que necesitemos ejecutarlas.\nLa función source() nos permite llamar a ese o esos scripts externos y contar con las funciones a nuestra disposición.\nEntonces podemos automatizar algunas tareas, sobre todo en procesos repetitivos o que tienen un mismo procedimiento. Un ejemplo concreto en la epidemiología son las tareas vinculadas al análisis de datos provenientes de la vigilancia epidemiológica.\nLa forma de hacerlo es sencilla, si mi script de funciones se llama “funciones.R” ejecutamos:\n\nsource(\"funciones.R\")\n\nCada vez que lo hagamos dentro del script de trabajo tendremos a disposición todas las funciones que se encuentran declaradas dentro del archivo “funciones.R”.",
    "crumbs": [
      "Extra: Control de flujo y funciones"
    ]
  },
  {
    "objectID": "unidad1.html",
    "href": "unidad1.html",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "",
    "text": "El sitio oficial r-project.org dice que “R es un entorno de software libre para gráficos y computación estadística. Se compila y se ejecuta en una amplia variedad de plataformas UNIX, Windows y MacOS.”.\nProfundizando en su descripción podemos decir, técnicamente, que es un lenguaje de programación interpretado, orientado a objetos, multiplataforma y open source aplicado al manejo de datos estadísticos.\nA continuación detallamos cada parte de la definición:\nR es un lenguaje de programación estadístico\nR es un lenguaje de programación, con sus estructuras y reglas de sintaxis, que posee una gran variedad de funciones desarrolladas con fines estadísticos.\nR es un lenguaje Orientado a Objetos\nImplementa conceptos de la programación orientada a objetos y esto le permite ser simple y flexible en el manejo de datos. En R todo con lo que trabajamos es considerado un “objeto”: las variables, funciones, datos, resultados, etc. que pueden ser modificados por otros objetos.\nR es un lenguaje interpretado\nNo es necesario compilar los scripts de programación para construir ejecutables sino que directamente se ejecutan por medio del intérprete que devuelve resultados de forma inmediata.\nR es multiplataforma (corre en Linux, Windows y Mac)\nFunciona en diferentes sistemas operativos como Linux, Windows y Mac.\nR es Open Source y se distribuye bajo licencia GNU - GPL\nEsto quiere decir que se distribuye gratuitamente bajo licencia GNU (General Public License) – GPL y que los usuarios tienen la libertad de usar, estudiar, compartir (copiar) y modificar el software.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#qué-es-el-lenguaje-r",
    "href": "unidad1.html#qué-es-el-lenguaje-r",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "",
    "text": "El sitio oficial r-project.org dice que “R es un entorno de software libre para gráficos y computación estadística. Se compila y se ejecuta en una amplia variedad de plataformas UNIX, Windows y MacOS.”.\nProfundizando en su descripción podemos decir, técnicamente, que es un lenguaje de programación interpretado, orientado a objetos, multiplataforma y open source aplicado al manejo de datos estadísticos.\nA continuación detallamos cada parte de la definición:\nR es un lenguaje de programación estadístico\nR es un lenguaje de programación, con sus estructuras y reglas de sintaxis, que posee una gran variedad de funciones desarrolladas con fines estadísticos.\nR es un lenguaje Orientado a Objetos\nImplementa conceptos de la programación orientada a objetos y esto le permite ser simple y flexible en el manejo de datos. En R todo con lo que trabajamos es considerado un “objeto”: las variables, funciones, datos, resultados, etc. que pueden ser modificados por otros objetos.\nR es un lenguaje interpretado\nNo es necesario compilar los scripts de programación para construir ejecutables sino que directamente se ejecutan por medio del intérprete que devuelve resultados de forma inmediata.\nR es multiplataforma (corre en Linux, Windows y Mac)\nFunciona en diferentes sistemas operativos como Linux, Windows y Mac.\nR es Open Source y se distribuye bajo licencia GNU - GPL\nEsto quiere decir que se distribuye gratuitamente bajo licencia GNU (General Public License) – GPL y que los usuarios tienen la libertad de usar, estudiar, compartir (copiar) y modificar el software.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#breve-historia",
    "href": "unidad1.html#breve-historia",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Breve historia",
    "text": "Breve historia\nR fue desarrollado a partir del lenguaje S que tiene sus orígenes en Bell Labs de la AT&T (actualmente Lucent Technologies) de mediados de la década del ’70. Posteriormente, S fue vendido y dio origen a una versión propietaria denominada S-Plus que es comercializada por Insighful Corporation.\nEn 1995 dos profesores de estadística de la Universidad de Auckland, en Nueva Zelanda Ross Ihaka y Robert Gentleman, iniciaron el “Proyecto R”, con la intención de desarrollar un programa estadístico inspirado en el lenguaje S pero de dominio público.\nAunque se dice que R es un dialecto de S existen diferencias importantes en el diseño de ambos lenguajes.\nEl software está desarrollado en lenguaje C++ con algunas rutinas agregadas en Fortran) y su nombre se debe a la letra con la que inician los nombres de pila de sus autores (Ross y Robert).\nActualmente es mantenido por un grupo internacional de desarrolladores voluntarios denominado Core Development Team.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#scripts",
    "href": "unidad1.html#scripts",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Scripts",
    "text": "Scripts\nUn script es un archivo de texto plano con una lista secuencial de funciones y comandos del lenguaje R para ser ejecutado por el intérprete de R.\nScript se puede traducir como guión, archivo de órdenes, archivo de procesamiento por lotes o archivo de sintaxis.\nGeneralmente se crea en editores especiales y/o en cualquier procesador básico de texto plano. Se almacena en un archivo que puede ser leído, modificado, guardado y se puede ejecutar completo o línea a línea.\nPoseen una cualidad muy provechosa: son re-utilizables, adaptándolos a otras necesidades.\nDocumentación de los scripts de R:\nLa documentación es una tarea de mucha importancia en cualquier lenguaje de programación, ya que nos permite entender que estamos haciendo en el script. Además nos sirve para el futuro mantenimiento o para la reutilización del código elaborado, tanto para otros usuarios como para nosotros mismos.\nLa forma de documentar los scripts de código en R es utilizando comentarios. Toda línea que comienza con el símbolo # es entendido por el interprete como un comentario y los caracteres que sigan a ese símbolo no seran tenidos en cuenta cuando se ejecute ese código.\n\n# esto es una línea de comentario y no es tenida en cuenta por el intérprete\n\nAsí que a la hora de documentar es preferible abusar de estos comentarios que no utilizarlos.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#funciones",
    "href": "unidad1.html#funciones",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Funciones",
    "text": "Funciones\nLos comandos u órdenes elementales de R se denominan funciones. A algunas se las llama “integradas” porque están incluidas en el núcleo (R base) y sus nombres están reservados.\nTambien podemos utilizar otras pertenecientes a librerías (paquetes) que se pueden instalar y activar.\nToda función tiene un nombre y normalmente recibe argumentos o parámetros que deben ser escritos entre paréntesis y separados por comas. Incluso algunas de ellas que no tienen asociado ningún argumento necesitan finalizar con paréntesis () para ser entendidas como funciones.\nSiempre una función devuelve un resultado, un valor o realiza una acción.\n\n\n\n\n\n\n\n\n\nComo el interprete de R no permite errores en la sintaxis de las expresiones, debemos atender a los siguientes puntos a la hora de escribirlas:\n\nLa sintaxis habitual de una función y sus argumentos es la siguiente:\n\n\nfuncion(arg1, arg2, arg3,...)\n\n\nLos títulos de los argumentos pueden escribirse y mediante un igual agregar el valor correspondiente. También se puede omitir el título del argumento y escribir directamente el valor, pero en este caso, hay que respetar el orden definido por la función.\n\n\nfuncion(arg1=32, arg2=5, arg3=65,...)\n\nes igual a hacer:\n\nfuncion(32, 5, 65,...)\n\nsiempre que se respete el mismo orden.\n\nCon los argumentos se deben cumplir las mismas reglas que en todo el lenguaje. Los valores numéricos, lógicos, especiales y objetos van escritos en forma directa y cuando escribimos caracteres (texto) van necesariamente encerrados entre comillas.\n\n\nfuncion(arg1=3, arg2=NA, arg3=TRUE, arg4=\"less\", arg5=x,...)",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#librerías-paquetes",
    "href": "unidad1.html#librerías-paquetes",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Librerías (paquetes)",
    "text": "Librerías (paquetes)\nLas librerías son grupos de funciones empaquetados que se pueden instalar y utilizar en el análisis de datos. Habitualmente se agrupan por tema o similitud de funciones.\nEstos paquetes se pueden descargar directamente del repositorio oficial de CRAN en Internet (similar al uso de los repositorios de Linux) o bien descargar en formato .zip para luego instalar y usar.\nSe pueden activar y desactivar en cualquier momento del análisis.\nAlgunos poseen dependencias de otros paquetes que serán necesarios para que funcione.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#sintaxis-errores-y-advertencias",
    "href": "unidad1.html#sintaxis-errores-y-advertencias",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Sintaxis, errores y advertencias",
    "text": "Sintaxis, errores y advertencias\nEl lenguaje es muy preciso en su sintaxis y equivocarse en la forma de escribir una función o cualquier otro objeto produce respuestas de error del interprete de R que es habitual cuando iniciamos el aprendizaje.\nLa exactitud en la escritura de comandos y funciones incluye la distinción entre mayúsculas y minúsculas. Es decir, que no es lo mismo una ‘a’ que una ‘A’.\nExisten tres grupos de mensajes de error:\n\nerror de sintaxis\nerror de objeto no encontrado\notros errores\n\nSe dice que hay un error de sintaxis, cuando ejecutamos una línea de código que el motor de R no puede interpretar debido a que algo está mal escrito.\nHabitualmente los errores de sintaxis se deben a que falta o sobra algún elemento necesario en la estructura de una función (comas, parentesis, llaves, corchetes, comillas, etc.)\nPor ejemplo la función rep() repite valores una cantidad de veces. Tiene dos argumentos, x donde se coloca el valor a repetir y times donde se define la cantidad de veces.\n\nrep(x = 3, times = 4) #repetimos 4 veces 3 con rep()\n\n[1] 3 3 3 3\n\n\nSi nos olvidamos de cerrar el paréntesis…\n\nrep(x = 3, times = 4\n    \nError: Incomplete expression: rep(x = 3, times = 4\n\nSi nos olvidamos de separar los argumentos con la coma\n\nrep(x = 3 times = 4)\n\nError: unexpected symbol in \"rep(x =3 times\"\n\nSi en lugar de escribir x como primer argumento y escribimos otra letra…\n\nrep(y =3, times = 4)\n\nError in rep(y = 3, times = 4) : \n  attempt to replicate an object of type 'symbol'\n\nSi escribimos mal la función…\n\nREP(x =3, times = 4)\n\nError in REP(x = 3, times = 4) : no se pudo encontrar la función \"REP\"\n\nEsta última posibilidad es similar a un “objeto no encontrado” por error de sintaxis.\nLos mensajes de error en general y sobre todo al principio pueden parecer extraños y difíciles de entender, pero con un poco de práctica podemos inferir donde está el problema.\nLos errores de objetos no encontrados pueden tener una de varias causas:\n\nel nombre no se escribió correctamente (p.ej.: sintaxis, mayúsculas / minúsculas)\nel paquete o archivo que contiene el objeto no ha sido cargado\nolvidamos poner comillas en un lugar que corresponde\notros motivos posibles\n\nVolvamos al ejemplo anterior, ahora repitiendo un valor tipo character\n\nrep(x = \"A\", times = 4) #repetimos 4 veces 3 con rep()\n\n[1] \"A\" \"A\" \"A\" \"A\"\n\n\nSi olvidamos las comillas…\n\nrep(x = A, times = 4) #repetimos 4 veces 3 con rep()\n\nError: objeto 'A' no encontrado\n\nAdvertencias\nUna advertencia no es algo tan serio, como un error, o al menos no lo parece, ya que esta permite que la función se ejecute igual. Pero puede ocurrir que ignorar una advertencia llegue a ser algo muy serio, si esto implica que la salida de la función es equivocada.\nPor lo tanto, es una buena política entender los mensajes de advertencia para ver si indican problemas para preocuparnos o no.\nResumiendo:",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#creación-de-objetos",
    "href": "unidad1.html#creación-de-objetos",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Creación de objetos",
    "text": "Creación de objetos\nTodas las declaraciones donde se crean objetos, tienen este símbolo de asignación &lt;-.\n\nnombre_objeto &lt;- valor\n\nVeámoslo en un ejemplo:\n\na &lt;- 1\n\nEn este caso asignamos el valor 1 al objeto a. El objeto a es un vector de una posición (un solo valor).\nSi llamasemos al objeto a, el interprete nos devuelve el valor asignado previamente.\n\na\n\n[1] 1\n\n\nObservemos que además de devolvernos el valor aparece delante un 1 entre corchetes [1].Este número es la ubicación o índice del comienzo del objeto, que en este caso tiene una sola posición.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#estructuras-de-datos",
    "href": "unidad1.html#estructuras-de-datos",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Estructuras de datos",
    "text": "Estructuras de datos\nLos objetos contenedores de datos más simples pertenecen a cinco clases que se denominan atómicas y que son los siguientes tipos de datos:\n\ninteger (números enteros)\nnumeric / double (números reales)\ncomplex (números complejos)\nchacacter (cadena de caracteres)\nlogical (lógicos o booleanos – toman valores por si o no)\n\n\n\n\n\n\n\n\n\n\nSin embargo, cada una de estas clases de datos no se encuentran de manera aislada, sino encapsulados dentro de la clase de objeto operacional más básica del lenguaje a la que se denomina vector.\nVector\nUn vector es un conjunto de valores (números o símbolos), todos del mismo tipo ordenados de la forma (elemento 1, elemento 2, … , elemento \\(n\\)) y \\(n\\) es la longitud o tamaño del vector.\nSurge de la definición dos términos importantes: el tipo y la longitud.\nTodos los objetos de datos tienen estos dos atributos intrínsecos.\n\nel tipo, que puede ser integer, numeric, chacacter, complex y logical\nla longitud, que es el número de elementos que contiene el objeto.\n\nEl vector más simple es el que contiene un dato, podría ser numérico de un solo dígito. El tipo sería numeric y la longitud 1.\n\nvec1 &lt;- 1\nvec1\n\n[1] 1\n\n\nOtro vector más grande por ejemplo podría ser (1,5,2). En este caso también es del tipo numeric pero tiene una longitud de 3 elementos (3 posiciones que integran el vector).\n\nvec2 &lt;- c(1,5,2)\nvec2\n\n[1] 1 5 2\n\n\nComo vemos, para concatenar estos tres valores numéricos usamos la forma c(). Esta c es una función de R, justamente para concatenar. (todo lo que aparece siempre antes de paréntesis es una función). Dentro de la función los valores van separados por comas.\nAquí podemos señalar otra característica, según la definición de vector, la colección de elementos se encuentra ordenada, por lo que en nuestro ejemplo la primera posición la ocupa el 1, la segunda el 5 y la tercera el 2. Como el orden importa, si tuviese otro vector (5,1,2), a pesar de tener los mismos elementos no sería el mismo vector porque están ordenados de forma diferente.\nPara ver la longitud del vector usamos:\n\nlength(vec2)\n\n[1] 3\n\n\nNos informa que vec2 tiene 3 elementos.\nAsimismo podemos ver que los datos almacenados en este segundo ejemplo cumplen con la definición en lo que respecta al tipo de dato, ya que cada elemento es del mismo tipo (numeric).\nPara conocer la clase del dato ejecutamos:\n\nclass(vec2)\n\n[1] \"numeric\"\n\n\nVeamos un ejemplo de asignación de otro tipo de dato atómico, como es el character:\n\nvec3 &lt;- \"Hola\"\nvec3\n\n[1] \"Hola\"\n\n\nSiempre que escribamos contenido de tipo caracter debemos hacerlo entre comillas. En este caso generamos el vector vec3 con el contenido “Hola”. A pesar de ser una palabra que, por supuesto, esta compuesta de varios caracteres, dentro del vector vec3 esta ocupa una sola posición.\n\nlength(vec3)\n\n[1] 1\n\n\nRespecto a la clase del dato si usamos la función class() tendremos:\n\nclass(vec3)\n\n[1] \"character\"\n\n\nDataframe\nUn dataframe es un objeto cuya finalidad es contener conjuntos de datos. Se asemeja a una tabla que tiene filas y columnas (dos dimensiones), donde cada columna puede almacenar elementos de diferentes tipos.\nAdemás las columnas suelen tener nombres únicos y podemos referenciarlas por estos nombres, como si fueran variables del conjunto de datos.\nEs el tipo de objeto que utilizamos para almacenar información leída de tablas de datos provenientes de archivos externos (formato texto separado por comas, Excel, etc) y con las cuales acostumbramos a trabajar en el análisis.\nDesde el punto de vista de su estructura, todo dataframe esta conformado por una serie de vectores de la misma longitud ubicados verticalmente uno al lado de otro.\nPodemos verlo en la siguiente porción de código:\n\nHC &lt;- c(\"F324\", \"G21\", \"G34\", \"F231\")\nedad &lt;- c(34,32,34,54)\nsexo &lt;- c(\"M\", \"H\", \"H\", \"M\")\n\ndf1 &lt;- data.frame(HC, edad, sexo)\n\ndf1\n\n    HC edad sexo\n1 F324   34    M\n2  G21   32    H\n3  G34   34    H\n4 F231   54    M\n\n\nCreamos tres vectores con datos de supuestos individuos, su historia clinica, la edad y el sexo. Luego mediante la función data.frame() “unimos” esos vectores en forma vertical para formar un dataframe de 3 variables y 4 observaciones.\nExisten otras estructuras de datos que aparecen en la siguiente figura. Las más habituales en nuestro trabajo son los vectores y los dataframes.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#videos-sobre-objetos",
    "href": "unidad1.html#videos-sobre-objetos",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Videos sobre Objetos",
    "text": "Videos sobre Objetos",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#operadores-en-r",
    "href": "unidad1.html#operadores-en-r",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Operadores en R",
    "text": "Operadores en R\nAdemás de funciones, el lenguaje R cuenta con operadores similares a otros lenguajes de programación, que permiten realizar operaciones con datos.\n\nR como calculadora\nEl lenguaje R cuenta con operadores aritméticos de uso relativamente intuitivo, que permiten realizar operaciones matemáticas como si usasemos una calculadora.\n\n\n\n\n\n\n\n\n\n\n# suma\n2 + 5\n\n[1] 7\n\n# resta\n3 - 2\n\n[1] 1\n\n# multiplicación\n9 * 3\n\n[1] 27\n\n# división\n10 / 2\n\n[1] 5\n\n# potenciación\n5 ^ 2\n\n[1] 25\n\n\nNota: observarán que el interprete del lenguaje al devolvernos un valor en consola lo muestra con una notación inicial de un 1 encerrado entre corchetes [1]. Este número es el índice del vector que nos está mostrando R y que siempre comienza con 1. Si la cantidad de elementos de un vector mostrados por la consola superase el ancho de la pantalla, entonces el listado seguiría debajo y al comienzo de la nueva línea veríamos otro número entre corchetes que sería el indice de ese primer valor. Veamos un ejemplo:\n\n\n [1] 0.10 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24\n[16] 0.25 0.26 0.27 0.28 0.29 0.30 0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39\n[31] 0.40 0.41 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.50 0.51 0.52 0.53 0.54\n[46] 0.55 0.56 0.57 0.58 0.59 0.60 0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n[61] 0.70 0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.80 0.81 0.82 0.83 0.84\n[76] 0.85 0.86 0.87 0.88 0.89 0.90\n\n\nEl 0.25 que es primer valor de la segunda fila esta en la posición 16 de ese vector de números. Y, por ejemplo, el 0.70 en la posición 61.\nPara otras operaciones matemáticas como la raíz cuadrada o el valor absoluto de un múmero, existen funciones específicas incluídas en R base.\n\n# radicación (raíz cuadrada)\nsqrt(9)\n\n[1] 3\n\n# valor absoluto\nabs(-3)\n\n[1] 3\n\n\nTambién se pueden hacer operaciones con los objetos que almacenan a estos valores numéricos asignados:\n\n# a contiene el valor 3\na &lt;- 3\n\n# b contiene el valor 6\nb &lt;- 6\n\n# aplicamos una fórmula determinada\n(a + b) * b\n\n[1] 54\n\n\nY funciona con objetos como los vectores que contienen más de un elemento, aplicando artimética vectorial, donde las operaciones se realizan elemento a elemento.\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# ejecutamos una operación matemática a todos los elementos de a\na * 3\n\n[1] 3 6 9\n\n\nO bien, con operaciones entre objetos, donde se las operaciones se realizan entre los elementos de la misma posición:\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# ejecutamos una operación matemática a todos los elementos de a * a\na * a\n\n[1] 1 4 9\n\n\nMediante sum() se puede hacer sumatorias de elementos en vectores numéricos.\n\n# creamos el vector a con 3 elementos\na &lt;- c(1, 2, 3)\n\n# realizamos una sumatoria de todos los elementos de a\nsum(a)\n\n[1] 6\n\n\nOtra función muy utilizada es la que permite que redondeemos valores con decimales.\n\n## redondeamos definiendo 2 digitos decimales\n\nround(23.76859, digits = 2)\n\n[1] 23.77",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#concatenación-y-secuencias-regulares",
    "href": "unidad1.html#concatenación-y-secuencias-regulares",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Concatenación y secuencias regulares",
    "text": "Concatenación y secuencias regulares\nYa usamos la función c() para concatenar elementos. Habitualmente cuando deseemos crear vectores con más de un elemento vamos a recurrir a esta función.\n\n# vector numérico de 4 elementos\nc(6, 3, 6, 8)\n\n[1] 6 3 6 8\n\n# vector caracter de 2 elementos\nc(\"Hola\", \"Chau\")\n\n[1] \"Hola\" \"Chau\"\n\n\nExiste otra forma de concatenar elementos a partir de un operador de rango. Produce un intervalo secuencial de enteros que puede ser ascendente o descendente. El operador es : y se usa de la siguiente forma:\n\n# ascendente\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# descendente\n10:1\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\nOtra manera es por medio de la función seq() que tiene como argumentos principales from, to y by\n\n# secuencia de 1 a 20 cada 2\nseq(from = 1, to = 20, by = 2)\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\nAlgunos otros ejemplos de la misma función pueden ser:\n\n# secuencia de 0.1 a 0.9 cada 0.1\nseq(from = 0.1, to = 0.9, by = 0.1)\n\n[1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\n\n# secuencia de -5 a 5 cada 1\nseq(from = -5, to = 5, by = 1)\n\n [1] -5 -4 -3 -2 -1  0  1  2  3  4  5\n\n# secuencis de 300 a 0 cada 50 (se escribe -50 porque es descendente)\nseq(from = 300, to = 0, by = -50)\n\n[1] 300 250 200 150 100  50   0\n\n\nFinalmente la última posibilidad que vamos a mostrar es la función rep() que repite valores. Su forma más sencilla es rep(x, times = Nº) que coloca un Nº de repeticiones de x, una tras otra.\nAlgunos ejemplos de la función:\n\n# repetimos 5 veces el número 2\nrep(x = 2, times = 5)\n\n[1] 2 2 2 2 2\n\n# combinada con el operador de rango\nrep(1:4, 5)  \n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4\n\n# combinada con la función de concatenación\nrep(c(4.5,6.8,7.2), 2) \n\n[1] 4.5 6.8 7.2 4.5 6.8 7.2\n\n\nTambién existen operadores relacionales y conectores lógicos que vamos a ver más adelante, cuando por ejemplo, necesitemos construir condiciones para filtrar subconjuntos de datos.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#valores-especiales-en-r",
    "href": "unidad1.html#valores-especiales-en-r",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Valores especiales en R",
    "text": "Valores especiales en R\nExisten algunos valores especiales para datos con expresiones reservadas en R, entre ellos encontramos los valores NA, NaN, Inf y NULL.\n\n\n\n\n\n\n\n\n\nEl más relevante de estos valores especiales es el NA que sirve para indicar la inexistencia de valor.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#rstudio",
    "href": "unidad1.html#rstudio",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "RStudio",
    "text": "RStudio\nUna vez instalado el software (R + RStudio + Rtools) tenemos todo lo necesario para comenzar a trabajar con el lenguaje R.\nEn principio, aunque instalamos tres programas, el único que debemos ejecutar para ponernos a trabajar es RStudio. Éste se encarga de utilizar a R como motor/interprete y a Rtools si llegamos a necesitar instalar algún paquete desarrollado en C/C++ o Fortran. (proceso desantendido al que no deberemos prestar atención)",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#proyectos-de-rstudio",
    "href": "unidad1.html#proyectos-de-rstudio",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Proyectos de RStudio",
    "text": "Proyectos de RStudio\nLos proyectos de RStudio se utilizan para organizar todo el código, los resultados y salidas, las fuentes de datos y cualquier otro archivo utilizado en un análisis.\nLa organización del trabajo en proyectos es muy útil para asegurarnos que cada vez que necesitemos importar datos, RStudio los buscará dentro de la carpeta asociada al proyecto.\n\nCrear un nuevo proyecto de RStudio\nCreamos un nuevo proyecto de RStudio seleccionando la opción File y luego New Project … de la barra de menú en la parte superior de la pantalla de RStudio como se muestra en la siguiente figura.\n\n\n\n\n\n\n\n\n\nTambién accedemos a generar un proyecto nuevo a partir de pulsar sobre New Project… del menú desplegado en el extremo derecho superior de la interface de RStudio.\n\n\n\n\n\n\n\n\n\nEn cualquiera de los dos casos aparecerá un cuadro de diálogo que presenta algunas opciones para crear el nuevo proyecto de RStudio.\n\n\n\n\n\n\n\n\n\nPor lo general, seleccionaremos la primera opción, New Directory, que crea una nueva carpeta a la que deberemos colocarle un nombre. Esta es la forma de crear un nuevo proyecto cuando aún no tenemos archivos dentro de alguna carpeta con los que deseemos trabajar.\nEn el caso que tengamos algunos archivos de código o archivos de datos con los que necesitemos trabajar, podemos elegir la segunda opción, Existing Directory. El proyecto tomará el nombre de la carpeta que seleccionemos en forma predeterminada.\n\n\nTipos de proyectos\nExisten varios tipos de proyectos pero nosotros en este curso utilizaremos solo la primera opción, que nos abre la siguiente ventana.\n\n\n\n\n\n\n\n\n\nDebemos completar los dos campos.\nEn Directory name hay que escribir el nombre de la nueva carpeta que también será el nombre de nuestro proyecto.\nEn Create Project as subdirectory of: podemos pulsar sobre el botón Browse… y navegar por nuestro Explorador de Archivos hasta ubicar la carpeta donde queremos que se ubique el nuevo proyecto con su nueva carpeta asociada.\nFinalmente hacemos click en el botón Create Project.\nSupongamos que nombremos a nuestro nuevo proyecto como “Practica R” y que lo generamos dentro de la carpeta Mis Documentos.\n\n\n\n\n\n\n\n\n\nEste nuevo proyecto de RStudio se almacenará en la carpeta Practica R que encontraremos en Mis Documentos.\nLos proyectos de RStudio tienen sus propios entornos, por lo que si cerramos o cambiamos de proyecto, nuestra configuración se mantendrá inalterable.\nEsto es cierto para los scripts y cualquier otra cosa que se pueda necesitar para un análisis, mientras esté almacenado dentro de esa carpeta de trabajo.\nEchemos un vistazo a lo que RStudio realizó.\n\n\n\n\n\n\n\n\n\nEn la figura anterior podemos ver dos cambios en la pantalla de inicio.\nEn primer lugar el panel Files (pantalla inferior derecha) apunta a la nueva carpeta Practica R y dentro de ella vemos un nuevo archivo el nombre del proyecto y la extensión Rproj. Este archivo contiene todas las configuraciones del proyecto.\nEl otro cambio se observa en la parte superior derecha, que muestra el nombre del proyecto activo.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#scripts-1",
    "href": "unidad1.html#scripts-1",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Scripts",
    "text": "Scripts\nComo dijimos en Introducción al lenguaje R un script es un archivo de código que contiene un listado secuencial de funciones para ser ejecutadas por el interprete. Estos archivos permiten guardar el código que vamos creando y volver a utilizarlo tantas veces como se quiera, además de poder compartirlo con otras personas.\n\nCómo creamos un script nuevo en RStudio?\nTenemos dos formas de crear un script nuevo. Desde el menú superior pulsando File &gt; New File &gt; R Script (atajo Ctrl+Shift+N) o con el ícono del documento con un símbolo +, como se muestra debajo.\n\n\n\n\n\n\n\n\n\n\n\nCómo editamos un script en RStudio?\nSi queremos comenzar a escribir código o modificar alguna línea ya escrita vamos a utilizar el editor de código.\nEste editor posee algunas herramientas especiales que nos facilitan el trabajo, evitando problemas de sintaxis entre otras ventajas.\nEstas herramientas las vamos a detallar más adelante.\n\n\nCómo ejecutamos un script en RStudio?\nLa forma de ejecutar habitualmente el código escrito, es línea por línea mediante el uso de la combinación de teclas Ctrl+Enter o el botón Run del editor de código de RStudio. Para esto tenemos que tener el cursor activo en la línea que queremos correr (puede ser en cualquier parte de la línea) y luego de ser ejecutada el cursor saltará automáticamente a la siguiente línea que tenga código.\nMientras ejecutamos cada línea debemos ir observando la salida en la consola y también los cambios que se dan en el bloque Environment (Entorno) donde aparecerán los objetos que vayamos creando y modificando.\n\n\nCómo guardamos un script en RStudio?\nCualquier código agregado o modificación que hayamos realizado al script que nos interese mantener nos obligará a guardar el archivo.\nBasta con pulsar sobre el ícono del diskette celeste del editor de código para guardar el script, o bien hacerlo desde el menú principal File &gt; Save o presionando el atajo Ctrl+S.\nSi en cambio quisiera guardarlo como otro archivo para mantener el script original, podemos guardarlo con diferente nombre mediante File &gt; Save As…\n\n\nCómo abrimos un script en RStudio?\nLos scripts que construyamos o bien que nos compartan siempre tendrán extensión .R y generalmente, se encontrarán dentro de algún proyecto.\nPara abrir estos archivos .R podemos pulsar sobre ellos dentro del panel Files (abajo a la derecha) o bien desde el manú con File &gt; Open file… (atajo de teclado Ctrl+O)\nVisualizaremos el script en una nueva pestaña en el editor de código.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#herramientas-de-rstudio",
    "href": "unidad1.html#herramientas-de-rstudio",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Herramientas de RStudio",
    "text": "Herramientas de RStudio\n\nAsistente de código\nCuando escribimos desde el teclado en el editor de código o en la consola de RStudio, aparece un asistente de forma automática que autocompleta las funciones que vamos tipeando.\nEsta herramienta de autocompletado también se ejecuta pulsando la tecla de tabulación (Tab) y nos muestra las posibilidades de finalizar las palabras que vamos escribiendo junto al esquema de argumentos obligatorios que tiene asociado dicha función. Solo debemos presionar Enter para seleccionar el término correcto.\n\n\n\n\n\n\n\n\n\nAl sistematizar la escritura de código apoyandonos en el uso del autocompletado vamos a reducir la tasa de errores de sintaxis, dado que las funciones, los argumentos y los nombres de las tablas y variables de nuestros datos van a estar correctamente escritos.\n\n\nAyuda en línea\nSi necesitamos acceder a una ayuda adicional en línea bastará que presionemos la tecla F1 con el cursor situado sobre el nombre de la función escrita en el editor de código para que aparezca la información relacionada en el bloque Help de Rstudio (generalmente panel abajo a la derecha).\n\n\n\n\n\n\n\n\n\n\n\nHistorial de funciones\nOtra característica de utilidad dentro de la Consola de RStudio es que si nos situamos en el prompt activo, y pulsamos las teclas flecha hacia arriba o abajo, veremos pasar la lista completa de código ejecutado en la sesion de trabajo.\nEsto nos ayuda a la hora de volver a ejecutar una función o bien cuando debemos hacer alguna corrección de la o las líneas anteriores, puesto que nos ahorra tiempo y trabajo evitando volver a tener que tipear lo que ya escribimos.\nEste historial de funciones también lo encontramos en el bloque superior derecho de RStudio, dentro de la pestaña History.\nHistory almacena todos las funciones ejecutados en consola de forma acumulativa, incluso anidando sesión tras sesión.\nLos comandos que aparecen en ese panel se pueden copiar y pegar en la Consola o, de forma más directa, puedes seleccionar uno de ellos con el mouse, y pulsar en el botón To Console (Enter) para insertarlo en consola o To Source (Shitft+Enter) para insertarlo en el script activo en el que estemos trabajando.\n\n\n\n\n\n\n\n\n\n\n\nAtajos de teclados relevantes (para Windows)\n\n\n\n\n\n\n\nMenú Archivo (File)\n\n\n\n\n\nCtrl+Shift+N\nCrea un nuevo script\n\n\nCtrl+O\nAbre un script guardado\n\n\nCtrl+S\nGuarda el script activo\n\n\nCtrl+W\nCierra el script activo\n\n\nCtrl+Q\nSale del programa RStudio\n\n\nMenú Edición (Edit)\n\n\n\nCtrl+F\nAbre la ventana de búsqueda (para buscar palabras dentro de un script)\n\n\nCtrl+L\nLimpia la consola\n\n\nMenú Código (Code)\n\n\n\nCtrl+Enter\nEjecuta la línea de código donde está situado el cursor\n\n\nCtrl+Alt+R\nEjecuta todo el código del script activo",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#paquetes-librerías",
    "href": "unidad1.html#paquetes-librerías",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Paquetes (librerías)",
    "text": "Paquetes (librerías)\nR consta de un sistema base y de librerías adicionales, llamados paquetes (packages) que extienden su funcionalidad.\nSiendo open source cualquier persona puede construir paquetes con nuevas funciones, aunque no todos se publican en el repositorio CRAN (Comprehensive R Archive Network).\nUn grupo de paquetes conforman el sistema base que quedan activos cuando instalamos el software R.\nOtros paquetes se encuentran publicados en el repositorio para ser descargados cuando sea necesario. Actualmente existen más de 22000 paquetes para múltiples aplicaciones.\nExisten dos formas de descargar estos paquetes, directamente desde RStudio/R y por medio del sitio web, descargándolos como archivos comprimidos .zip\nSi el equipo se encuentra conectado a Internet es más cómodo realizar las descargas desde RStudio, pero en el caso de no tener acceso permanente a la red, se pueden descargar desde la web en otro equipo y luego guardar en el equipo donde tenemos el programa R.\nEl sitio web para las descargas de los paquetes publicados es https://cran.r-project.org/web/packages/\nAllí se encuentran los enlaces para ver el listado de paquetes ordenados alfabéticamente o por fecha de publicación.\nUna vez que ingresamos al link del paquete que nos interesa veremos en la página algunos datos relacionados como un breve texto de que trata el paquete, el numero de versión, la fecha de publicación, el autor, el archivo de documentación, y por supuesto los archivos a descargar para cada sistema operativo.\nAfortunadamente en la actualidad la mayoría de las computadoras cuentan con acceso a Internet por lo cual explicaremos como se puede descargar, instalar y activar los paquetes desde RStudio.\nRStudio tiene una pestaña específica para gestionar los paquetes ubicada de forma predeterminada en el bloque inferior derecho de la interfaz (Packages)\n\n\n\n\n\n\n\n\n\nPrácticamente todos las acciones que nos facilita la interfaz de RStudio se traduce internamente en ejecuciones de funciones de R que podemos ver en la consola.\nLa secuencia para instalar un paquete que no tengamos previamente instalado inicia a partir de pulsar el botón Install y la ventana emergente que visualizaremos es la siguiente:\n\n\n\n\n\n\n\n\n\n\nDependencias\nLa gran mayoría de las funciones que integran los paquetes que podemos descargar y utilizar están construidas en el mismo lenguaje R y para su elaboración se usan muchas veces funciones pertenecientes a otros paquetes.\nQue pasa cuando queremos ejecutar una función que necesita de otra que no tenemos instalada? Sucede que no es posible ejecutarla dado que no puede encontrar la o las funciones que están siendo llamadas en su propio código y no existen en la actual instalación de R; por lo tanto nos devolverá un mensaje de error alertando por la función desconocida.\nEsta relación de funciones que llaman a otras funciones se denomina dependencia. Es decir, que un paquete puede depender de otro u otros que tienen funciones que son llamadas y por ende, debe asegurarse su previa instalación para evitar el error.\nHay una forma de asegurarnos cuando instalamos un paquete que a su vez se instalen los paquetes del cual depende y es marcando la opción Install dependencies en la ventana anterior (Install Packages).",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#lectura-de-archivos-de-datos",
    "href": "unidad1.html#lectura-de-archivos-de-datos",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Lectura de archivos de datos",
    "text": "Lectura de archivos de datos\nEl lenguaje nos permite importar variados formatos de tablas de datos utilizando funciones propias de R base como de paquetes que se dedican a esta tarea.\nEl formato nativo de tablas de datos de R es el texto plano (UTF-8) con sus columnas separadas por algún caracter. Estos pueden ser caracteres habituales como la coma (,) o el punto y coma (;) que da lugar a la extensión *.csv, o algunos especiales como la barra vertical (|) que suele utilizar el INDEC para sus productos o bien cualquier otro, como espacios o la tabulación.\nOtra característica que tienen estos archivos es que generalmente poseen una cabecera donde se ubican los nombres de cada columna/variable y por supuesto que cada una de ellas debe respetar un mismo tipo de dato para cumplir con la condición que la hace una tabla/base de datos.\nLo más importante para hacer una buena lectura de la tabla de datos con la que deseamos trabajar es conocer previamente el formato que tiene, si tiene cabecera, que caracter usa como separador de columnas, etc. Al ser un texto plano se puede abrir desde un simple Block de Notas de Windows o desde el mismo RStudio para conocer sus particularidades.\nActualmente y dentro del ecosistema con el que vamos a trabajar durante este curso hay un paquete con funciones diseñadas para importar estos tipos de archivos. Se llama readr y su fuerte es detectar el formato que tiene cada columna en el momento de la lectura.\nPosee una familia de funciones analizadoras donde se destacan:\n\nread_csv(): archivos separados por comas (CSV)\nread_delim(): archivos separados con delimitadores generales\nread_tsv(): archivos separados por tabulaciones\nread_fwf(): archivos con columnas de ancho fijo\nread_table(): archivos formato tabla con columnas separadas por espacios\n\nTodas estas funciones tiene argumentos comunes, además de file = donde se declara el nombre del archivo a importar entre comillas. Algunos de estos argumentos importantes son:\ncol_names = con TRUE le indicamos que la primera fila contiene los nombres de las columnas (con FALSE lo negamos)\nskip = salteamos una cantidad determinada de líneas que el archivo puede contener. En el caso que existan textos que no pertenecen al formato de la tabla de datos.\nlocale = es la configuración regional que el arhivo puede tener. Estos incluyen:\n\nLas marcas decimales y de agrupación, utilizadas al leer números.\nLa codificación de caracteres, utilizada al leer cadenas que no son ASCII.\nLos nombres de meses y días, utilizados al analizar fechas.\nLa zona horaria predeterminada, utilizada al analizar fechas y horas.\n\nLa adecuada configuración de este argumento evitará que palabras que tengan acentos o eñes o diferentes formatos de fecha sean bien reconocidos.\nPor lo tanto, nuestra tarea es hacer coincidir el formato de origen del archivo a leer con la función y los argumentos correctos.\nDurante el proceso de importación, decíamos que las funciones analizan columna por columna a que tipo de dato pertenecen. Los posibles tipos de datos son: character, integer, numeric, double, logical y date/time.\nPor ejemplo, si tenemos un archivo con punto y coma de separador, vamos a utilizar read_csv2() y si queremos importar la tabla de datos que ofrece el INDEC para los datos de las Encuestas Nacionales de Factores de Riesgo utilizaremos read_delim() declarando “|” dentro del argumento delim = (única función de la familia que la incorpora).",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#agunas-buenas-prácticas-de-trabajo",
    "href": "unidad1.html#agunas-buenas-prácticas-de-trabajo",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Agunas buenas prácticas de trabajo",
    "text": "Agunas buenas prácticas de trabajo\n\nAgrupar nuestros datos, scripts y resultados dentro de proyectos de RStudio (Rproj)\nDeclarar en el inicio de los scripts la activación de paquetes necesarios para ejecutar las funciones incluídas en el código. ( función library() )\nDocumentar el código que vayamos creando por medio de comentarios (iniciados con #)\nCumplir con un correcto estilo de codificación (Intentar utilizar espacios e identación adecuada para que el código sea de fácil lectura).",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#introducción-a-tidyverse",
    "href": "unidad1.html#introducción-a-tidyverse",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Introducción a tidyverse",
    "text": "Introducción a tidyverse\nTidyverse es el nombre que se ha dado al conjunto de paquetes desarrollados a partir de la inciativa de Hadley Wickham (jefe científico de Posit -antes RStudio-) y su equipo, para ciencia de datos con R.\nEstos paquetes están diseñados para funcionar juntos y comparten una misma filosofía, que se puede consultar en The tidy tools manifesto.\nLos cuatro principios básicos en los que se basa son:\n\nReutilizar las estructuras de datos\nResolver problemas complejos combinando varias piezas sencillas\nUtilizar programación funcional\nDiseñado para humanos\n\nLos paquetes incluidos en el tidyverse tienen como objetivo cubrir todas las fases del análisis de datos dentro de R: importar datos, ponerlos en formato ordenado (tidy data), buscar relaciones entre ellos (mediante su transformación, visualización y creación de modelos) y comunicar los resultados.\nLa palabra “tidy” se puede traducir como “ordenado” y refiere a que los datos deben cumplir con una estructura determinada donde:\n\nCada variable es una columna de la tabla de datos.\nCada observación es una fila de la tabla de datos.\nCada tabla responde a una unidad de observación o análisis.\n\n\n\n\n\n\n\n\n\n\nAdemás de los paquetes principales que realizan estas funciones, al instalar el tidyverse también se proporcionan otros que ayudan a trabajar con fechas, cadenas de caracteres o factores siguiendo los mismos principios.\nUna de las interesantes incorporaciones transversales en el ambiente tidyverse es el uso de tuberías (pipe en inglés).\nUna tubería conecta un trozo de código con otro mediante el conector %&gt;% que surge del paquete magrittr que permite transformar llamadas de funciones anidadas (con muchos paréntesis) en una simple serie de operaciones que son más fáciles de escribir y comprender. Este aporte fue tan importante que el equipo de desarrolladores que mantiene el lenguaje R incorporó la idea a partir de la versión 4.1.0 de 2021, agregando la funcionalidad nativa con el operador |&gt;.\nNota: durante el curso pueden llegar a coexistir ambas tuberías, dado que funcionan igual. De todas maneras, al utilizar versiones actualizadas del lenguaje preferimos utilizar la tubería nativa que es más eficiente que la propia del tidyverse.\nLa idea de tubería responde al principio donde cada función es un paso y la forma de trabajar se puede ver en el siguiente esquema general:\n\n\n\n\n\n\n\n\n\nBase gramatical\nLa intención de los desarrolladores para este conjunto de paquetes es lograr incorporar una gramática a la sintaxis de las funciones y sus argumentos buscando un entendimiento semántico más claro.\nUna prueba de ello, es que la mayoría de las funciones son verbos que se entrelazan con objetos y argumentos que permiten construir “frases”.",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#el-paquete-de-paquetes",
    "href": "unidad1.html#el-paquete-de-paquetes",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "El paquete de paquetes",
    "text": "El paquete de paquetes\nEl paquete tidyverse nucleo actual (versión 2.0.0) se puede descargar del repositorio oficial CRAN mediante menú Packages de RStudio o ejecutando en consola:\n\ninstall.packages(\"tidyverse\")\n\nSe activa, como cualquier otro paquete, mediante:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nObservamos que nos informa sobre la versión del paquete, el listado de paquetes que acabamos de activar sólo llamando a tidyverse y una serie de conflictos de nombres de funciones.\nEsto es muy habitual cuando activamos varios paquetes, dado que las funciones que se encuentran dentro de ellos pueden llamarse iguales.\nPor ejemplo, existe en el paquete base stats y en el paquete dplyr (que es parte de tidyverse) una función llamada filter(), por lo tanto al activar tidyverse nos informa de esta manera: dplyr::filter() masks stats::filter()\nEn este caso, cuando necesitemos asegurarnos que la función que deseamos ejecutar pertenece a determinado paquete, es recomendable escribirla de la siguiente forma:\n\nnombre_paquete::nombre_función\n\nstats::filter() para la función filter() del paquete stats\ndplyr::filter() para la función filter() del paquete dplyr\nLos paquetes incluidos que se instalan en esta versión son 31:\n\ntidyverse_packages()\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nExisten otros paquetes (la cantidad crece con el tiempo) que son creados bajo la misma filosofía pero no están incluidos. En esos casos hay que instalarlos y activarlos individualmente.\nPara profundizar sobre tidyverse se puede visitar el sitio https://www.tidyverse.org/ y la primera versión del libro traducido al español r4ds. La segunda versión está disponible en inglés en r4ds(2e)",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad1.html#lectura-y-escritura-de-datos",
    "href": "unidad1.html#lectura-y-escritura-de-datos",
    "title": "Unidad 1: Introducción al lenguaje R",
    "section": "Lectura y escritura de datos",
    "text": "Lectura y escritura de datos\n\nPaquete readr\nreadr contiene funciones similares a las de la familia read.table() de R base pero desarrollados bajo el ecosistema tidyverse.\nLos archivos de texto plano (ASCII y otras codificaciones) son universalmente utilizados por la mayoría de los gestores de bases de datos y/o planillas de cálculo. Generalmente encontrados con extensiones .txt o .csv (por comma-separated values) son el tipo de archivo de datos más habitual dentro del lenguaje R.\nEstos datos planos tienen dos peculiaridades:\n\nLa cabecera (en inglés header)\nEl caracter o símbolo separador que indica la separación de columnas: pueden estar separadas por comas, puntos y comas, por tabulación, etc…\n\nLa cabecera puede existir o no, y de existir puede ser simple o compleja. La inclusión o no de la cabecera se maneja desde los argumentos col_names y skip.\nCon col_names = TRUE incluimos la primer fila como cabecera (nombre de las columnas) y en FALSE la salteamos.\nCon skip = 0 la lectura de produce desde la primer fila (se puede omitir), pero si la cabecera fuese compleja con varias filas entre títulos y subtítulos, debemos indicar cuantas filas iniciales se “saltea”. Por ejemplo con skip = 5 se saltea las primeras 5 filas del archivo.\nEl otro elemento a tener en cuenta es el caracter separador que utiliza el archivo para indicar cuando comienza una nueva columna (variable).\nGeneralmente los separadores más comunes son: la coma (,), el punto y coma (;), el tabulador (TAB), el espacio ( ), el caracter pipe (|), entre otros posibles.\nAlgunas de las funciones del paquete asumen un separador particular. Por caso read_csv() lee separados por coma y read_tsv() separado por tabulaciones, pero la función read_delim() permite que definamos el separador a través del argumento delim =.\nEn forma detallada el paquete readr soporta siete formatos de archivo a partir de siete funciones:\n\nread_csv(): archivos separados por comas (CSV)\nread_tsv(): archivos separados por tabulaciones\nread_delim(): archivos separados con delimitadores generales\nread_fwf(): archivos con columnas de ancho fijo\nread_table(): archivos formato tabla con columnas separadas por espacios\nread_log(): archivos log web\n\nEn comparación con las funciones base de R, las funciones de readr:\n\nUsan un esquema de nombres consistente de parámetros\nSon más rápida.\nAnalizan eficientemente los formatos de datos comunes, incluyendo fecha/hora.\nMuestran una barra de progreso si la carga va a llevar un tiempo. (para archivos grandes)\n\nViene incluida dentro de la instalación de tidyverse y se activa con él, pero también permite activarse solo:\n\nlibrary(readr)\n\nAlgunos ejemplos de sintaxis:\n\nLeemos un archivo sin cabecera separado por comas\n\n\nread_csv(\"datos/ejemplo-datos.csv\", col_names = F)\n\n# A tibble: 6 × 5\n     X1 X2      X3       X4    X5        \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone   Fernando M     1958-12-24\n2    26 Salem   Esteban  M     1954-01-21\n3    35 Orduna  Nicolas  M     1993-06-27\n4    48 Manueli Viviana  F     1965-06-21\n5    49 Orozco  Laura    F     1993-08-15\n6    55 Umpier  Leopoldo M     1952-10-11\n\n\n\nLeemos el mismo archivo con cabecera y separado por punto y comas\n\n\nread_csv2(\"datos/ejemplo-datos-header.csv\", col_names = T)\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone    Fernando M     1958-12-24\n2    26 Salem    Esteban  M     1954-01-21\n3    35 Orduna   Nicolas  M     1993-06-27\n4    48 Manueli  Viviana  F     1965-06-21\n5    49 Orozco   Laura    F     1993-08-15\n6    55 Umpier   Leopoldo M     1952-10-11\n\n\n\nLeemos el archivo con cabecera separado por tabulaciones\n\n\nread_tsv(\"datos/ejemplo-datos-header2.csv\", col_names = T)\n\nRows: 6 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (3): Apellido, Nombre, Sexo\ndbl  (1): Iden\ndate (1): FNac\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;date&gt;    \n1     9 Leone    Fernando M     1958-12-24\n2    26 Salem    Esteban  M     1954-01-21\n3    35 Orduna   Nicolas  M     1993-06-27\n4    48 Manueli  Viviana  F     1965-06-21\n5    49 Orozco   Laura    F     1993-08-15\n6    55 Umpier   Leopoldo M     1952-10-11\n\n\nObservemos que cada vez que hacemos una lectura la función se encarga de analizar (parse) el tipo de dato que hay en cada columna. En esta última ocasión además, devuelve un listado con el resultado del análisis antes de mostrar la tabla importada.\nLos posibles tipos de datos son los atómicos del lenguaje más algún agregado: character, integer, numeric, double, logical y date/time.\nPor ejemplo, en la tabla leída anteriormente las columnas donde hay números enteros fueron reconocidos como double (&lt;dbl&gt;), los que tienen algún caracter como character (&lt;chr&gt;) y las fechas como date (&lt;date&gt;).\nAhora escribimos la sintaxis para leer un archivo con cabecera compleja (la tabla comienza en la fila 9) separado por |.\n\nread_delim(\"datos/ejemplo-datos-header-skip.txt\", \n           col_names = T, \n           skip = 8,      # salteamos las primeras 8 filas\n           delim = \"|\")\n\n# A tibble: 6 × 5\n   Iden Apellido Nombre   Sexo  FNac      \n  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     \n1     9 Leone    Fernando M     24/12/1958\n2    26 Salem    Esteban  M     21/01/1954\n3    35 Orduna   Nicolas  M     27/06/1993\n4    48 Manueli  Viviana  F     21/06/1965\n5    49 Orozco   Laura    F     15/08/1993\n6    55 Umpier   Leopoldo M     11/10/1952\n\n\n\nEn estos ejemplos visualizamos el contenido de los archivos leídos en consola con el propósito de mostrar como trabajan las funciones, pero en la práctica cada vez que importemos datos de un archivo debemos asignar su salida a un nombre, que será el nombre del dataframe que reciba los datos dentro de nuestra sesión de trabajo. (&lt;-)\n\n\nFunciones de escritura\nDentro del paquete coexisten funciones espejo de escritura para las posibilidades de lectura más relevantes. Así encontramos estos cuatro:\n\nwrite_csv(): escribe archivos separados por comas (csv)\nwrite_csv2(): escribe archivos separados por punto y comas (csv)\nwrite_tsv(): escribe archivos separados por tabulaciones\nwrite_delim(): escribe archivos separados con delimitadores definidos por el usuario\n\nLos argumentos son generales y para el caso del último más extensos, dado que hay que definir cual es el separador que deseamos en el archivo.\n\nargs(write_delim)\n\nfunction (x, file, delim = \" \", na = \"NA\", append = FALSE, col_names = !append, \n    quote = c(\"needed\", \"all\", \"none\"), escape = c(\"double\", \n        \"backslash\", \"none\"), eol = \"\\n\", num_threads = readr_threads(), \n    progress = show_progress(), path = deprecated(), quote_escape = deprecated()) \nNULL\n\n\nPor ejemplo para exportar un conjunto de datos en texto plano al que denominaremos ejemplo.csv con separador punto y coma y cabecera incluida podemos hacer:\n\nwrite_delim(x = datos, file = \"ejemplo.csv\", delim = \";\")\n\no más sencillo:\n\nwrite_csv2(datos, \"ejemplo.csv\")\n\n\n\n\nPaquete readxl\nUno de los formatos de documentos más comunes en los que se almacenan datos son las hojas de cálculo, en particular, las creadas con el programa Excel de Microsoft Office.\nEl paquete readxl es parte del ecosistema tidyverse y permite leer este tipo de archivos.\nPosee compatibilidad con hojas de cálculo de Excel 97-03, de extensión .xls, y con hojas de cálculo de las versiones más recientes de Excel, de extensión, .xlsx\nLa primera función interesante es excel_sheets(), útil para conocer y listar los nombre de las hojas contenidas dentro de un archivo (libro) Excel.\nPor ejemplo, supongamos que tenemos un archivo denominado datos.xlsx y queremos saber por cuantas hojas está compuesto y que nombre tienen.\n\nlibrary(readxl) # hay que activarlo independientemente de tidyverse\n\nexcel_sheets(\"datos/datos.xlsx\")\n\n[1] \"diabetes\"   \"vigilancia\" \"mortalidad\"\n\n\nObtenemos de esta manera información sobre el archivo. Hay tres hojas llamadas diabetes, vigilancia y mortalidad.\nPara poder leer cada una de estas hojas de datos debemos usar la función read_excel(), que tiene los siguientes argumentos:\n\nargs(read_excel)\n\nfunction (path, sheet = NULL, range = NULL, col_names = TRUE, \n    col_types = NULL, na = \"\", trim_ws = TRUE, skip = 0, n_max = Inf, \n    guess_max = min(1000, n_max), progress = readxl_progress(), \n    .name_repair = \"unique\") \nNULL\n\n\nDonde los más relevantes son:\npath: nombre del archivo y la ubicación (si fuese necesaria) entre comillas\nsheet: nombre de la hoja o número de ubicación\ncol_names: si se activa toma la primer fila como nombres de columnas (variables)\nskip: permite saltear una cantidad determinada de filas antes de comenzar la lectura\nEn primer lugar, cuando ejecutamos esta función, llama a otra denominada excel_format() que determina frente a que formato de archivo estamos. Si es un Excel tipo .xsl o tipo .xlsx. En relación a esta respuesta, luego aplica la función específica para cada caso - read_xls() o readxlsx().\nTodas estas funciones mencionadas en el procedimiento que sigue read_excel() se pueden utilizar en forma específica.\nContinuemos con el archivo datos.xlsx y procedamos a leer los datos de su primer hoja, llamada diabetes.\n\ndiabetes &lt;- read_excel(path = \"datos/datos.xlsx\", \n                       sheet = \"diabetes\",\n                       col_names = T)\n\nhead(diabetes) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 8\n    A1C  hba1 GLUCB   SOG Tol_Glucosa    DM    SM  HOMA\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  6.17   7.9   101   122 IFG             0     1  4.04\n2  5.58   7.2   103   100 IFG             0     0  5.03\n3  5.38   7.1   103    90 IFG             0     1  2.92\n4  5.38   6.6   109    96 IFG             0     1  4.79\n5  5.19   6.3   107    69 IFG             0     1  3.06\n6  4.89   6      NA   117 IFG             0     0  5.77\n\n\nObservemos que en los argumentos escribimos el nombre del archivo que se encuentra en nuestro proyecto y por lo tanto en nuestra carpeta activa, el nombre de la hoja y nos aseguramos que la primer fila representa a la cabecera de la tabla (sus nombres de variables).\nComo el paquete readxl se inscribe dentro del universo tidyverse el formato de salida es un dataframe/tibble. En este caso de 23 observaciones por 8 variables.\nAhora leamos la segunda hoja de nombre vigilancia.\n\nvigilancia &lt;- read_excel(path = \"datos/datos.xlsx\", \n                         sheet = 2, \n                         col_names = F)\n\nhead(vigilancia) # mostramos las 6 primeras observaciones\n\n# A tibble: 6 × 9\n   ...1 ...2        ...3      ...4  ...5  ...6  ...7 ...8  ...9                 \n  &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;                \n1   875 09/28/2015  2015 544080000     1    31     1 F     VIGILANCIA EN SALUD …\n2   875 42317       2015 544080000     1    35     1 F     VIGILANCIA EN SALUD …\n3   875 42317       2015 544080000     1    47     1 F     VIGILANCIA EN SALUD …\n4   307 09/26/2015  2015 544005273     1    23     1 M     VIGILANCIA INTEGRADA…\n5   307 09/24/2015  2015 544005273     1    19     1 M     VIGILANCIA INTEGRADA…\n6   875 09/28/2015  2015 544080000     1    63     1 F     VIGILANCIA EN SALUD …\n\n\nCentremos nuestra mirada en los argumentos anteriores: en lugar del nombre de la hoja usamos un 2 que es su ubicación (la segunda hoja del archivo Excel) y configuramos a col_names con F (false) porque el conjunto de datos no tiene cabecera.\nCuando ocurre esta situación donde la tabla no tiene nombre de columnas readxl le asigna nombres del tipo ...1, ...2, ...x\nFinalmente leemos la última hoja disponible del archivo.\n\nmortalidad &lt;- read_excel(path = \"datos/datos.xlsx\", \n                         sheet = \"mortalidad\",\n                         col_names = T, \n                         skip = 1)\n\nhead(mortalidad) # mostramos las 6 primeras observaciones\n\n# A tibble: 5 × 10\n  grupo_edad grupo.I.1.1 grupo.II.1.1 grupo.III.1.1 grupo.I.2.1 grupo.II.2.1\n  &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 30-44               41          202           222         539         1438\n2 45-59               99         1071           181         759         6210\n3 60-69              114         1782           119         985         9238\n4 70-79              221         2336           119        1571        12369\n5 80+                362         2492            81        2523        14642\n# ℹ 4 more variables: grupo.III.2.1 &lt;dbl&gt;, grupo.I.3.1 &lt;dbl&gt;,\n#   grupo.II.3.1 &lt;dbl&gt;, grupo.III.3.1 &lt;dbl&gt;\n\n\nLo novedoso de esta lectura es el argumento skip = 1 que debimos incorporar dado que, en este caso, la hoja de Excel comienza con una línea de título que no pertenece al conjunto de datos. También que el argumento sheet permite el nombre de la hoja elegida entre comillas.\nRetomando los argumentos generales de la función podemos mencionar estos otros:\nn_max: número máximo de filas leídas\nrange: rango de celdas a leer (definidas como se suele usar en Excel, por ej: B3:D87)\ncol_types: especificación del tipo de dato para cada columna leída. Se pueden utilizar los tipos habituales “numeric”, “logical”, “text”, “date”, etc. Existen dos tipos específicos más: “skip” que saltea la lectura de la columna y “guess” que permite que la función decida cual es el formato adecuado de importación. Este último es el modo predeterminado cuando no especificamos el argumento.\nna: caracter o vector que deseamos se interprete como valor perdido (missing). Por defecto las celdas vacías se interpretan de esta forma y se le asigna NA",
    "crumbs": [
      "Unidad 1: Introducción al lenguaje R"
    ]
  },
  {
    "objectID": "unidad3.html",
    "href": "unidad3.html",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "",
    "text": "En el ámbito de los proyectos de análisis de datos, el preprocesamiento, también conocido como preparación de datos, es una etapa crucial que precede al análisis propiamente dicho. Esta fase esencial tiene como objetivo acondicionar los datos para su posterior análisis, garantizando su confiabilidad e integridad.\nLas tareas de preprocesamiento son específicas para cada conjunto de datos y dependen de los objetivos del proyecto y las técnicas de análisis que se emplearán. Sin embargo, existen tareas comunes que son aplicables a la mayoría de los casos, entre las que se encuentran el diagnóstico y la limpieza de datos.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#exploración-y-diagnóstico-de-datos",
    "href": "unidad3.html#exploración-y-diagnóstico-de-datos",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Exploración y diagnóstico de datos",
    "text": "Exploración y diagnóstico de datos\nLa etapa de diagnóstico de datos es fundamental para comprender la estructura y características del conjunto de datos que se va a analizar. Esta fase involucra una serie de tareas esenciales, como:\nAnálisis de la estructura de la tabla de datos: Esta tarea implica comprender la organización de los datos, identificando las variables, sus tipos de datos y la distribución de los registros. Es relevante vincular este proceso con el “diccionario de datos” de la tabla o base, ya sea de fuente secundaria o creada por nosotros mismos.\nVerificación del tipo de dato de cada variable de interés: Es crucial determinar el tipo de dato de cada variable (numérica, categórica, fecha-hora, etc.) para aplicar las técnicas de análisis adecuadas.\nDetección de valores faltantes: La presencia de valores faltantes puede afectar significativamente los resultados del análisis. Es importante identificar estos valores y determinar la mejor manera de manejarlos (eliminación, imputación, etc.).\nIdentificación de las categorías de las variables cualitativas: En el caso de variables categóricas, es necesario identificar las categorías existentes y evaluar su distribución.\nAnálisis de los mínimos y máximos de valores de cada variable cuantitativa: Para variables numéricas, es importante determinar los valores mínimos y máximos para detectar posibles valores atípicos o errores de entrada.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#exploración-de-datos",
    "href": "unidad3.html#exploración-de-datos",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Exploración de datos",
    "text": "Exploración de datos\nEl primer paso en la exploración de un conjunto de datos es conocer su estructura y tamaño.\nEl tamaño está definido por la cantidad de observaciones (filas) y la cantidad de variables (columnas).\nLlamamos estructura a la forma en se organizan sus variables, sus tipos de datos y sus categorías/valores.\nVamos a utilizar un dataframe de ejemplo con variedad en sus tipos de datos. Para ver su estructura en R base tenemos la función str()\n\nstr(datos)\n\n'data.frame':   74 obs. of  7 variables:\n $ id     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ sexo   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ edad   : num  76 68 50 49 51 68 70 64 60 57 ...\n $ peso   : num  71 71 79 71 87 75 80 83 69 73 ...\n $ talla  : num  167 164 164 164 168 ...\n $ trabaja: logi  FALSE FALSE FALSE TRUE TRUE FALSE ...\n $ fecha  : Date, format: \"2020-10-20\" \"2020-10-20\" ...\n\n\nNos informa que la tabla tiene 74 observaciones y 7 variables con su tipo de dato al lado.\nEn R base los tipos de datos son:\n\nint (integer): números enteros\nnum (numeric): números reales\nchr (character): caracteres (texto)\nlogi (logical): valores lógicos\nDate: fechas\nfct (factor): factores\n\nEn tidyverse, la función que reemplaza a str() es glimpse():\n\nglimpse(datos)\n\nRows: 74\nColumns: 7\n$ id      &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,…\n$ sexo    &lt;chr&gt; \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", \"M\", NA, \"F\", \"F\", \"M\", \"F\"…\n$ edad    &lt;dbl&gt; 76, 68, 50, 49, 51, 68, 70, 64, 60, 57, 83, 76, 27, 34, 17, 45…\n$ peso    &lt;dbl&gt; 71.0, 71.0, 79.0, 71.0, 87.0, 75.0, 80.0, 83.0, 69.0, 73.0, 60…\n$ talla   &lt;dbl&gt; 167.0, 164.0, 164.0, 164.0, 167.5, 170.0, 166.0, 160.0, 160.0,…\n$ trabaja &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, NA, TRUE, TRUE, TRUE, …\n$ fecha   &lt;date&gt; 2020-10-20, 2020-10-20, 2020-10-20, 2020-11-05, 2020-11-05, 2…\n\n\nParece idéntica pero tiene una ventaja cuando la tabla de datos tiene muchas variables. La lista de respuesta de str() se trunca y no nos deja visualizar la totalidad de columnas, cosa que si hace glimpse().\nPor otra parte vamos a encontrar distintas definiciones para los tipos de datos, del modo tidyverse:\n\nnum para a ser dbl (double): números reales\nlogi para a ser lgl (logical): valores lógicos\n\nY se incluyen un tipo nuevo:\n\ndttm (date-time): fechas y horas\n\nEsta exploración inicial de la estructura generalmente viene acompañada por el “diccionario de datos” (codebook) asociado a la tabla de datos, ya sea que esta tabla provenga de un proyecto de investigación propio (fuente primaria), producto de una fuente secundaria o de un sistema de vigilancia epidemiológica.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#comprobación-y-coerción-de-tipos-de-datos",
    "href": "unidad3.html#comprobación-y-coerción-de-tipos-de-datos",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Comprobación y coerción de tipos de datos",
    "text": "Comprobación y coerción de tipos de datos\nLa mayoría de las funciones producen un error cuando el tipo de datos que esperan no coincide con los que pasamos como argumentos. En esta situación seguiremos el siguiente camino:\n\nComprobar el tipo de datos utilizando las funciones is.*(), que nos responden con un valor lógico (TRUE si el tipo de dato coincide y FALSE si no lo hace). Si el tipo de dato coincide con el formato esperado por el argumento de la función, entonces podemos aplicarla, de lo contrario necesitaremos continuar:\nForzar el tipo de datos deseado coercionando con funciones de la familia as.*(), que fuerzan el tipo de datos, siempre y cuando esto devuelva valores correctos. Por ejemplo, no podremos obtener valores correctos si intento coercionar caracteres a tipos numéricos.\n\n\n# Ejmeplo coercionando la variable sexo de caracter a factor\n\nas.factor(datos$sexo) # llamamos a la variable con el formato &lt;dataframe&gt;$&lt;variable&gt;\n\n [1] M    M    M    M    M    M    M    M    &lt;NA&gt; F    F    M    F    F    F   \n[16] F    F    M    M    M    M    M    M    F    M    F    &lt;NA&gt; M    F    M   \n[31] F    F    M    F    F    F    M    M    M    M    M    F    M    F    M   \n[46] M    F    M    F    &lt;NA&gt; M    M    M    F    M    M    M    M    M    F   \n[61] F    M    F    F    M    M    F    F    F    M    M    M    M    M   \nLevels: F M\n\n# detecta que hay dos niveles o categorías posibles (F y M) \n\nis.factor(as.factor(datos$sexo))\n\n[1] TRUE\n\n# nos confirma que los datos se coercionaron a factor\n\n\nTransformar el tipo de dato a partir de aplicar funciones específicas incluidas en paquetes que gestionan datos especiales, como por ejemplo las fechas (el paquete lubridate del tidyverse, que conoceremos más adelante, se ocupa de esto)\n\nA continuación se muestra una lista con los tipos más importantes que se pueden comprobar o forzar a partir de funciones de R base:\n\n\n\nTipo\nComprobación\nCoerción\n\n\n\n\ncharacter\nis.character()\nas.character()\n\n\nnumeric\nis.numeric()\nas.numeric()\n\n\ninteger\nis.integer()\nas.integer()\n\n\ndouble\nis.double()\nas.double()\n\n\nfactor\nis.factor()\nas.factor()\n\n\nlogical\nis.logical()\nas.logical()\n\n\nNA\nis.na()\nas.na()",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#skimr",
    "href": "unidad3.html#skimr",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Skimr",
    "text": "Skimr\n\n\n\n\n\nExisten diversas herramientas y funciones que facilitan la etapa de diagnóstico de datos, es el caso de skimr.\nEste paquete tiene funciones diseñadas para obtener un resumen rápido de la estructura de tablas de datos y son compatibles con el ecosistema tidyverse.\nLa función principal del paquete es skim y puede ser aplicada a todo el dataframe o bien a una variable o a un grupo de ellas.\n\nProporciona un conjunto más amplio de estadísticas que summary(), incluyendo valores faltantes, completos, número total (n) y desvío estándar (sd).\nInforma de cada tipo de dato por separado.\nManeja fechas, valores lógicos y otros tipos.\n\nTrabajemos con skimr sobre un conjunto de datos provenientes de la vigilancia del SNVS.\n\nlibrary(skimr)\n\nskim(datos)\n\n\nData summary\n\n\nName\ndatos\n\n\nNumber of rows\n200\n\n\nNumber of columns\n56\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n47\n\n\nDate\n7\n\n\nlogical\n1\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nSEXO\n0\n1.00\n1\n1\n0\n3\n0\n\n\nGRUPEDAD\n0\n1.00\n3\n5\n0\n18\n0\n\n\nPROVINCIA_RESIDENCIA\n0\n1.00\n4\n16\n0\n18\n0\n\n\nID_PROV_INDEC_RESIDENCIA\n0\n1.00\n2\n2\n0\n18\n0\n\n\nDEPARTAMENTO_RESIDENCIA\n9\n0.96\n4\n26\n0\n81\n0\n\n\nID_DEPTO_INDEC_RESIDENCIA\n0\n1.00\n2\n5\n0\n89\n0\n\n\nLOCALIDAD_RESIDENCIA\n0\n1.00\n4\n57\n0\n106\n0\n\n\nESTABLECIMIENTO_SALUD\n0\n1.00\n11\n82\n0\n125\n0\n\n\nESTABLECIMIENTO_CARGA\n0\n1.00\n5\n82\n0\n117\n0\n\n\nPROVINCIA_CARGA\n0\n1.00\n4\n16\n0\n17\n0\n\n\nDEPTO_CARGA\n0\n1.00\n4\n22\n0\n70\n0\n\n\nESTAB_CLINICA\n20\n0.90\n11\n76\n0\n112\n0\n\n\nDEPTO_CLINICA\n20\n0.90\n4\n23\n0\n73\n0\n\n\nPPL\n0\n1.00\n2\n2\n0\n2\n0\n\n\nSERVICIO_PENITENCIARIO\n0\n1.00\n2\n19\n0\n7\n0\n\n\nMOTIVO_CONSULTA\n181\n0.09\n8\n24\n0\n3\n0\n\n\nCLASIFICACION_MANUAL\n0\n1.00\n10\n67\n0\n9\n0\n\n\nCLASIF_INICIO_TRAT\n0\n1.00\n5\n34\n0\n6\n0\n\n\nID_PULMONAR\n0\n1.00\n2\n15\n0\n3\n0\n\n\nID_EXTRAPULMONAR\n0\n1.00\n5\n31\n0\n13\n0\n\n\nRESULTADO_RX\n0\n1.00\n9\n28\n0\n8\n0\n\n\nBacteriologia\n0\n1.00\n8\n15\n0\n3\n0\n\n\nBaciloscopia\n0\n1.00\n8\n15\n0\n6\n0\n\n\nCultivo\n0\n1.00\n8\n26\n0\n7\n0\n\n\nPRUEBA_RESISTENCIA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nRESISTENCIA\n0\n1.00\n15\n25\n0\n4\n0\n\n\nDroga\n0\n1.00\n2\n26\n0\n6\n0\n\n\nTipo_Resistencia\n0\n1.00\n2\n10\n0\n4\n0\n\n\nESTABLECIMIENTO_MUESTRA\n72\n0.64\n5\n102\n0\n73\n0\n\n\nDEPARTAMENTO_MUESTRA\n72\n0.64\n5\n32\n0\n46\n0\n\n\nESTABLECIMIENTO_DIAG\n76\n0.62\n5\n160\n0\n62\n0\n\n\nDEPARTAMENTO_DIAG\n76\n0.62\n5\n37\n0\n39\n0\n\n\nPrueba_VIH\n0\n1.00\n2\n15\n0\n2\n0\n\n\nVIH\n0\n1.00\n8\n15\n0\n3\n0\n\n\nTRATAMIENTO_ANTIRRETROVIRAL\n199\n0.01\n2\n2\n0\n1\n0\n\n\nDiag_rapido\n0\n1.00\n2\n2\n0\n2\n0\n\n\nResultado_diag_rapido\n0\n1.00\n15\n62\n0\n9\n0\n\n\nEMBARAZO\n0\n1.00\n2\n15\n0\n3\n0\n\n\nDIABETES\n0\n1.00\n2\n2\n0\n2\n0\n\n\nCONSUMO_PROB_DROGAS\n0\n1.00\n2\n15\n0\n2\n0\n\n\nENF_RESP_CRONICA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nCOVID\n199\n0.01\n2\n2\n0\n1\n0\n\n\nSE_DECLARA_PUEBLO_INDIGENA\n0\n1.00\n2\n15\n0\n2\n0\n\n\nTABAQUISMO\n0\n1.00\n2\n15\n0\n2\n0\n\n\nALCOHOLISMO\n0\n1.00\n2\n15\n0\n2\n0\n\n\nESTAB_TTO\n35\n0.82\n11\n76\n0\n102\n0\n\n\nRESULTADO_TRATAMIENTO\n0\n1.00\n6\n22\n0\n7\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nFECHA_NACIMIENTO\n0\n1.00\n1934-12-13\n2023-05-05\n1989-07-27\n198\n\n\nFECHA_APERTURA\n0\n1.00\n2021-09-20\n2024-04-18\n2023-07-16\n151\n\n\nFECHA_NOTIFICACION\n0\n1.00\n2023-01-03\n2023-12-27\n2023-07-03\n147\n\n\nFIS\n48\n0.76\n2020-12-20\n2023-12-21\n2023-05-12\n116\n\n\nFECHA_INICIO_SINTOMA\n44\n0.78\n2022-08-15\n2023-12-26\n2023-05-17\n116\n\n\nFECHA_INICIO_TRAT\n43\n0.78\n2023-01-03\n2024-01-08\n2023-07-02\n119\n\n\nFECHA_FIN_TRAT\n142\n0.29\n2023-03-09\n2024-04-05\n2023-10-23\n52\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\nETNIA\n200\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nEDAD_DIAGNOSTICO\n0\n1\n37.02\n18.63\n0\n23\n33\n49\n88\n▂▇▅▃▁\n\n\n\n\n\nLa salida completa de skim() separa los resultados por partes. Un resumen de datos inicial, donde vemos la cantidad de filas y columnas con la frecuencia de tipo de variable. Luego le siguen tablas con información descriptiva univariada, donde podemos ver que dependiendo del tipo de variable nos muestra diferentes estadísticos y hasta un mini histograma en el caso de las numéricas.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#dlookr",
    "href": "unidad3.html#dlookr",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "dlookr",
    "text": "dlookr\n\n\n\n\n\nEl paquete se define como una “colección de herramientas que permiten el diagnóstico, la exploración y la transformación de datos”.\nEl diagnóstico de datos proporciona información y visualización de valores faltantes, valores atípicos y valores únicos y negativos para ayudarle a comprender la distribución y la calidad de sus datos.\nContiene funciones, compatibles con tidyverse, que nos facilitan ver la calidad de nuestros datos, además de otras que tienen por objetivo la exploración y su transformación.\nEntre estas funciones encontramos:\n\ndiagnose()\nPermite diagnosticar variables del dataframe y devuelve como resultado: el tipo de dato de la variable, la cantidad de valores faltantes, su porcentaje, la cantidad de valores únicos y su tasa (valores únicos/observaciones). Lo observamos en forma de tabla interactiva:\n\nlibrary(dlookr)\n\ndiagnose(datos)\n\n\n\n\n\n\n\nAl ser compatible con tidyverse se puede editar antes o después de la función, por ejemplo si quisiéramos filtrar variables con valores faltantes (de mayor a menor):\n\ndiagnose(datos) |&gt; \n  select(!starts_with(\"unique\")) |&gt; \n  filter(missing_count &gt; 0) |&gt; \n  arrange(desc(missing_count))\n\n# A tibble: 16 × 4\n   variables                   types     missing_count missing_percent\n   &lt;chr&gt;                       &lt;chr&gt;             &lt;int&gt;           &lt;dbl&gt;\n 1 ETNIA                       logical             200           100  \n 2 TRATAMIENTO_ANTIRRETROVIRAL character           199            99.5\n 3 COVID                       character           199            99.5\n 4 MOTIVO_CONSULTA             character           181            90.5\n 5 FECHA_FIN_TRAT              Date                142            71  \n 6 ESTABLECIMIENTO_DIAG        character            76            38  \n 7 DEPARTAMENTO_DIAG           character            76            38  \n 8 ESTABLECIMIENTO_MUESTRA     character            72            36  \n 9 DEPARTAMENTO_MUESTRA        character            72            36  \n10 FIS                         Date                 48            24  \n11 FECHA_INICIO_SINTOMA        Date                 44            22  \n12 FECHA_INICIO_TRAT           Date                 43            21.5\n13 ESTAB_TTO                   character            35            17.5\n14 ESTAB_CLINICA               character            20            10  \n15 DEPTO_CLINICA               character            20            10  \n16 DEPARTAMENTO_RESIDENCIA     character             9             4.5\n\n\n\n\ndiagnose_category()\nAsí como existe diagnose() como una función general, también hay funciones que sirven para el diagnóstico específico por tipo de dato.\ndiagnose_category() lo hace con las variables categóricas, es decir de caracter, de factor y de factor ordenado, mostrando información de cada categoría de cada variable (N, frecuencia, proporción y ranking).\n\ndatos|&gt; \n diagnose_category()\n\n\n\n\n\n\n\n\n\ndiagnose_numeric()\nPara variables numéricas tenemos a diagnose_numeric() que nos brinda estadísticos resumen descriptivos univariados.\n\ndatos|&gt; \n diagnose_numeric()\n\n\n\n\n\n\n\nObservamos que sobre la única variable numérica de datos nos calcula el mínimo, primer cuartil, media, mediana, tercer cuartil, máximo, la cantidad de ceros, la cantidad de números negativos y la cantidad de datos atípicos.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#diagnose_outlier",
    "href": "unidad3.html#diagnose_outlier",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "diagnose_outlier()",
    "text": "diagnose_outlier()\nSobre los datos atípicos diagnose_outlier() nos amplía la información:\n\ndatos|&gt; \n diagnose_outlier()\n\n\n\n\n\n\n\nAquí la variable EDAD_DIAGNOSTICO no tiene datos atípicos por lo que el conteo y proporción es de cero, la media de los outlier no existe y la media contando y no contando estos outlier da lo mismo (37,02)",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#plot_outlier",
    "href": "unidad3.html#plot_outlier",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "plot_outlier()",
    "text": "plot_outlier()\nAgreguemos algún dato atípico a EDAD_DIAGNOSTICO para poder mostrar este gráfico.\n\ndatos[10, \"EDAD_DIAGNOSTICO\"] &lt;- 105  # cambiamos la edad de la observación 10 \n\n\ndatos |&gt; \n  plot_outlier(EDAD_DIAGNOSTICO) \n\n\n\n\n\n\n\n\nEl gráfico siempre se va a producir si al menos tenemos un dato atípico en la variable. Grafica un boxplot e histograma contando los valores outlier que la variable tenga y otro quitándolos.\n\nOtras funciones del paquete\ndlookr tiene muchas otras funciones, para la conversión de datos y/o la imputación de datos ausentes, que no trabajaremos en el curso pero pueden encontrarse en el sitio del desarrollador https://choonghyunryu.github.io/dlookr/index.html",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#depuración-de-datos",
    "href": "unidad3.html#depuración-de-datos",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Depuración de datos",
    "text": "Depuración de datos\n\n\n\n\n\nUna vez finalizado el diagnóstico de datos, se procede a la etapa de depuración, donde se corrigen los errores identificados y se prepara el conjunto de datos para su análisis. La depuración involucra técnicas como la eliminación de valores faltantes, la corrección de errores de entrada, la transformación de variables y el manejo de valores atípicos.\nUn flujo de trabajo modelo partiendo de datos crudos y terminando en datos limpios es el siguiente:\n\n\n\n\n\nDurante este proceso puede haber múltiples situaciones dependiendo de la calidad original de los datos crudos, desde carecer de encabezados o contener tipos de datos incorrectos, pasando por tener que corregir etiquetas de categorías incorrectas, etc.\nLas herramientas de dplyr en tidyverse nos van a facilitar esta tarea que suele ocupar entre un 70 y 80% del tiempo de trabajo cuando analizamos datos.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#gestión-de-duplicados",
    "href": "unidad3.html#gestión-de-duplicados",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Gestión de duplicados",
    "text": "Gestión de duplicados\nUn caso habitual con el que debemos lidiar es el tener observaciones duplicadas, total o parcialmente. Por este motivo, debemos conocer las características de la o las tablas con las que estamos trabajando, es decir, si las observaciones tiene claves unívocas, si estas observaciones se pueden repetir, si la relación es uno a uno o uno a varios cuando hay más de una tabla relacionada, etc.\nEntonces, el primer paso será asegurarnos que los datos cumplen con el criterio que conocemos haciendo una detección de observaciones y/o partes de observaciones (variables clave) que se encuentran duplicadas.\nLuego, hay diferentes tareas que se pueden realizar para gestionar estos datos duplicados, cuando su existencia no es la esperada:\n\nEliminación de duplicados a partir de observaciones únicas.\nRecortar tabla de datos para eliminar duplicados\nMarcar duplicados (conservando duplicados en la tabla)\n\nLa función get_dupes() del paquete janitor es muy útil porque identifica estas repeticiones.\n\nlibrary(janitor)\n\ndatos |&gt; \n  get_dupes(everything())\n\n# A tibble: 0 × 57\n# ℹ 57 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;date&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\n\nAplicada sobre el dataframe entero detecta aquellas observaciones que sean iguales en todas sus observaciones. Esto es difícil que pase pero puede suceder cuando por alguna falla técnica el sistema desde donde se obtienen los datos duplica registros completos.\nOtra posibilidad es utilizar la variable que es clave en la tabla de datos o las variables que constituyen una clave combinada.\nPor ejemplo, en este caso, usemos una serie de variables como SEXO, FECHA_NACIMIENTO, ID_PROV_INDEC_RESIDENCIA e ID_DEPTO_INDEC_RESIDENCIA para ver si hay observaciones donde estos datos se repitan.\n\ndatos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n            ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA)\n\n# A tibble: 2 × 57\n  SEXO  FECHA_NACIMIENTO ID_PROV_INDEC_RESIDENCIA ID_DEPTO_INDEC_RESIDENCIA\n  &lt;chr&gt; &lt;date&gt;           &lt;chr&gt;                    &lt;chr&gt;                    \n1 M     1947-06-29       90                       90063                    \n2 M     1947-06-29       90                       90063                    \n# ℹ 53 more variables: dupe_count &lt;int&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, DEPARTAMENTO_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;,\n#   FECHA_NOTIFICACION &lt;date&gt;, MOTIVO_CONSULTA &lt;chr&gt;, …\n\n\nEncontramos dos observaciones que tienen los mismo valores en esta combinación de variables. Un hombre nacido el 29/06/1947 en la provincia de Tucumán, en el departamento Lules.\nSupongamos que no puede existir dos veces la misma persona en la tabla (sería deseable confirmar esto teniendo alguna variable univoca cómo el DNI, por ejemplo), procederíamos a solucionar este duplicado.\n\nEliminación de duplicados por observaciones únicas\nPara eliminar filas duplicadas en una tabla de datos podemos utilizar la función distinct() de dplyr.\nLa función tiene un argumento denominado .keep_all que permite valores TRUE o FALSE. Si se iguala a TRUE se mantienen en el resultado todas las variables que son parte de la tabla, aunque estas no estén declaradas dentro del distinct().\nPor defecto, este argumento se encuentra igualado a FALSE.\n\nnrow(datos)\n\n[1] 200\n\ndatos |&gt; \n  distinct(SEXO, FECHA_NACIMIENTO, ID_PROV_INDEC_RESIDENCIA, \n           ID_DEPTO_INDEC_RESIDENCIA, \n           .keep_all = T)\n\n# A tibble: 199 × 56\n   SEXO  FECHA_NACIMIENTO EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n   &lt;chr&gt; &lt;date&gt;                      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n 1 M     1948-06-22                     74 70-74    Tierra del Fuego    \n 2 F     1981-06-20                     41 40-44    Buenos Aires        \n 3 F     1989-03-30                     33 30-34    Buenos Aires        \n 4 M     2006-11-17                     16 15-19    Chaco               \n 5 M     1993-06-02                     29 25-29    Jujuy               \n 6 M     1989-04-08                     33 30-34    Buenos Aires        \n 7 F     1977-07-30                     45 45-49    Buenos Aires        \n 8 M     1968-04-09                     54 50-54    Misiones            \n 9 F     2008-01-10                     15 15-19    Chaco               \n10 M     1987-11-27                    105 35-39    Buenos Aires        \n# ℹ 189 more rows\n# ℹ 51 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\n\nObservamos que las 200 observaciones distinct() nos devuelve 199. Eliminó una de las dos que tenían duplicadas esa serie de variables definidas (no podemos controlar cuál de ellas elimina).\n\n\nEliminación de duplicados por recorte de observaciones\nRecortar es similar a filtrar, la diferencia está en que se filtra por condiciones y recortamos por posiciones.\nLa familia de funciones de dplyr que se puede utilizar para recortar es slice_*().\nEstas funciones pueden ser muy útiles si se aplican a un dataframe agrupado porque la operación de recorte se realiza en cada grupo por separado.\nPor ejemplo, podemos usar la FECHA_NOTIFICACION para seleccionar la mas vieja. Esto se hace combinado group_by() y slice_min() (observación con el valor mínimo)\n\ndatos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n             ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  select(SEXO, FECHA_NACIMIENTO, FECHA_NOTIFICACION)\n\n# A tibble: 2 × 3\n  SEXO  FECHA_NACIMIENTO FECHA_NOTIFICACION\n  &lt;chr&gt; &lt;date&gt;           &lt;date&gt;            \n1 M     1947-06-29       2023-03-10        \n2 M     1947-06-29       2023-02-24        \n\ndatos |&gt; \n  group_by(SEXO, FECHA_NACIMIENTO, \n           ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  slice_min(FECHA_NOTIFICACION) |&gt; \n  filter(SEXO == \"M\", FECHA_NACIMIENTO == dmy(\"29/06/1947\")) |&gt; \n  select(SEXO, FECHA_NACIMIENTO, FECHA_NOTIFICACION) |&gt; \n  ungroup()\n\nAdding missing grouping variables: `ID_PROV_INDEC_RESIDENCIA`,\n`ID_DEPTO_INDEC_RESIDENCIA`\n\n\n# A tibble: 1 × 5\n  ID_PROV_INDEC_RESIDENCIA ID_DEPTO_INDEC_RESIDENCIA SEXO  FECHA_NACIMIENTO\n  &lt;chr&gt;                    &lt;chr&gt;                     &lt;chr&gt; &lt;date&gt;          \n1 90                       90063                     M     1947-06-29      \n# ℹ 1 more variable: FECHA_NOTIFICACION &lt;date&gt;\n\n\n\n\nMarcar duplicados\nSi, en cambio, lo que buscamos es mantener a todas las observaciones de la tabla pero marcar aquellos que consideramos duplicados podemos hacer:\n\nRecortar el dataframe original a sólo las filas para el análisis. Guardar los ID de este dataframe reducido en un vector.\nEn el dataframe original, creamos una variable de marca usando una función condicional, basándonos si el ID está presente en el dataframe reducido (vector de ID anterior).\n\nPrimer paso, en esta tabla no existe un ID único por lo que vamos a crear una clave subrogada.\n\ndatos &lt;- datos |&gt; \n  mutate(ID = row_number())\n\nAhora usaremos este ID para crear un vector con los números de las dos observaciones anteriores que están duplicadas.\n\nID_duplicados &lt;- datos |&gt; \n  get_dupes(SEXO, FECHA_NACIMIENTO, \n             ID_PROV_INDEC_RESIDENCIA, ID_DEPTO_INDEC_RESIDENCIA) |&gt; \n  pull(ID)\n\nID_duplicados\n\n[1]  44 166\n\n\nFinalmente aplicamos este vector con una función como if_else() para marcar con una X en la variable duplicado.\n\ndatos &lt;- datos |&gt; \n  mutate(duplicado = if_else(ID %in% ID_duplicados, \"X\", NA))\n\nLuego podriamos filtrar los duplicados directamente\n\ndatos |&gt; \n  filter(duplicado == \"X\")\n\n# A tibble: 2 × 58\n  SEXO  FECHA_NACIMIENTO EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n  &lt;chr&gt; &lt;date&gt;                      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n1 M     1947-06-29                     75 75-79    Tucumán             \n2 M     1947-06-29                     75 75-79    Tucumán             \n# ℹ 53 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;,\n#   FECHA_NOTIFICACION &lt;date&gt;, MOTIVO_CONSULTA &lt;chr&gt;, …",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#datos-faltantes-o-perdidos",
    "href": "unidad3.html#datos-faltantes-o-perdidos",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Datos faltantes o perdidos",
    "text": "Datos faltantes o perdidos\nCuando trabajamos con datos los valores perdidos o faltantes (conocidos en inglés como missing) pueden constituir un serio problema en nuestras variables por lo que deben explorarse y manejarse cuidadosamente en las etapas iniciales del análisis.\nEstos datos pueden faltar por muchas razones, pero generalmente se suelen agrupar en dos categorías: valores faltantes informativos y valores faltantes aleatorios. Los informativos implican una causa estructural, ya sea por deficiencias en la forma en que se recopilaron los datos o por anomalías en el entorno de observación. Los aleatorios son aquellos que tienen lugar independientemente del proceso de recopilación de datos.\nDependiendo de si los valores faltantes son de uno u otro tipo, se procederá de una u otra manera. A los informativos, en general, se les puede asignar un valor concreto (por ejemplo, “Ninguno” o “Sin dato”), ya que este valor puede convenir tenerlo como una categoría más de la variable. Los aleatorios, en cambio, pueden manejarse mediante la eliminación o la imputación.\nResumiendo, las tareas habituales respecto a estos valores consisten en:\n\nEvaluar la existencia de valores perdidos (exploración y conteo).\nExcluir los valores ausentes (si es posible y conveniente).\nEtiquetar o recodificar los valores ausentes (imputación de datos).\n\nRespecto a la imputación existen numerosa bibliografía sobre diversos algoritmos que no vamos a incluir en este curso.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#detectar-observaciones-incompletas-valores-missing",
    "href": "unidad3.html#detectar-observaciones-incompletas-valores-missing",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Detectar observaciones incompletas (valores missing)",
    "text": "Detectar observaciones incompletas (valores missing)\nEl lenguaje R gestiona a los datos perdidos mediante el valor especial reservado NA de Not Available (No disponible),\nEn principio, sólo vamos a enfocarnos en como podemos utilizar algunas funciones del lenguaje para detectarlos y contabilizarlos. A partir de su identificación decidiremos que hacer con ellos, dependiendo de su cantidad y extensión, es decir, si los valores faltantes son la mayoría de una variable o la mayoría de una observación o bien si representan la falta de respuesta de una pregunta, con lo cual convenga etiquetarlos.\nUna manera de abordar esta tarea con R base para una variables es hacer la sumatoria de valores NA, usando la función de identificación is.na().\nPara ejemplificar, tomamos una tabla de datos de vigilancia con 200 observaciones y 56 variables.\n\ndatos |&gt; \n  summarise(Cantidad_NA = sum(is.na(FECHA_FIN_TRAT)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1         142\n\n\nLa consulta dice que hay 142 observaciones vacías en la variable FECHA_FIN_TRAT. Lo malo es que debemos hacer esta tarea variable por variable, lo que resulta muy trabajoso.\nTambién la función summary() aplicada sobre el dataframe completo informa la cantidad de NA de variables cuantitativas, lógicas y fecha, pero no lo hace con las de tipo caracter.\n\nsummary(datos)\n\n     SEXO           FECHA_NACIMIENTO     EDAD_DIAGNOSTICO   GRUPEDAD        \n Length:200         Min.   :1934-12-13   Min.   :  0.00   Length:200        \n Class :character   1st Qu.:1973-11-06   1st Qu.: 23.00   Class :character  \n Mode  :character   Median :1989-07-27   Median : 33.00   Mode  :character  \n                    Mean   :1985-12-04   Mean   : 37.37                     \n                    3rd Qu.:1999-11-17   3rd Qu.: 49.00                     \n                    Max.   :2023-05-05   Max.   :105.00                     \n                                                                            \n PROVINCIA_RESIDENCIA ID_PROV_INDEC_RESIDENCIA DEPARTAMENTO_RESIDENCIA\n Length:200           Length:200               Length:200             \n Class :character     Class :character         Class :character       \n Mode  :character     Mode  :character         Mode  :character       \n                                                                      \n                                                                      \n                                                                      \n                                                                      \n ID_DEPTO_INDEC_RESIDENCIA LOCALIDAD_RESIDENCIA ESTABLECIMIENTO_SALUD\n Length:200                Length:200           Length:200           \n Class :character          Class :character     Class :character     \n Mode  :character          Mode  :character     Mode  :character     \n                                                                     \n                                                                     \n                                                                     \n                                                                     \n ESTABLECIMIENTO_CARGA PROVINCIA_CARGA    DEPTO_CARGA        ESTAB_CLINICA     \n Length:200            Length:200         Length:200         Length:200        \n Class :character      Class :character   Class :character   Class :character  \n Mode  :character      Mode  :character   Mode  :character   Mode  :character  \n                                                                               \n                                                                               \n                                                                               \n                                                                               \n DEPTO_CLINICA          PPL            SERVICIO_PENITENCIARIO\n Length:200         Length:200         Length:200            \n Class :character   Class :character   Class :character      \n Mode  :character   Mode  :character   Mode  :character      \n                                                             \n                                                             \n                                                             \n                                                             \n FECHA_APERTURA       FECHA_NOTIFICACION   MOTIVO_CONSULTA   \n Min.   :2021-09-20   Min.   :2023-01-03   Length:200        \n 1st Qu.:2023-04-12   1st Qu.:2023-04-03   Class :character  \n Median :2023-07-16   Median :2023-07-03   Mode  :character  \n Mean   :2023-07-14   Mean   :2023-07-01                     \n 3rd Qu.:2023-10-18   3rd Qu.:2023-10-03                     \n Max.   :2024-04-18   Max.   :2023-12-27                     \n                                                             \n CLASIFICACION_MANUAL CLASIF_INICIO_TRAT ID_PULMONAR       \n Length:200           Length:200         Length:200        \n Class :character     Class :character   Class :character  \n Mode  :character     Mode  :character   Mode  :character  \n                                                           \n                                                           \n                                                           \n                                                           \n      FIS             ID_EXTRAPULMONAR   FECHA_INICIO_SINTOMA\n Min.   :2020-12-20   Length:200         Min.   :2022-08-15  \n 1st Qu.:2023-02-20   Class :character   1st Qu.:2023-03-01  \n Median :2023-05-12   Mode  :character   Median :2023-05-17  \n Mean   :2023-05-10                      Mean   :2023-05-28  \n 3rd Qu.:2023-08-09                      3rd Qu.:2023-08-09  \n Max.   :2023-12-21                      Max.   :2023-12-26  \n NA's   :48                              NA's   :44          \n RESULTADO_RX       Bacteriologia      Baciloscopia         Cultivo         \n Length:200         Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n PRUEBA_RESISTENCIA RESISTENCIA           Droga           Tipo_Resistencia  \n Length:200         Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n ESTABLECIMIENTO_MUESTRA DEPARTAMENTO_MUESTRA ESTABLECIMIENTO_DIAG\n Length:200              Length:200           Length:200          \n Class :character        Class :character     Class :character    \n Mode  :character        Mode  :character     Mode  :character    \n                                                                  \n                                                                  \n                                                                  \n                                                                  \n DEPARTAMENTO_DIAG   Prueba_VIH            VIH           \n Length:200         Length:200         Length:200        \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n TRATAMIENTO_ANTIRRETROVIRAL Diag_rapido        Resultado_diag_rapido\n Length:200                  Length:200         Length:200           \n Class :character            Class :character   Class :character     \n Mode  :character            Mode  :character   Mode  :character     \n                                                                     \n                                                                     \n                                                                     \n                                                                     \n   EMBARAZO           DIABETES         CONSUMO_PROB_DROGAS ENF_RESP_CRONICA  \n Length:200         Length:200         Length:200          Length:200        \n Class :character   Class :character   Class :character    Class :character  \n Mode  :character   Mode  :character   Mode  :character    Mode  :character  \n                                                                             \n                                                                             \n                                                                             \n                                                                             \n    COVID           SE_DECLARA_PUEBLO_INDIGENA  ETNIA        \n Length:200         Length:200                 Mode:logical  \n Class :character   Class :character           NA's:200      \n Mode  :character   Mode  :character                         \n                                                             \n                                                             \n                                                             \n                                                             \n  TABAQUISMO        ALCOHOLISMO         ESTAB_TTO         FECHA_INICIO_TRAT   \n Length:200         Length:200         Length:200         Min.   :2023-01-03  \n Class :character   Class :character   Class :character   1st Qu.:2023-03-20  \n Mode  :character   Mode  :character   Mode  :character   Median :2023-07-02  \n                                                          Mean   :2023-06-28  \n                                                          3rd Qu.:2023-10-05  \n                                                          Max.   :2024-01-08  \n                                                          NA's   :43          \n FECHA_FIN_TRAT       RESULTADO_TRATAMIENTO       ID          duplicado        \n Min.   :2023-03-09   Length:200            Min.   :  1.00   Length:200        \n 1st Qu.:2023-08-21   Class :character      1st Qu.: 50.75   Class :character  \n Median :2023-10-23   Mode  :character      Median :100.50   Mode  :character  \n Mean   :2023-10-23                         Mean   :100.50                     \n 3rd Qu.:2024-01-11                         3rd Qu.:150.25                     \n Max.   :2024-04-05                         Max.   :200.00                     \n NA's   :142                                                                   \n\n\nMás completo y en una sola línea la función find_na() del paquete dlookr muestra el porcentaje de valores perdidos en todas las variables de una tabla de datos y se complementa con el gráfico de barras de pareto plot_na_pareto().\n\nlibrary(dlookr)\n\nfind_na(datos, rate = T) # argumento rate = T muestra % de valores NA\n\n                       SEXO            FECHA_NACIMIENTO \n                        0.0                         0.0 \n           EDAD_DIAGNOSTICO                    GRUPEDAD \n                        0.0                         0.0 \n       PROVINCIA_RESIDENCIA    ID_PROV_INDEC_RESIDENCIA \n                        0.0                         0.0 \n    DEPARTAMENTO_RESIDENCIA   ID_DEPTO_INDEC_RESIDENCIA \n                        4.5                         0.0 \n       LOCALIDAD_RESIDENCIA       ESTABLECIMIENTO_SALUD \n                        0.0                         0.0 \n      ESTABLECIMIENTO_CARGA             PROVINCIA_CARGA \n                        0.0                         0.0 \n                DEPTO_CARGA               ESTAB_CLINICA \n                        0.0                        10.0 \n              DEPTO_CLINICA                         PPL \n                       10.0                         0.0 \n     SERVICIO_PENITENCIARIO              FECHA_APERTURA \n                        0.0                         0.0 \n         FECHA_NOTIFICACION             MOTIVO_CONSULTA \n                        0.0                        90.5 \n       CLASIFICACION_MANUAL          CLASIF_INICIO_TRAT \n                        0.0                         0.0 \n                ID_PULMONAR                         FIS \n                        0.0                        24.0 \n           ID_EXTRAPULMONAR        FECHA_INICIO_SINTOMA \n                        0.0                        22.0 \n               RESULTADO_RX               Bacteriologia \n                        0.0                         0.0 \n               Baciloscopia                     Cultivo \n                        0.0                         0.0 \n         PRUEBA_RESISTENCIA                 RESISTENCIA \n                        0.0                         0.0 \n                      Droga            Tipo_Resistencia \n                        0.0                         0.0 \n    ESTABLECIMIENTO_MUESTRA        DEPARTAMENTO_MUESTRA \n                       36.0                        36.0 \n       ESTABLECIMIENTO_DIAG           DEPARTAMENTO_DIAG \n                       38.0                        38.0 \n                 Prueba_VIH                         VIH \n                        0.0                         0.0 \nTRATAMIENTO_ANTIRRETROVIRAL                 Diag_rapido \n                       99.5                         0.0 \n      Resultado_diag_rapido                    EMBARAZO \n                        0.0                         0.0 \n                   DIABETES         CONSUMO_PROB_DROGAS \n                        0.0                         0.0 \n           ENF_RESP_CRONICA                       COVID \n                        0.0                        99.5 \n SE_DECLARA_PUEBLO_INDIGENA                       ETNIA \n                        0.0                       100.0 \n                 TABAQUISMO                 ALCOHOLISMO \n                        0.0                         0.0 \n                  ESTAB_TTO           FECHA_INICIO_TRAT \n                       17.5                        21.5 \n             FECHA_FIN_TRAT       RESULTADO_TRATAMIENTO \n                       71.0                         0.0 \n                         ID                   duplicado \n                        0.0                        99.0 \n\n\n\nplot_na_pareto(datos, \n               only_na = T) # argumento only_na = T muestra variables solo con algún valor NA",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#gestión-de-nas-con-naniar",
    "href": "unidad3.html#gestión-de-nas-con-naniar",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Gestión de NA’s con naniar",
    "text": "Gestión de NA’s con naniar\n\n\n\n\n\nEl paquete naniar es un paquete que reúne funciones diseñadas para el manejo de valores faltantes pensado para una gestión completa.\n\nlibrary(naniar)\n\n\nAdjuntando el paquete: 'naniar'\n\n\nThe following object is masked from 'package:skimr':\n\n    n_complete\n\n\nSus caracteristicas generales son:\n\nProporciona funciones analíticas y visuales de detección y gestión\nEs compatible con el mundo “tidy” de tidyverse\nAborda las relaciones o estructura de la falta de datos.\nPosibilita el trabajo de imputación (no tratado en este curso)\n\nDe las muchas funciones que tiene el paquete seleccionamos algunas para mostrar que son muy útiles para una tarea básica.\nLa función miss_var_summary() proporciona un resumen sobre los valores NA en cada variable del dataframe similar a find_na() que vimos anterioremente pero con una salida en forma de tabla y un recento absoluto, además de porcentual.\n\nmiss_var_summary(datos)\n\n# A tibble: 58 × 3\n   variable                    n_miss pct_miss\n   &lt;chr&gt;                        &lt;int&gt;    &lt;num&gt;\n 1 ETNIA                          200    100  \n 2 TRATAMIENTO_ANTIRRETROVIRAL    199     99.5\n 3 COVID                          199     99.5\n 4 duplicado                      198     99  \n 5 MOTIVO_CONSULTA                181     90.5\n 6 FECHA_FIN_TRAT                 142     71  \n 7 ESTABLECIMIENTO_DIAG            76     38  \n 8 DEPARTAMENTO_DIAG               76     38  \n 9 ESTABLECIMIENTO_MUESTRA         72     36  \n10 DEPARTAMENTO_MUESTRA            72     36  \n# ℹ 48 more rows\n\n\nPor el lado gráfico, ofrece la función gg_miss_var() que representa la información de la tabla anterior pero a través de un gráfico lollipop horizontal de tipo ggplot2.\n\ngg_miss_var(datos, \n            show_pct = T) # muestra valores en porcentajes\n\n\n\n\n\n\n\n\nHay otra viaulización muy interesante porque muestra las relaciones de los valores ausentes de las variables cuya función se llama gg_miss_upset() y genera un gráfico Upset en función de la existencia de valores NA.\n\ngg_miss_upset(datos) \n\n Por defecto, construye el gráfico tomando las primeras 10 variables de la tabla de datos con valores NA de forma decreciente. Esto se puede modificar cambiando el argumentos nset =.\nTiene dos entradas para su lectura. En la parte inferior izquierda nos muestra los nombres de las variables con valores NA ordenadas de menor a mayor medida en una escala absoluta. El gráfico de barras principal, ordenado de forma predeterminada de mayor a menor, informa sobre las cantidades absolutas de valores NA de las combinaciones que aperecen debajo del eje x del gráfico.\nPor ejemplo, la variable ETNIA tiene todos sus observaciones como NA y la variable COVID casi lo mismo, mientras que la variable FIS cerca de 50.\nPodemos eliminar del gráfico a esas dos variables con casi todos los valores NA, usando formas de tidyverse previas dado que las funciones de naniar son compatibles.\n\ndatos |&gt; \n  select(-ETNIA, -COVID) |&gt; \n  gg_miss_upset() \n\n\nAl quitar esas dos variables, aparecen dos nuevas con cantidades menores de NA que FIS (FECHA_INICIO_TRAT y FECHA_INICIO_SINTOMA), es decir siguen siendo 10 por defecto.\nSi miramos los datos faltantes con estructura notamos que la combinación más frecuente de NA combinados es FECHA_FIN_TRAT, MOTIVO_CONSULTA y TRATAMIENTO_ANTIRETROVIRAL con 39 observaciones a las que le faltan valores en las tres variables simultáneamente.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#reemplazo-de-valores",
    "href": "unidad3.html#reemplazo-de-valores",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Reemplazo de valores",
    "text": "Reemplazo de valores\nEl paquete tiene además dos funciones de reemplazo que funcionan como herramientas antagónicas.\nreplace_with_na() reemplaza valores o etiquetas específicas con valores NA y replace_na_with() hace lo contrario, reemplaza valores NA con valores específicos, como “Sin dato” por ejemplo.\nLa primera función trabaja sobre el dataframe completo adignando valores NA en la categoría o valor que le indiquemos.\nPor ejemplo, la variable ID_PROV_INDEC_RESIDENCIA no tiene valores perdidos pero si hay una categoría/código desconocido (“00”), entonces podemos decirle que ese código sea NA.\n\ndatos |&gt; \n  summarise(Cantidad_NA = sum(is.na(ID_PROV_INDEC_RESIDENCIA)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1           0\n\ndatos |&gt; \n   replace_with_na(replace = list(ID_PROV_INDEC_RESIDENCIA = \"00\")) |&gt;     \n  summarise(Cantidad_NA = sum(is.na(ID_PROV_INDEC_RESIDENCIA)))\n\n# A tibble: 1 × 1\n  Cantidad_NA\n        &lt;int&gt;\n1           2\n\n\nreplace_na_with() etiqueta valores faltantes con categorías definidas que serán tenidas en cuenta a la hora de hacer tablas u otras operaciones. Esta función se utiliza dentro de mutate() del tidyverse.\nLa variable MOTIVO_CONSULTA tiene 181 valores NA que serán etiquetados como “Sin dato” de esta forma:\n\ndatos |&gt; \n  count(MOTIVO_CONSULTA)\n\n# A tibble: 4 × 2\n  MOTIVO_CONSULTA              n\n  &lt;chr&gt;                    &lt;int&gt;\n1 Contacto                     2\n2 Examen de Salud              1\n3 Sintomático Respiratorio    16\n4 &lt;NA&gt;                       181\n\ndatos |&gt; \n  mutate(MOTIVO_CONSULTA = replace_na_with(MOTIVO_CONSULTA, \n                                           \"Sin dato\")) |&gt; \n  count(MOTIVO_CONSULTA)\n\n# A tibble: 4 × 2\n  MOTIVO_CONSULTA              n\n  &lt;chr&gt;                    &lt;int&gt;\n1 Contacto                     2\n2 Examen de Salud              1\n3 Sin dato                   181\n4 Sintomático Respiratorio    16",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad3.html#eliminación-de-valores-na",
    "href": "unidad3.html#eliminación-de-valores-na",
    "title": "Unidad 3: Exploración, diagnóstico y limpieza de datos",
    "section": "Eliminación de valores NA",
    "text": "Eliminación de valores NA\nCuando decidimos eliminar valores NA de alguna variable, salvo que se quite la variable entera, tenemos que tener en cuenta que perdemos la observación completa, incluso valores válidos que se encuentran en otras variables.\nR base tiene una función llamada na.omit() que omite toda observación donde al menos haya un solo NA en alguna variable.\n\nna.omit(datos)\n\n# A tibble: 0 × 58\n# ℹ 58 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;date&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\n\nAplicar esta función sobre el dataframe datos produce que no quede ninguna observación, dado que vimos que la variable ETNIA tenía sus doscientos valores vacíos.\nUna función superadora es drop_na() de tidyr que pertenece a tidyverse, porque omite observaciones que tengan variables que definamos, por ejemplo:\n\ndatos |&gt; \n  drop_na(ETNIA)\n\n# A tibble: 0 × 58\n# ℹ 58 variables: SEXO &lt;chr&gt;, FECHA_NACIMIENTO &lt;date&gt;, EDAD_DIAGNOSTICO &lt;dbl&gt;,\n#   GRUPEDAD &lt;chr&gt;, PROVINCIA_RESIDENCIA &lt;chr&gt;, ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\ndatos |&gt; \n  drop_na(FIS)\n\n# A tibble: 152 × 58\n   SEXO  FECHA_NACIMIENTO EDAD_DIAGNOSTICO GRUPEDAD PROVINCIA_RESIDENCIA\n   &lt;chr&gt; &lt;date&gt;                      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;               \n 1 M     1948-06-22                     74 70-74    Tierra del Fuego    \n 2 F     1981-06-20                     41 40-44    Buenos Aires        \n 3 F     1989-03-30                     33 30-34    Buenos Aires        \n 4 M     2006-11-17                     16 15-19    Chaco               \n 5 M     1993-06-02                     29 25-29    Jujuy               \n 6 M     1989-04-08                     33 30-34    Buenos Aires        \n 7 F     1977-07-30                     45 45-49    Buenos Aires        \n 8 F     2008-01-10                     15 15-19    Chaco               \n 9 M     1987-11-27                    105 35-39    Buenos Aires        \n10 F     2002-12-21                     20 20-24    Buenos Aires        \n# ℹ 142 more rows\n# ℹ 53 more variables: ID_PROV_INDEC_RESIDENCIA &lt;chr&gt;,\n#   DEPARTAMENTO_RESIDENCIA &lt;chr&gt;, ID_DEPTO_INDEC_RESIDENCIA &lt;chr&gt;,\n#   LOCALIDAD_RESIDENCIA &lt;chr&gt;, ESTABLECIMIENTO_SALUD &lt;chr&gt;,\n#   ESTABLECIMIENTO_CARGA &lt;chr&gt;, PROVINCIA_CARGA &lt;chr&gt;, DEPTO_CARGA &lt;chr&gt;,\n#   ESTAB_CLINICA &lt;chr&gt;, DEPTO_CLINICA &lt;chr&gt;, PPL &lt;chr&gt;,\n#   SERVICIO_PENITENCIARIO &lt;chr&gt;, FECHA_APERTURA &lt;date&gt;, …\n\n\nEn el ejemplo anterior aplicamos la función sobre la variable ETNIA y FIS, en el primer caso omite todas las observaciones y en el segundo caso 48 observaciones, mostrando las 152 restantes sin NA en la variable.\nPor último, debemos saber que eliminar observaciones por valores faltantes reduce la potencia de cualquier test de hipotesis o modelo que hagamos porque se reduce el tamaño de la muestra.",
    "crumbs": [
      "Unidad 3: Exploración, diagnóstico y limpieza de datos"
    ]
  },
  {
    "objectID": "unidad5.html",
    "href": "unidad5.html",
    "title": "Unidad 5: Estadísticos, operaciones múltiples y resúmenes",
    "section": "",
    "text": "Con las herramientas conocidas hasta el momento sabemos obtener resúmenes estadísticos de variables cuantitativas usando a summarise() y estratificados a partir de group_by() o el argumento by = de summarise().\nDentro de este andamiaje que produce summarise() se aplican las funciones estadísticas conocidas de lenguaje como:\n\nmin() mínimo\nmax() máximo\nmean() media\nmedian() mediana\nvar() varianza\nsd() desvío\nsum() sumatoria\nfirst() primer valor en el vector\nlast() último valor en el vector\nn() número de valores en el vector\nn_distinct() números de valores distintos en el vector\n\nY tantas otras provenientes de paquetes específicos como construidas (propias).\nEstas tareas, ya sea transformando u obteniendo resultados resumenes de variables, las aplicamos variable a variable, es decir repitiendo las operaciones para cada una de las columnas de una tabla.\nUna premisa del tidyverse, y también de la programación en general, es no copiar y pegar el código mas de dos veces. Si bien esta práctica ahorra tiempo y no esta mal en si mismo, hacerlo suele ser una fuente de errores y además incrementa las líneas de código del script.",
    "crumbs": [
      "Unidad 5: Estadísticos, operaciones múltiples y resúmenes"
    ]
  },
  {
    "objectID": "unidad5.html#introducción",
    "href": "unidad5.html#introducción",
    "title": "Unidad 5: Estadísticos, operaciones múltiples y resúmenes",
    "section": "",
    "text": "Con las herramientas conocidas hasta el momento sabemos obtener resúmenes estadísticos de variables cuantitativas usando a summarise() y estratificados a partir de group_by() o el argumento by = de summarise().\nDentro de este andamiaje que produce summarise() se aplican las funciones estadísticas conocidas de lenguaje como:\n\nmin() mínimo\nmax() máximo\nmean() media\nmedian() mediana\nvar() varianza\nsd() desvío\nsum() sumatoria\nfirst() primer valor en el vector\nlast() último valor en el vector\nn() número de valores en el vector\nn_distinct() números de valores distintos en el vector\n\nY tantas otras provenientes de paquetes específicos como construidas (propias).\nEstas tareas, ya sea transformando u obteniendo resultados resumenes de variables, las aplicamos variable a variable, es decir repitiendo las operaciones para cada una de las columnas de una tabla.\nUna premisa del tidyverse, y también de la programación en general, es no copiar y pegar el código mas de dos veces. Si bien esta práctica ahorra tiempo y no esta mal en si mismo, hacerlo suele ser una fuente de errores y además incrementa las líneas de código del script.",
    "crumbs": [
      "Unidad 5: Estadísticos, operaciones múltiples y resúmenes"
    ]
  },
  {
    "objectID": "unidad5.html#operaciones-múltiples",
    "href": "unidad5.html#operaciones-múltiples",
    "title": "Unidad 5: Estadísticos, operaciones múltiples y resúmenes",
    "section": "Operaciones múltiples",
    "text": "Operaciones múltiples\n\n\n\n\n\nEl paquete dplyr de tidyverse implementa desde hace poco tiempo un esquema de trabajo para operaciones múltiples o simultáneas a través de su función across().\nEsta función se puede utilizar en estructuras de mutate() o summarise() dependiendo del resultado buscado y tiene dos partes fundamentales: la captura o selección de variables donde vamos a aplicar determinadas funciones y la declaración de las funciones a aplicar.\n\nacross()\nLa función se incorporó a partir de la versión de dplyr 1.0.0 y su sintaxis general es:\n\nacross(.cols,  \n       .fns,  \n       ...,  \n       .names)\n\ndonde los argumentos son:\n.cols = columnas a transformar\n.fns = función o funciones para aplicar a cada columna de .cols\n... = argumentos adicionales de las funciones especificadas anteriormente (ejemplo: na.rm = T)\n.names = nombres de las columnas de salida. Aquí, {.col} es un marcador especial al que se le puede agregar el sufijo deseado.\n\n\nAplicación en resúmenes\nVeamos un ejemplo de uso para situaciones donde queremos obtener resumenes simultáneos.\nTomemos la siguiente tabla de datos ficticios:\n\ndatos\n\n# A tibble: 10 × 4\n         a      b      c       d\n     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1 -0.560   1.22  -1.07   0.426 \n 2 -0.230   0.360 -0.218 -0.295 \n 3  1.56    0.401 -1.03   0.895 \n 4  0.0705  0.111 -0.729  0.878 \n 5  0.129  -0.556 -0.625  0.822 \n 6  1.72    1.79  -1.69   0.689 \n 7  0.461   0.498  0.838  0.554 \n 8 -1.27   -1.97   0.153 -0.0619\n 9 -0.687   0.701 -1.14  -0.306 \n10 -0.446  -0.473  1.25  -0.380 \n\n\nSupongamos que queremos calcular la media de cada variable numérica, con lo que sabemos hasta ahora podríamos hacerlo repitiendo para cada variable.\n\ndatos |&gt; summarise(\n  a = mean(a),\n  b = mean(b),\n  c = mean(c),\n  d = mean(d),\n)\n\n# A tibble: 1 × 4\n       a     b      c     d\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 0.0746 0.209 -0.425 0.322\n\n\nPero esto rompe la regla general que buscamos de nunca copiar y pegar más de dos veces, ocasionando que me pueda equivocar al editar el nombre de la variable que va en cada mean() y generando tantas líneas de código como cantidad de variables tengo.\nPara solucionarlo vamos a aplicar across() realizando el resumen simultáneo en una sola línea.\n\ndatos |&gt; summarise(\n  across(.cols = a:d, \n         .fns = mean),\n)\n\n# A tibble: 1 × 4\n       a     b      c     d\n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 0.0746 0.209 -0.425 0.322\n\n\nObservemos que el primer argumento es el rango de nombres de variables que estamos seleccionando donde aplicar la función que aperece como segundo argumento.\nEs decir, que el primer argumento de la función responde de la misma forma que la función select() y por ende, aplican también las funciones ayudantes de selección.\n\n\n\neverything(): coincide con todas las variables.\ngroup_cols(): seleccione todas las columnas de agrupación.\nstarts_with(): comienza con un prefijo.\nends_with(): termina con un sufijo.\ncontains(): contiene una cadena literal.\nmatches(): coincide con una expresión regular.\n\n\n\nnum_range(): coincide con un rango numérico como x01, x02, x03.\nall_of(): coincide con nombres de variables en un vector de caracteres. Todos los nombres deben estar presentes; de lo contrario, se generará un error de fuera de límites.\nany_of(): igual que all_of(), excepto que no se genera ningún error para los nombres que no existen.\nwhere(): aplica una función a todas las variables y selecciona aquellas para las cuales la función regresa TRUE.\n\n\n\nMostremos otra tabla de ejemplo similar a la anterior:\n\ndatos\n\n# A tibble: 10 × 5\n   grupo       a      b       c        d\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n 1 B     -1.12    1.52   0.304   1.03   \n 2 B     -0.403  -1.55   0.448  -0.285  \n 3 A     -0.467   0.585  0.0530 -1.22   \n 4 B      0.780   0.124  0.922   0.181  \n 5 B     -0.0834  0.216  2.05   -0.139  \n 6 B      0.253   0.380 -0.491   0.00576\n 7 A     -0.0285 -0.502 -2.31    0.385  \n 8 A     -0.0429 -0.333  1.01   -0.371  \n 9 B      1.37   -1.02  -0.709   0.644  \n10 A     -0.226  -1.07  -0.688  -0.220  \n\n\nAquí datos agrega una variable categórica llamada grupo con dos valores (A y B).\nUsando group_by() combinada con una selección completa (ayudante everything) del resto de las variables obtenemos las medias por cada uno de estos grupos.\n\ndatos |&gt; \n  group_by(grupo) |&gt; \n  summarise(across(everything(), mean))\n\n# A tibble: 2 × 5\n  grupo      a       b      c      d\n  &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 A     -0.191 -0.331  -0.485 -0.357\n2 B      0.132 -0.0552  0.421  0.239\n\n\nEl argumento .cols también puede recibir construcciones booleanas utilizando los operadores conocidos como ! (negación) y conectores lógicos como & (AND) y | (OR) entre las funciones ayudantes de selección.\n\n.cols = !where(is.numeric) & starts_with(\"a\")\n\nEn este ejemplo, se seleccionan todas las columnas no numéricas, cuyo nombre comienza con “a”.\nHasta ahora vimos el ejemplo de aplicar una función simple como mean() a un grupo de variables.\nQue sucede si entre los datos de esas variables hay valores NA?\n\ndatos_na\n\n# A tibble: 5 × 4\n        a      b      c      d\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1  1.56   -1.27  NA     -0.473\n2 -0.560  NA     -1.05  -1.07 \n3 -0.230   1.22   0.238 -0.218\n4 NA      -0.446  1.29  -1.03 \n5  0.0705 -0.687 NA     -0.729\n\n\nVamos a necesitar incorporar el argumento na.rm = TRUE a la función mean() porque si no el resultado será:\n\ndatos_na |&gt; summarise(\n  across(.cols = a:d, \n         .fns = mean),\n)\n\n# A tibble: 1 × 4\n      a     b     c      d\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1    NA    NA    NA -0.703\n\n\nComo lo hacemos dentro de un across()?\nExisten dos formas sintácticas de realizarlo.\n\nUna función estilo-purrr (tidyverse) que tiene la forma ~ mean(.x, na.rm = TRUE)\nUna función anónima de R base mediante function(x) mean(x, na.rm = TRUE) o más sencilla en su forma de atajo: \\(x) mean(x, na.rm = TRUE)\n\n\n# forma tidyverse (purrr)\n\ndatos_na |&gt; \n  summarise(\n    across(a:d, ~ mean(.x, na.rm = TRUE))\n  )\n\n# A tibble: 1 × 4\n      a      b     c      d\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 0.210 -0.293 0.161 -0.703\n\n\n\n# forma R base (atajo función anómina)\n\ndatos_na |&gt; \n  summarise(\n    across(a:d, \\(x) mean(x, na.rm = TRUE))\n  )\n\n# A tibble: 1 × 4\n      a      b     c      d\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 0.210 -0.293 0.161 -0.703\n\n\nSe le llama función anónima justamente porque no hace falta ponerle nombre. Acostumbrarse a esta notación es más útil que la forma del tidyverse porque aplica también para otras funciones.\nPara incorporar más de una función dentro de across() debemos incluirlas dentro de una lista [list()]\n\ndatos_na |&gt; \n  summarise(\n    across(a:d, list(\n      media = \\(x) mean(x, na.rm = TRUE),\n      desvio = \\(x) sd(x, na.rm = TRUE),\n      n_na = \\(x) sum(is.na(x))))\n  )\n\n# A tibble: 1 × 12\n  a_media a_desvio a_n_na b_media b_desvio b_n_na c_media c_desvio c_n_na\n    &lt;dbl&gt;    &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;int&gt;\n1   0.210    0.936      1  -0.293     1.07      1   0.161     1.17      2\n# ℹ 3 more variables: d_media &lt;dbl&gt;, d_desvio &lt;dbl&gt;, d_n_na &lt;int&gt;\n\n\nLa lista contiene cada función a aplicar, bajo nombres definidos a la izquierda del igual. El resultado muestra 12 variables producto de hacer tres operaciones en cada una de las 4 variables de la tabla.\nObservemos que los nombres de las variables resultado se componen del nombre de la columna, un guión bajo y el nombre definido de la función aplicada (variable_funcion)\nLa estructura de estos nombres se pueden modificar con el argumento .names.\nEl marcador especial para el nombre de columna es {.col} y para el nombre de la función definida es {.fn}.\nPor ejemplo, podríamos invertir el orden predeterminado de los nombres del resumen (funcion_variable)\n\ndatos_na |&gt; \n  summarise(\n    across(a:d, list(\n      media = \\(x) mean(x, na.rm = TRUE),\n      n_na = \\(x) sum(is.na(x))),\n      .names = \"{.fn}_{.col}\")\n  )\n\n# A tibble: 1 × 8\n  media_a n_na_a media_b n_na_b media_c n_na_c media_d n_na_d\n    &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;   &lt;dbl&gt;  &lt;int&gt;\n1   0.210      1  -0.293      1   0.161      2  -0.703      0\n\n\n\n\nAplicación en conversión o creación de nuevas variables\nHasta el momento trabajamos con la función across() dentro de un resumen (summarise) pero al comienzo también dijimos que se puede utilizar para transformaciones masivas de datos.\nLa plataforma para lograr esto es mutate() y lo podemos usar modificando las variables originales o bien creando nuevas variables si cambiamos su nombre con .names.\nPara ejemplificar, aplicaremos la función coalesce() perteneciente a dplyr, para convertir los valores NA en ceros, transformando las variables originales anteriores.\n\ndatos_na |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n\n# A tibble: 5 × 4\n        a      b      c      d\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1  1.56   -1.27   0     -0.473\n2 -0.560   0     -1.05  -1.07 \n3 -0.230   1.22   0.238 -0.218\n4  0      -0.446  1.29  -1.03 \n5  0.0705 -0.687  0     -0.729\n\n\nSi no agregamos ningún otro argumento el reemplazo de los valores NA por 0 se realiza en cada variable sobrescribiendo las observaciones.\nEn cambio, si queremos que coexistan las variables originales con las nuevas incluyendo estos cambios podemos declarar en el argumento .names la estructura de los nombres nuevos.\n\ndatos_na |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0),\n      .names = \"{.col}_na_cero\")\n  )\n\n# A tibble: 5 × 8\n        a      b      c      d a_na_cero b_na_cero c_na_cero d_na_cero\n    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1  1.56   -1.27  NA     -0.473    1.56      -1.27      0        -0.473\n2 -0.560  NA     -1.05  -1.07    -0.560      0        -1.05     -1.07 \n3 -0.230   1.22   0.238 -0.218   -0.230      1.22      0.238    -0.218\n4 NA      -0.446  1.29  -1.03     0         -0.446     1.29     -1.03 \n5  0.0705 -0.687 NA     -0.729    0.0705    -0.687     0        -0.729\n\n\nOtras conversiones posibles pueden utilizar funciones de reemplazo para variables cuantitativas como por ejemplo exp(), log(), scale(), etc. O bien convertir a factor variables character y hasta aplicar funciones condicionales como if_else() o case_when().",
    "crumbs": [
      "Unidad 5: Estadísticos, operaciones múltiples y resúmenes"
    ]
  },
  {
    "objectID": "unidad5.html#filtros-con-iteraciones",
    "href": "unidad5.html#filtros-con-iteraciones",
    "title": "Unidad 5: Estadísticos, operaciones múltiples y resúmenes",
    "section": "Filtros con iteraciones",
    "text": "Filtros con iteraciones\nEl paquete dplyr trae consigo algunas funciones iterativas emparentadas con across() para usar dentro de estructuras de filtro -filter()-, es el caso de if_any() e if_all().\nif_any() enmascara una repetición de OR lógicos if_all() una secuencia de AND lógicos.\nUsémoslas con los datos con los que venimos trabajando.\n\ndatos_na |&gt; \n  filter(if_any(a:d, is.na))\n\n# A tibble: 4 × 4\n        a      b     c      d\n    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  1.56   -1.27  NA    -0.473\n2 -0.560  NA     -1.05 -1.07 \n3 NA      -0.446  1.29 -1.03 \n4  0.0705 -0.687 NA    -0.729\n\n\nDevuelve las observaciones donde en alguna de las variables encuentra algún NA.\nEs lo mismo que filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\n\ndatos_na |&gt; \n  filter(if_all(a:d, is.na))\n\n# A tibble: 0 × 4\n# ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n\nDevuelve las observaciones donde en todas las variables encuentra valores NA. En este caso no hay ninguna que cumpla esa condición, por eso el resultado es un dataframe vacío.\nEs lo mismo que filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\nUna forma rápida de armar filtros por múltiples variables escribiendo poco código.\nLas dos funciones de filtro trabajan con el mismo esquema que across(), por lo tanto se le puede aplicar una función o expresión de condición (todas deben devolver TRUE o FALSE)\n\ndatos |&gt; \n  filter(if_all(a:d, \\(x) x &gt; -0.5 & x &lt; 1))\n\n# A tibble: 2 × 5\n  grupo     a     b      c       d\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 B     0.780 0.124  0.922 0.181  \n2 B     0.253 0.380 -0.491 0.00576\n\n\nAcá el valor de cada en todas las observaciones filtradas debe estar en el rango -0,5 a 1. Hay una que cumple la condición en las 4 variables numéricas.",
    "crumbs": [
      "Unidad 5: Estadísticos, operaciones múltiples y resúmenes"
    ]
  },
  {
    "objectID": "unidad5.html#operaciones-por-fila",
    "href": "unidad5.html#operaciones-por-fila",
    "title": "Unidad 5: Estadísticos, operaciones múltiples y resúmenes",
    "section": "Operaciones por fila",
    "text": "Operaciones por fila\nLa filosofía del tidy-data, es particularmente adecuada para realizar operaciones por columnas (variables). Todas las funciones de resúmenes toman los valores de forma vertical para realizar una operación, como si tuviesemos vectores “parados” dentro de un dataframe.\nHay algunas circunstancias que nos lleva a necesitar realizar operaciones por filas y por supuesto esto es mucho más difícil.\nEl paquete dplyr incorporó en sus últimas versiones la función rowwise() que implementa un agrupamiento por cada fila, haciendo que sea más sencillo hacer estas tareas.\nEl uso más común es hacer calculos agregados por filas (por ejemplo, calcular la media de x, y, z).\nLa apariencia de los resultados de la función son similares a group_by() donde solo vemos cambios en los metadatos del dataframe que luego van a ser aprovechados por las funciones siguientes.\nTenemos un pequeño dataframe de prueba:\n\n\n# A tibble: 2 × 3\n      x     y     z\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n\nY aplicamos la función rowwise()\n\ndf |&gt; \n  rowwise()\n\n# A tibble: 2 × 3\n# Rowwise: \n      x     y     z\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1     3     5\n2     2     4     6\n\n\nLo único que vemos es la aparición de un metadatos que dice “rowwise”. Significa que las filas de la tabla está agrupadas a lo ancho y las funciones que vengan despues van a respetar este agrupamiento.\nPara ver los cambios que produce este agrupamiento veamos un ejemplo comparativo.\n\ndf |&gt;  \n  mutate(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 4\n      x     y     z     m\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1     3     5   3.5\n2     2     4     6   3.5\n\ndf |&gt; \n  rowwise() |&gt; \n  mutate(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 4\n# Rowwise: \n      x     y     z     m\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1     3     5     3\n2     2     4     6     4\n\n\nSi usamos mutate() con un dataframe normal, calcula la media de x, y, z tomando los valores de todas las filas. Si lo aplicamos a una tabla con rowwise, calcula la media de cada fila, tomando los valores de cada una de las tres variables.\nOpcionalmente, se puede indicar variables como “identificador”.\nEstas variables se conservan cuando se llama a un summarise() por ejemplo, por lo que se comportan de manera similar a las variables de agrupación pasadas a group_by().\nCambiamos el dataframe que ahora es:\n\n\n# A tibble: 2 × 4\n  nombre       x     y     z\n  &lt;chr&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1 Mercurio     1     3     5\n2 Venus        2     4     6\n\n\n\ndf |&gt; \n  rowwise() |&gt;   \n  summarise(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 1\n      m\n  &lt;dbl&gt;\n1     3\n2     4\n\ndf  |&gt;  \n  rowwise(nombre) |&gt;  \n  summarise(m = mean(c(x, y, z)))\n\n# A tibble: 2 × 2\n# Groups:   nombre [2]\n  nombre       m\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Mercurio     3\n2 Venus        4\n\n\nrowwise() es solo una forma especial de agrupación por fila, por lo que si deseamos eliminarla de una tabla, simplemente llamamos a ungroup().\n\nc_across()\nLa versión de across() para operaciones simultáneas por filas se llama c_across() y tiene los mismos fundamentos aplicados a estas situaciones, aunque es mucho más sencilla dado que no tiene argumentos extras.\nAplicada sobre el último dataframe:\n\ndf  |&gt;  \n  rowwise(nombre) |&gt;  \n  summarise(m = mean(c_across(x:z)))\n\n# A tibble: 2 × 2\n# Groups:   nombre [2]\n  nombre       m\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Mercurio     3\n2 Venus        4\n\n\nO bien, seleccionando los tipos de datos numéricos:\n\ndf  |&gt;  \n  rowwise(nombre) |&gt;  \n  summarise(m = mean(c_across(where(is.numeric))))\n\n# A tibble: 2 × 2\n# Groups:   nombre [2]\n  nombre       m\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Mercurio     3\n2 Venus        4\n\n\nSin duda este abordaje tiene mayor utilidad cuando las operaciones por fila contemplan muchas variables.",
    "crumbs": [
      "Unidad 5: Estadísticos, operaciones múltiples y resúmenes"
    ]
  },
  {
    "objectID": "unidad5.html#estadísticos-compatibles-con-tidyverse",
    "href": "unidad5.html#estadísticos-compatibles-con-tidyverse",
    "title": "Unidad 5: Estadísticos, operaciones múltiples y resúmenes",
    "section": "Estadísticos compatibles con tidyverse",
    "text": "Estadísticos compatibles con tidyverse\nEl interprete de R trae muchas funciones estadísticas descriptivas y para inferencia disponibles en su versión base pero ninguna de estas son compatibles con la filosofia de trabajo de tidyverse. Es por eso que para utilizar funciones como mean() o median() por ejemplo, debemos introducirlas dentro de estructuras como summarise(). Las funciones de este tipo trabajan sobre vectores y no tienen en cuenta a los dataframes que encapsulan a los vectores como variables.\nTenemos estos datos y vamos a calcular su media.\n\ndatos\n\n# A tibble: 10 × 1\n    Edad\n   &lt;dbl&gt;\n 1    34\n 2    56\n 3    43\n 4    21\n 5    67\n 6    89\n 7    54\n 8    32\n 9    16\n10    76\n\n\nSi lo abordamos con la sintaxis R base:\n\n# Edad es una variable de datos pero llamada así es un vector numérico\n\ndatos$Edad\n\n [1] 34 56 43 21 67 89 54 32 16 76\n\n# preguntamos si es vector\n\nis.vector(datos$Edad)\n\n[1] TRUE\n\n# ejecutamos mean() sobre ese vector\nmean(datos$Edad)\n\n[1] 48.8\n\n\nSi lo abordamos con tuberías.\n\nlibrary(tidyverse)\n\n\ndatos |&gt; \n  mean(Edad)\n\nWarning in mean.default(datos, Edad): argument is not numeric or logical:\nreturning NA\n\n\n[1] NA\n\n\nNecesitamos la función summarise() para que funcione bien.\n\ndatos |&gt; \n  summarise(media_edad = mean(Edad))\n\n# A tibble: 1 × 1\n  media_edad\n       &lt;dbl&gt;\n1       48.8\n\n\nCuando los estadísticos son más complejos que estas funciones descriptivas y devuelven un conjunto de resultados en forma de lista ni siquiera alcanza con aplicarlas dentro de un andamiaje de tidyverse como summarise().\nUn ejemplo de ello, son todas las funciones de R base para comparaciones de inferencia. Tomemos el caso de la prueba t de Student, que sirve para comparar las medias de muestras aproximadamente normales.\nLa función de R base es t.test() y sus argumentos obligatorios son x e y o bien utilizar un formato fórmula (var1 ~ var2)\nPara comparar dos conjuntos de datos con la forma x e y los datos tienen que estar en dos variables separadas y por lo tanto no cumplir con el formato “ordenado”.\n\ndatos\n\n# A tibble: 10 × 2\n   Edad1 Edad2\n   &lt;dbl&gt; &lt;dbl&gt;\n 1    34    45\n 2    56    76\n 3    43    32\n 4    21    12\n 5    67    14\n 6    89    18\n 7    54    20\n 8    32    54\n 9    16    98\n10    76    32\n\n\nAplicamos la función teniendo en cuenta que lo que ingresa en cada argumento es un vector (dataframe$variable)\n\nt.test(x = datos$Edad1, y = datos$Edad2)\n\n\n    Welch Two Sample t-test\n\ndata:  datos$Edad1 and datos$Edad2\nt = 0.73815, df = 17.458, p-value = 0.4702\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -16.11732  33.51732\nsample estimates:\nmean of x mean of y \n     48.8      40.1 \n\n\nEl resultado da un valor de probabilidad de 0,47 lo que indica que no hay diferencias significativas entre las medias de las dos muestras.\nPara usar el formato fórmula es necesario que la tabla de datos cumpla con el formato “ordenado”, quedando:\n\ndatos\n\n# A tibble: 20 × 2\n   Muestra  Edad\n     &lt;dbl&gt; &lt;dbl&gt;\n 1       1    34\n 2       1    56\n 3       1    43\n 4       1    21\n 5       1    67\n 6       1    89\n 7       1    54\n 8       1    32\n 9       1    16\n10       1    76\n11       2    45\n12       2    76\n13       2    32\n14       2    12\n15       2    14\n16       2    18\n17       2    20\n18       2    54\n19       2    98\n20       2    32\n\n\nEn este caso el t.test() lleva formula y datos en el argumento data.\n\nt.test(formula = Edad ~ Muestra, data = datos)\n\n\n    Welch Two Sample t-test\n\ndata:  Edad by Muestra\nt = 0.73815, df = 17.458, p-value = 0.4702\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -16.11732  33.51732\nsample estimates:\nmean in group 1 mean in group 2 \n           48.8            40.1 \n\n\nLo importante acá no es el resultado sino la forma en que lo devuelve. Observaran que no se trata de un formato ordenado ni se parece a una tabla. El tidyverse siempre (salvo raras excepciones, como con pull()) devuelve una tabla de datos ordenada y por eso todas estas funciones son incompatibles, aún utilizando un summarise() y nos dan error:\n\ndatos |&gt; \n  summarise(IC = t.test(Edad ~ Muestra))\n\nError in `summarise()`:\nℹ In argument: `IC = t.test(Edad ~ Muestra)`.\nCaused by error:\n! `IC` must be a vector, not a &lt;htest&gt; object.\n\n\nHace unos años a un desarrollador se le ocurrió crear un paquete que contiene todas estas funciones (y algunas más) del R base en espejo pero compatibles con tidyverse, esto es: reciben un dataframe y devuelven un dataframe.\nEl paquete se llama rstatix y provee un marco simple e intuitivo compatible con el uso de tuberías, coherente con la filosofía de diseño “tidyverse”, para realizar pruebas estadísticas descriptivas básicas y otras más avanzadas de inferencia y modelado.\nLas funciones de inferencia estadística, para comparar medias y proporciones (métodos paramétricos y no paramétricos), ANOVAS, analisis post-hoc, correlaciones y tamaños de efecto, así como también valores p ajustados o agregados de etiquetas de significación no serán explicados en este curso pero aquellxs que les interese profundizar y utilizarlas le pueden sacar un provecho muy útil a este paquete, cuyo sitio es https://rpkgs.datanovia.com/rstatix/index.html.\nRespecto del ejemplo anterior la función de rstatix que reemplaza al t.test() tradicional es t_test(), es decir que al modo tidyverse reemplaza en el nombre el punto por un guión bajo (sucede en todas las funciones del paquete).\n\nlibrary(rstatix)\n\ndatos |&gt; \n  t_test(Edad ~ Muestra, conf.level = .95)\n\n# A tibble: 1 × 8\n  .y.   group1 group2    n1    n2 statistic    df     p\n* &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Edad  1      2         10    10     0.738  17.5  0.47\n\n\nAhora si, el resultado es una tabla de 8 variables por una fila, lo que nos va a permitir poder continuar el trabajo con tuberías. Debajo seleccionamos solo la variable que queremos ver (valor de p).\n\ndatos |&gt; \n  t_test(Edad ~ Muestra, conf.level = .95) |&gt; \n  select(p)\n\n# A tibble: 1 × 1\n      p\n  &lt;dbl&gt;\n1  0.47\n\n\nDentro de los estadísticos descriptivos la función get_summary_stats() devuelve un resumen univariado para variables cuantitativas.\n\ndatos |&gt; \n  get_summary_stats(Edad)\n\n# A tibble: 1 × 13\n  variable     n   min   max median    q1    q3   iqr   mad  mean    sd    se\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Edad        20    12    98   38.5  20.8  58.8    38  26.7  44.4  26.0  5.82\n# ℹ 1 more variable: ci &lt;dbl&gt;\n\n\nY al ser compatible con tidyverse se puede estratificar con group_by().\n\ndatos |&gt; \n  group_by(Muestra) |&gt; \n  get_summary_stats(Edad)\n\n# A tibble: 2 × 14\n  Muestra variable     n   min   max median    q1    q3   iqr   mad  mean    sd\n    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       1 Edad        10    16    89   48.5  32.5  64.2  31.8  25.9  48.8  23.9\n2       2 Edad        10    12    98   32    18.5  51.8  33.2  23.7  40.1  28.6\n# ℹ 2 more variables: se &lt;dbl&gt;, ci &lt;dbl&gt;\n\n\nLa función freq_table() construye tablas con las variables categóricas.\n\ndatos |&gt; \n freq_table(Sexo)\n\n# A tibble: 2 × 3\n  Sexo      n  prop\n  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Mujer    14    70\n2 Varon     6    30\n\n\nTambién agregando otra variables que estratifiquen la salida.\n\ndatos |&gt; \n freq_table(Sexo, Fuma)\n\n# A tibble: 4 × 4\n  Sexo  Fuma      n  prop\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Mujer No       10  71.4\n2 Mujer Si        4  28.6\n3 Varon No        2  33.3\n4 Varon Si        4  66.7\n\n\nUna opción más completa para construir tablas y tablas de contingencia es usar la familia de funciones tabyl() del paquete janitor.\n\nlibrary(janitor)\n\ndatos |&gt; \n  tabyl(Sexo)\n\n  Sexo  n percent\n Mujer 14     0.7\n Varon  6     0.3\n\n\nCalcula las frecuencias absolutas y relativas de variables categóricas de forma similar a freq_table() pero se le pueden modificar sus argumentos y asociar otras funciones del paquete mediante tuberías para obtener mejores resultados (también es compatible con tidyverse).\n\ndatos |&gt;  \n  tabyl(Sexo) |&gt; \n  adorn_totals(where = \"row\") %&gt;% # agregamos totales \n  adorn_pct_formatting(digits = 2) # porcentaje con dos decimales\n\n  Sexo  n percent\n Mujer 14  70.00%\n Varon  6  30.00%\n Total 20 100.00%\n\n\nLa forma más adecuada de describir la relación entre dos variables categóricas es a partir de la construcción de una tabla de contingencia. Para ello se introduce en cada fila de la tabla las categorías de una de las variables y las categorías de la otra variable se asocian a cada una de las columnas de la tabla, en cada celda de la tabla aparecerá el número de observaciones correspondientes a la combinación oportuna de ambas variables. Si bien freq_table() hace lo mismo, respeta la salida ordenada lo que dificulta su lectura.\nCon la misma función tabyl() se puede realizar una tabla de contingencia, incluyendo a la variable Fuma.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) \n\n  Sexo No Si\n Mujer 10  4\n Varon  2  4\n\n\nRecordemos que el orden dentro de los paréntesis de la función es igual al de los índices del lenguage, el primer argumento es la variable que aparecerá en las filas y el segundo la variable de las columnas. Por ese motivo, en la tabla de contingencia absoluta tenemos el Sexo en las filas y a Fuma en las columnas.\nSu salida se puede mejorar con totales por columna y que aparezca el nombre de la variable que esta en la columna:\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt; \n  adorn_title(placement = \"combined\") |&gt; \n  adorn_totals(where = \"row\")\n\n Sexo/Fuma No Si\n     Mujer 10  4\n     Varon  2  4\n     Total 12  8\n\n\nTambién haciendo que los valores sean porcentuales por fila.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt;  \n  adorn_title(placement = \"combined\") |&gt; \n  adorn_totals(where = \"row\") |&gt;  \n  adorn_percentages(denominator = \"row\") |&gt;  #  % por fila\n  adorn_pct_formatting(digits = 2) # redondea con 2 decimales\n\n Sexo/Fuma     No     Si\n     Mujer 71.43% 28.57%\n     Varon 33.33% 66.67%\n     Total 60.00% 40.00%\n\n\nIncoporamos valores absolutos entre paréntesis.\n\ndatos  |&gt;   \n  tabyl(Sexo, Fuma) |&gt;  \n  adorn_totals(where = \"row\") |&gt;  \n  adorn_percentages(denominator = \"row\") |&gt;  \n  adorn_pct_formatting(digits = 2) |&gt; \n  adorn_ns() |&gt; \n  adorn_title() \n\n              Fuma           \n  Sexo          No         Si\n Mujer 71.43% (10) 28.57% (4)\n Varon 33.33%  (2) 66.67% (4)\n Total 60.00% (12) 40.00% (8)\n\n\nEl paquete trae muchas funciones que se integran para construir tablas complejas. Más de estas opciones las pueden encontrar en el sitio oficial del paquete janitor",
    "crumbs": [
      "Unidad 5: Estadísticos, operaciones múltiples y resúmenes"
    ]
  },
  {
    "objectID": "unidad5.html#tablas-para-presentaciones",
    "href": "unidad5.html#tablas-para-presentaciones",
    "title": "Unidad 5: Estadísticos, operaciones múltiples y resúmenes",
    "section": "Tablas para presentaciones",
    "text": "Tablas para presentaciones\nCuando necesitemos presentar resultados estadísticos combinados, producto de variables cuanti y cualitativas a la vez, podemos hechar mano a funciones del paquete gtsummary.\n\n\n\n\n\nEsta librería proporciona una forma elegante y flexible de crear tablas analíticas y de resumen, univariadas, estratificadas y complejas.\nIntegra estimaciones estadísticas predefinidas y se pueden personalizar a gusto, interactuando con otros paquetes como gt, labelled y flextable.\nEn el sitio del desarrollador (gtsummary), encontrarán mucha documentación para adecuar los requerimientos de la salida buscada.\nMostramos un ejemplo en función de unos datos de prueba.\n\nlibrary(readxl)\nlibrary(gtsummary)\n\n\ndatos &lt;- read_excel(\"datos/base2023r.xlsx\")\n\n\ndatos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  tbl_summary()\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN = 2001\n\n\n\n\nEDAD_DIAGNOSTICO\n33 (23, 49)\n\n\nSEXO\n\n\n\n\n    A\n1 (0.5%)\n\n\n    F\n68 (34%)\n\n\n    M\n131 (66%)\n\n\nMOTIVO_CONSULTA\n\n\n\n\n    Contacto\n2 (11%)\n\n\n    Examen de Salud\n1 (5.3%)\n\n\n    Sintomático Respiratorio\n16 (84%)\n\n\n    Unknown\n181\n\n\n\n1 Median (Q1, Q3); n (%)\n\n\n\n\n\n\n\n\nQuizás lo mejor sea presentar los datos estratificados por sexo, por ejmplo. Además configuramos algunos argumentos mas.\n\ndatos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  filter(SEXO != \"A\") |&gt; \n  tbl_summary(by = SEXO,\n              statistic = list(\n                all_continuous() ~ \"{mean} ({sd})\",\n                all_categorical() ~ \"{n} / {N} ({p}%)\"),\n              digits = all_continuous() ~ 1,\n              missing_text = \"Sin dato\") |&gt; \n  modify_header(label ~ \"**Variable**\")\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nF\nN = 681\nM\nN = 1311\n\n\n\n\nEDAD_DIAGNOSTICO\n33.2 (19.1)\n39.1 (18.2)\n\n\nMOTIVO_CONSULTA\n\n\n\n\n\n\n    Contacto\n2 / 7 (29%)\n0 / 12 (0%)\n\n\n    Examen de Salud\n1 / 7 (14%)\n0 / 12 (0%)\n\n\n    Sintomático Respiratorio\n4 / 7 (57%)\n12 / 12 (100%)\n\n\n    Sin dato\n61\n119\n\n\n\n1 Mean (SD); n / N (%)\n\n\n\n\n\n\n\n\nEl argumento statistic permite que, mediante una lista, configuremos los estadísticos a presentar. Para todas las variables continuas seleccionamos la media (mean) y el desvío estandar (sd); para todas las variables categóricas el conteo de cada categoría y el porcentaje. Los decimales de las variables continuas quedan definidos en 1 y cuando aparezcan valores NA serán expresados con la etiqueta “Sin dato”. Por último, la cabecera de la tabla en la comuna de las variables será “Variable” en negrita.\n\nFlextable\n\n\n\n\n\nEstas tablas de presentación de resultados se pueden conectar con el paquete flextable para exportarlas en diferentes formatos, como Word, html, PDF, PowerPoint o imagen y además se vincula con el contenido en estructuras de archivos rmarkdown y/o Quarto.\nUna salida interesante es poder guardar la tabla en formato Word (.docx), porque luego podemos editarla facilmente, para esto la función as_flex_table() convierte al tbl_summary() de gtsummry en clase flextable.\n\nlibrary(flextable)\n\ntabla1 &lt;- datos |&gt; \n  select(EDAD_DIAGNOSTICO, SEXO, MOTIVO_CONSULTA) |&gt;\n  filter(SEXO != \"A\") |&gt; \n  tbl_summary(by = SEXO,\n              statistic = list(\n                all_continuous() ~ \"{mean} ({sd})\",\n                all_categorical() ~ \"{n} / {N} ({p}%)\"),\n              digits = all_continuous() ~ 1,\n              missing_text = \"Sin dato\") |&gt; \n  modify_header(label ~ \"**Variable**\") |&gt; \n  as_flex_table() |&gt; \n  autofit() |&gt;    # ajuste automático \n  theme_box()     # tema box\n\ntabla1\n\nVariableF  N = 681M  N = 1311EDAD_DIAGNOSTICO33.2 (19.1)39.1 (18.2)MOTIVO_CONSULTAContacto2 / 7 (29%)0 / 12 (0%)Examen de Salud1 / 7 (14%)0 / 12 (0%)Sintomático Respiratorio4 / 7 (57%)12 / 12 (100%)Sin dato611191Mean (SD); n / N (%)\n\n\nLuego es posible exportar fácilmente una o más tablas a partir de los objetos flextables almacenados a documentos tipo html, RTF, Word, PowerPoint o PNG.\nUn ejemplo para salidas tipo Word es: save_as_docx()\n\nsave_as_docx(\n  \"tabla 1\" = tabla1, \n  path = \"/resultados/tabla_exportada.docx\")\n\nExporta el objeto tabla1 en el archivo tabla_exportada.docx dentro de la carpeta resultados.\nTodos los objetos de clase flextable están compuestos por tres partes:\n\nheader: de forma predeterminada, solo hay una fila de encabezado que contiene los nombres del dataframe.\n\nbody: la parte del cuerpo contiene datos del dataframe.\nfooter: la parte del pie de tabla no está implementada de forma predeterminada, pero puede contener notas al pie o cualquier contenido.\n\n\n\n\n\n\nVamos a retomar, con mayor profundidad, estos paquetes cuando trabajemos con archivos Quarto donde integremos productos elaborados mediante código (resultados, tablas y gráficos) con elementos de documentación (textos y otros cosas de markdown).",
    "crumbs": [
      "Unidad 5: Estadísticos, operaciones múltiples y resúmenes"
    ]
  },
  {
    "objectID": "unidad7.html",
    "href": "unidad7.html",
    "title": "Unidad 7: Visualización de datos",
    "section": "",
    "text": "“Un simple gráfico ha brindado más información a la mente del analista de datos que cualquier otro dispositivo”. — John Tukey\n\n\n\nLa visualización de datos puede ser un medio muy eficaz para identificar patrones en los datos y transmitir un mensaje.\nEl objetivo científico de cualquier visualización es permitir al lector comprender datos y extraer información intuitivamente, de la forma más precisa y eficiente.\nGeneralmente construimos visualizaciones para dos fines:\nComo parte del análisis exploratorio (EDA) para descubrir y describir patrones en los datos o para presentar y comunicar, logrando transmitir el mensaje de forma clara y atractiva.\nEs importante, al crear una visualización, considerar las características del público objetivo. La interpretación está en el ojo del espectador, y una visualización sólo logrará transmitir su mensaje si se diseña teniendo en cuenta a su audiencia.\nUna visualización de datos exitosa logra:\n\nCaptar la atención: En un mar de texto, se destacará una visualización. Si un lector tiene poco tiempo o no está seguro de si un documento es de interés, una visualización que llame la atención puede incitarlo a comenzar a leer.\nMejorar el acceso a la información: Las descripciones textuales pueden ser largas y difíciles de leer, mientras que las visualizaciones creadas hábilmente permiten extraer información clave de manera más eficiente, lo que hace que la extracción de información sea una tarea divertida.\nAumentar la precisión: Las narrativas suelen ser menos precisas que una representación visual que muestra puntos de datos y sus ejes correspondientes, mientras que un texto con demasiados datos puede dificultar el seguimiento de la línea argumental.\nResumir contenido: Los gráficos y tablas permiten resumir contenido textual complejo, ayudando al lector a memorizar puntos clave.\n\nPor estas razones, las visualizaciones de datos son elementos clave en cualquier tipo de publicación: artículos científicos, presentaciones, posters, etc\nLas tablas también son una forma de visualizar datos y resúmenes estadísticos. Suelen ser componentes igualmente importantes en una publicación y en algunos casos, una tabla puede visualizar los datos mejor que un gráfico.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#introducción",
    "href": "unidad7.html#introducción",
    "title": "Unidad 7: Visualización de datos",
    "section": "",
    "text": "“Un simple gráfico ha brindado más información a la mente del analista de datos que cualquier otro dispositivo”. — John Tukey\n\n\n\nLa visualización de datos puede ser un medio muy eficaz para identificar patrones en los datos y transmitir un mensaje.\nEl objetivo científico de cualquier visualización es permitir al lector comprender datos y extraer información intuitivamente, de la forma más precisa y eficiente.\nGeneralmente construimos visualizaciones para dos fines:\nComo parte del análisis exploratorio (EDA) para descubrir y describir patrones en los datos o para presentar y comunicar, logrando transmitir el mensaje de forma clara y atractiva.\nEs importante, al crear una visualización, considerar las características del público objetivo. La interpretación está en el ojo del espectador, y una visualización sólo logrará transmitir su mensaje si se diseña teniendo en cuenta a su audiencia.\nUna visualización de datos exitosa logra:\n\nCaptar la atención: En un mar de texto, se destacará una visualización. Si un lector tiene poco tiempo o no está seguro de si un documento es de interés, una visualización que llame la atención puede incitarlo a comenzar a leer.\nMejorar el acceso a la información: Las descripciones textuales pueden ser largas y difíciles de leer, mientras que las visualizaciones creadas hábilmente permiten extraer información clave de manera más eficiente, lo que hace que la extracción de información sea una tarea divertida.\nAumentar la precisión: Las narrativas suelen ser menos precisas que una representación visual que muestra puntos de datos y sus ejes correspondientes, mientras que un texto con demasiados datos puede dificultar el seguimiento de la línea argumental.\nResumir contenido: Los gráficos y tablas permiten resumir contenido textual complejo, ayudando al lector a memorizar puntos clave.\n\nPor estas razones, las visualizaciones de datos son elementos clave en cualquier tipo de publicación: artículos científicos, presentaciones, posters, etc\nLas tablas también son una forma de visualizar datos y resúmenes estadísticos. Suelen ser componentes igualmente importantes en una publicación y en algunos casos, una tabla puede visualizar los datos mejor que un gráfico.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#principios-y-elementos-de-las-visualizaciones",
    "href": "unidad7.html#principios-y-elementos-de-las-visualizaciones",
    "title": "Unidad 7: Visualización de datos",
    "section": "Principios y elementos de las visualizaciones",
    "text": "Principios y elementos de las visualizaciones\nLas visualizaciones de datos deben tener un propósito que no debemos de perder de vista en el proceso de construcción.\nPodría decirse que un propósito general de una visualización es comparar grupos de datos, como datos sobre pacientes que reciben diferentes tratamientos. Una buena elección de ejes, límites de ejes, etiquetas y símbolos puede facilitar sustancialmente la identificación de patrones en los datos, mientras que una mala elección de cualquiera de estos elementos puede dificultar sustancialmente la extracción de información.\n\nElementos gráficos\nVarios elementos de una visualización pueden contribuir a la eficacia con la que se puede mostrar a la información, pero básicamente todos están compuestos por signos visuales y geométricas primitivas.\n\n\n\n\n\nCuando seleccionamos un tipo de gráfico estadístico como un gráfico de barras, un boxplot o una dispersión de puntos estamos usando varios de estos signos visuales como líneas, puntos, areas, con colores, tamaños y posiciones diferentes.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#elegir-un-tipo-de-visualización",
    "href": "unidad7.html#elegir-un-tipo-de-visualización",
    "title": "Unidad 7: Visualización de datos",
    "section": "Elegir un tipo de visualización",
    "text": "Elegir un tipo de visualización\nChristian Hennig, profesor de estadística de la Universidad de Bolonia, sugiere resolver las siguientes preguntas:\n\n\n¿El objetivo del gráfico es descubrir algo (“gráfico de análisis EDA”) o dejar claro algo a los demás?\n¿Qué quieres saber?\n¿Quién es la audiencia del gráfico?\n\n\n\nTipos de gráfico\nLos posibles tipos de gráfico están relacionados a las características de los datos, cuantas variables necesito mostrar, de que tipo son y que cualidad de esas variables me interesa.\nEl sitio From Data to Viz muestra una serie de árboles de decisión, cada uno de los cuales conduce a diferentes formatos de gráficos recomendados según el tipo de datos seleccionados (numéricos, categóricos, etc.).",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#gramática-de-gráficos",
    "href": "unidad7.html#gramática-de-gráficos",
    "title": "Unidad 7: Visualización de datos",
    "section": "Gramática de gráficos",
    "text": "Gramática de gráficos\nLa llamada “La gramática de gráficos” define un conjunto de reglas para construir gráficos estadísticos combinando diferentes tipos de capas, de manera similar a la gramática lingüística.\nEsta idea fue propuesta por Leland Wilkinson en su publicación de 2005 (The Grammar of Graphics - Statistics and Computing - USA).\nLa publicación inspiró a los desarrolladores del paquete ggplot2, el primer paquete del universo tidyverse lanzado en 2007, que se basa en un sistema de capas. El “gg” en el nombre se refiere a la “gramática de los gráficos” utilizada para construir las figuras.\n\n\n\n\n\nSegún la idea de Wilkinson, que aplica ggplot2, todo gráfico parte de los datos que queremos visualizar y vamos enlazando diferentes capas estéticas con elementos geométricos, escalas, ejes, facetas y temas.\nggplot2 necesita de tres componentes básicos y obligatorios para generar una visualización:\n\nDatos con estructura “ordenada”\nMapeo estético (aesthetic) de los datos\nObjeto geométrico que da nombre al tipo de gráfico\n\nSubyace siempre:\n\nCoordenadas que organizan los objetos geométricos\n\nY se le puede agregar:\n\nEscalas (scale) definen el rango de valores de las estéticas\nFacetas que agrupan en subgráficos\nTemas estéticos preconfigurados (themes)\n\nLa sintaxis básica de los tres elementos necesarios es:\n\n[dataframe] |&gt;  \n  ggplot(mapping = aes(&lt;MAPEO&gt;)) +\n  geom_xxx()\n\nObservamos que las capas del ggplot se añaden con un signo +, a diferencia de las tuberías que conectan otras funciones de tidyverse.\nAlgunas de las capas posteriores que son opcionales:\n\n[dataframe] |&gt;  \n  ggplot(mapping = aes(x = [x-varible],\n                       y = [y-variable])) +\n  geom_xxx() +\n  scale_x_...() +\n  scale_y_...() +\n  scale_fill_...() +\n  otras capas más\n\nEl mapeo estético permite definir el rol que cada variable representa en el gráfico. Los roles comunes son: eje x, eje y, color de contorno y color de relleno. Existen otros especiales como de text,agrupamiento u opacidad.\nLa simultáneidad de variables provoca que se puedan realizar gráficos con 2, 3 o n variables.\nPor supuesto que esta definición conecta con el elemento geométrico seleccionado. Por ejemplo, si el elemento geométrico es un geom_point() generamos un diagrama de dispersión de puntos y para esto necesitamos definir como mínimo una variable en el eje x y otra en el eje y que deberán ser numéricas. También podríamos definir alguna variable que mapee el color de los puntos, es decir una tercera variable participante.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#ejemplo-de-gráfico-de-dispersión",
    "href": "unidad7.html#ejemplo-de-gráfico-de-dispersión",
    "title": "Unidad 7: Visualización de datos",
    "section": "Ejemplo de gráfico de dispersión",
    "text": "Ejemplo de gráfico de dispersión\nNada mejor que ver un ejemplo para explicar el funcionamiento del sistema gráfico de ggplot2. Realicemos paso a paso un gráfico de dispersión de puntos:\nTenemos estos datos ficticios para probar el paquete.\n\ndatos\n\n# A tibble: 51 × 3\n       x     y z    \n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1     2     1 A    \n 2     5     2 A    \n 3     7     2 A    \n 4     4     2 A    \n 5     1     3 A    \n 6     8     4 A    \n 7     1     4 A    \n 8     9     5 A    \n 9     2     5 A    \n10     6     5 A    \n# ℹ 41 more rows\n\n\nA partir de datos vamos a conectar mediante una tubería a la función ggplot(), que tiene como argumento obligatorio mapping. Dentro del argumento se utiliza la función aes() para las definiciones estéticas que “mapeen” la o las variables del dataframe datos.\nDefinimos que la variable x se grafique en el eje x y la variable y lo haga en el eje y. Por supuesto que las coordenadas que utilice el gráfico serán cartesianas.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y))\n\n\n\n\n\n\n\n\nObservemos que tanto x como y aparecen en cada eje como etiqueta y que las escalas se generan automáticamente a partir de las escalas de las variables. Dentro del lienzo gris del plot no se visualiza aún ningún elemento geométrico.\nAgreguemos la primer capa en el ggplot para indicarle que elemento geométrico usaremos. En este caso geom_point() define una capa de puntos. La capa geométrica le da forma y nombre al tipo de gráfico.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y)) + \n  geom_point(size = 3)\n\n\n\n\n\n\n\n\nSe puede hacer participar a otra variable más que mapeamos con el color de los puntos. En este caso la variable categórica z de datos.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3)\n\n\n\n\n\n\n\n\nNotemos que cuando mapeamos variables lo hacemos dentro de la función aes() del mapping del ggplot. Esta función permite mapear ejes, colores de contorno y relleno, opacidades, entre otros elementos graficos.\nSi en lugar de mapear una variable queremos definir un color fijo para un elemento gráfico debemos escribirlo fuera del aes(). Por ejemplo, para que todos los puntos sean color azul debemos escribir el argumento color = “blue” dentro del geom_point() directamente. Además cambiamos el tamaño y forma del punto.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y)) + \n  geom_point(color = \"blue\", shape = 17, size = 3)\n\n\n\n\n\n\n\n\nLas formas de puntos surgen de esta tabla numerada.\n\n\n\n\n\nLos mapeos declarados en la función ggplot() principal son globales, es decir que aplican a todas las capas con elementos geométricos posteriores. Para mostrar su efecto agregamos una capa de recta de regresión (en este caso con el método de regresión lineal).\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nEl gráfico muestra que para cada conjunto de puntos (categoría A y B de la variable z) de dibuja una recta distinta respectando la declaración global del aes().\nEn cambio, si a la variable z la declarásemos solo en una de las capas geométricas (por ejemplo la de puntos), obtendríamos una sola recta de regresión, dado que esa definición termina siendo local y no global.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y)) + \n  geom_point(aes(color = z), size = 3) +           # estética local (solo en puntos)\n  geom_smooth(method = \"lm\")",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#estéticas",
    "href": "unidad7.html#estéticas",
    "title": "Unidad 7: Visualización de datos",
    "section": "Estéticas",
    "text": "Estéticas\nObservamos que la estética de un gráfico refiere a alguna propiedad visual que representa a los datos que estamos mostrando gráficamente.\nLos argumentos posibles dentro de aes() son:\ncolor = color de la línea de contorno de un polígono tipo barra, boxplot, etc., o el color de punto y lineas.\nfill = el color de relleno de polígonos (por ejemplo, de una barra, boxplot, áreas, etc)\nshape = formas que representan un punto (estrella, triángulo, cuadrado, círculo, etc)\nsize = tamaño del geom (por ejemplo, grosor de línea, tamaño de punto)\nalpha = transparencia (1 = opaco, 0 = invisible)\nwidth = ancho de las columnas de un gráfico de barras\nlinetype = tipo de línea (por ejemplo, sólida, discontinua, punteada)",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#capa-geométrica",
    "href": "unidad7.html#capa-geométrica",
    "title": "Unidad 7: Visualización de datos",
    "section": "Capa geométrica",
    "text": "Capa geométrica\nAnteriormente decíamos que el tipo de gráfico que queremos construir se decide por el elemento geométrico utilizado en la estructura del ggplot.\nEntre las funciones más utilizadas tenemos:\n\n\n\nGráfico\nFunción\n\n\n\n\nÁrea\ngeom_area()\n\n\nDensidad\ngeom_density()\n\n\nPolígono de frecuencia\ngeom_freqpoly()\n\n\nHistograma\ngeom_histogram()\n\n\nQQ-Plot\ngeom_qq()\n\n\nBarras\ngeom_bar()\n\n\nPuntos\ngeom_point()\n\n\nLínea regresión\ngeom_smooth()\n\n\nLíneas\ngeom_line()\n\n\nBoxplot\ngeom_boxplot()\n\n\nViolin plot\ngeom_violin()\n\n\nBarras de error\ngeom_errorbar()\n\n\nDotplot\ngeom_dotplot()\n\n\nPuntos al azar\ngeom_jitter()\n\n\nTexto\ngeom_text()\n\n\nEtiquetas\ngeom_label()\n\n\n\nMuchas de estas funciones se utilizan simultáneamente en capas diferentes del gráfico, por ejemplo podemos hacer un gráfico de barras con una capa de etiquetas. Algunas de las funciones se construyen con estéticas cuantitativas (boxplot) o categóricas (barras), pero también se pueden combinar (por ejemplo, un boxplot por cada categoría de una variable cualitativa).\nTambién se pueden activar otros paquetes que extienden la idea del ggplot para crear gráficos con otras capas, como heatmap, ridgeline, dispersión de puntos con barras marginales, rain plot, treemaps, waffles, Upset, etc.\nLas estéticas van a cambiar en base al elemento geométrico elegido. En un diagrama de puntos puede que usemos size, color, shape para el tamaño, el color y la forma del punto respectivamente y en un gráfico de barras podemos usar fill y width para el color de relleno y el ancho de la barra, por ejemplo.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#ejes",
    "href": "unidad7.html#ejes",
    "title": "Unidad 7: Visualización de datos",
    "section": "Ejes",
    "text": "Ejes\nLos gráficos con coordenadas cartesianas tienen dos ejes. Estos se pueden configurar mediante las capas scale_x_* y scale_y_*. Hay escalas para distintos tipos de datos y ggplot implementa funciones con sufijos como:\n\ncontinuous: valores continuos\ndate: valores tipo fecha\ndatetime: valores fecha y hora\nlog10: valores logaritmicos\ndiscrete: valores discretos\n\nEstas funciones tienen argumentos comunes para definir los límites (limits), el titulo (name) y los cortes que queremos para las marcas del eje (breaks).\nEn ocasiones necesitamos construir gráficos con doble eje y, es decir visualizar simultáneamente dos variables relacionadas con el mismo eje x donde cada una tiene una escala diferente.\nAlgunas de esta funciones de escala traen un argumento especial llamado sec.axis = que se puede combinar con la función de ggplot del mismo nombre (sec_axis()) para definir ese segundo eje que será representado en el extremo derecho del gráfico.\nsec_axis() no permite construir un eje y completamente nuevo. Simplemente construye uno basado en el primero, aplicando una transformación matemática, como el logaritmo o la raíz cuadrada.\nHabrá que tener en cuenta que las magnitudes de escala de ambas capas sean consistentes para lograr una visualización armoniosa.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#facetas",
    "href": "unidad7.html#facetas",
    "title": "Unidad 7: Visualización de datos",
    "section": "Facetas",
    "text": "Facetas\nLas facetas son una herramienta poderosa en ggplot2 que permite dividir un gráfico en múltiples paneles, cada uno mostrando la información para un subgrupo específico de los datos. Esto resulta particularmente útil para explorar la interacción entre dos o más variables categóricas, facilitando la identificación de patrones y tendencias que podrían pasar desapercibidos en un gráfico único.\nLas facetas se implementan principalmente mediante dos funciones: facet_wrap() y facet_grid().\n\nfacet_wrap() organiza los paneles por una única variable categórica, creando filas o columnas de gráficos según el número de niveles de la variable.\nfacet_grid() utiliza dos variables categóricas para organizar los paneles en una cuadrícula, permitiendo explorar la interacción entre ambas variables.\n\nLas facetas no solo mejoran la organización de la información, sino que también incrementan la claridad y la legibilidad de los gráficos, especialmente cuando se trata de conjuntos de datos con múltiples categorías. Además, permiten crear gráficos más compactos y eficientes en cuanto al espacio, aprovechando al máximo el área disponible.\nCon los datos anteriores podemos utilizar la variable z para sumar una capa de facetas.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3) +  \n  facet_wrap(~z) # formato columnas",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#colores",
    "href": "unidad7.html#colores",
    "title": "Unidad 7: Visualización de datos",
    "section": "Colores",
    "text": "Colores\nOtro elemento esencial para lograr gráficos atractivos son los colores. ggplot2 ofrece una amplia gama de funciones scale_* que permiten personalizar y controlar el uso del color en cada componente del gráfico.\n\nPaletas de colores\nggplot2 proporciona paletas predeterminadas para diferentes tipos de datos, como Set1, Set2, Darked, etc.\nAdemás, existen paquetes externos como RColorBrewer y viridis que ofrecen una amplia variedad de paletas de colores adicionales. La elección de la paleta dependerá del tipo de datos, la estética deseada y el mensaje que se quiere transmitir con el gráfico.\nUn sitio útil que muestra paquetes de paletas de colores es Palette finder. Esos paquetes deben ser instalados y activados previamente para poder utilizar sus colores.\n\n\nFunciones scale_*\nExisten dos funciones scale_*() principales que permiten ajustar el uso del color en las partes de los elementos gráficos:\n\nscale_color_*(): Define la paleta de colores y la asignación de colores de contorno o elementos tipo puntos y lineas.\nscale_fill_*(): Controla el color de relleno para elementos como barras o áreas.\n\nEl asterisco se reemplaza por nombres que refieren a una característica de la escala y el tipo de variable asociada:\nscale_color_discrete() para variables categóricas\nscale_fill_continuous() para variables cuantitativas continuas\nscale_color_manual() para definir colores en forma manual\nR es compatible con muchos formatos de colores. Tiene 657 colores bajo nombres que se pueden visualizar mediante la ejecución de la función colors(), también se puede convocar mediante números y expande sus posibilidades a partir del formato hexadecimal hasta 16.777.216 combinaciones.\nLa página ColorHexa entre otras similares ofrecen seleccionar colores visualmente y copiar el código hexadecimal correspondiente.\nOtra cuestión a tener en cuenta es la accesibilidad para personas daltónicas, es decir utilizar paletas de colores amigables que garanticen que la información sea accesible para todxs. Un paquete en R que aborda este tema es colorBlindness.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#coordenadas",
    "href": "unidad7.html#coordenadas",
    "title": "Unidad 7: Visualización de datos",
    "section": "Coordenadas",
    "text": "Coordenadas\nEs muy fácil invertir un gráfico. La función de coordenadas coord_flip() es todo lo que se necesita para hacerlo. Esto es útil con gráficos de barras para dibujarlas horizontales, por ejemplo. También funciona con cualquier otro tipo de capa geométrica.\nSi necesitamos ajustar un eje con respecto a otro (relación de aspecto del sistema de coordenadas cartesianas) se puede aplicar coord_fixed().\nTomando el diagrama de dispersión previo:\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 2) +\n  coord_fixed(ratio = 1/3) \n\n\n\n\n\n\n\n\nTambién se puede transformar a las coordenadas cartesianas en polares con coord_polar() para la construcción de gráficos circulares como de torta/sectores o similares.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#pirámides-poblacionales",
    "href": "unidad7.html#pirámides-poblacionales",
    "title": "Unidad 7: Visualización de datos",
    "section": "Pirámides poblacionales",
    "text": "Pirámides poblacionales\nUn gráfico habitual, que utilizamos tomado de la demografía, es la pirámide poblacional. Estos gráficos dan cuenta de la estructura de una población, en función del sexo y edad.\nEl gráfico tiene la forma de un histograma de barras horizontales:\n\nEl eje vertical representa los grupos de edad (por lo general, en intervalos de 5 años).\nEl eje horizontal muestra la cantidad o porcentaje de personas en cada grupo.\nSe divide en dos lados: la izquierda para hombres y la derecha para mujeres.\n\nSegún la forma, las pirámides pueden ser:\n\nProgresiva (piramidal o expansiva): Base ancha, indica alta natalidad y alta mortalidad (ejemplo: países con población joven y en crecimiento).\nEstacionaria: Base y parte media similares, refleja estabilidad demográfica (ejemplo: países con baja natalidad y mortalidad equilibrada).\nRegresiva (contractiva): Base más angosta que la parte superior, indica envejecimiento de la población (ejemplo: países con baja natalidad y población envejecida).\n\nPara su construcción, como siempre, partimos los datos. Estos tienen que contener las variables Edad (grupos etarios regulares cada 5 años), Sexo (mujeres y varones) y población de cada subgrupo.\nLuego ingresamos con esos datos en una estructura de ggplot, pero antes debemos incorporar un signo negativo a las poblaciones de los varones (para que las barras se construyan hacia la izquierda del eje 0).\nUna estructura completa de pirámide podría ser:\n\ndatos |&gt; \n  ggplot(aes(x = Edad, fill = Sexo, y = Poblacion)) +\n       geom_bar(stat = \"identity\")+\nscale_y_continuous(breaks = seq(-2000000, 2000000, 1000000), \n            labels = paste0(as.character(c(2:0, 1:2)), \"m\")) +\ncoord_flip() +\nscale_fill_brewer(palette = \"Set1\",direction = -1) +\ntheme_bw() +   labs(y = \"Población\", \ntitle = \"Piramide poblacional Argentina - Año xxxx\")",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#corredor-endémico",
    "href": "unidad7.html#corredor-endémico",
    "title": "Unidad 7: Visualización de datos",
    "section": "Corredor endémico",
    "text": "Corredor endémico\nOtras herramientas epidemiológica muy utilizadas, son los corredores endémicos. Aplicados a la vigilancia epidemiológica para la toma de decisiones, activando alertas y para poder comparar tendencias antes y despues de una intervención, por ejemplo.\nPermiten visualizar y analizar la variabilidad de una enfermedad a lo largo del tiempo en una población determinada.\nExisten varias técnicas para su construcción. La más común es utilizar cuartiles:\n\nSelección de datos históricos: Se recopilan datos de incidencia de la enfermedad en años previos, idealmente de al menos 5 o 7 años.\nCálculo de percentiles: Se dividen los datos en franjas de riesgo utilizando percentiles (ejemplo: P25, P50, P75 y P90), lo que permite identificar umbrales para diferentes niveles de alerta.\nVisualización gráfica: Se representa la incidencia semanal o mensual en un gráfico con bandas de colores que indican distintas zonas de riesgo:\n\n\nZona de éxito (bajo riesgo): Incidencia por debajo del percentil 25.\nZona de seguridad (esperada): Entre los percentiles 25 y 75.\nZona de alerta: Entre los percentiles 75 y 90.\nZona de epidemia: Por encima del percentil 90.\n\nDe esta forma, se pueden detectar brotes cuando los casos actuales superan las zonas de alerta y/o epidemia.\nOtra manera de construir estos corredores es por medio de la media geométrica. Método publicado por Marcelo Bortman ver publicación.\nConsiste en calcular la media geométrica de las tasas y sus intervalos de confianza (mayor solidez estadística).\nLa media geométrica la calculamos haciendo el logaritmo de la tasa para cada año, luego se calcula la media y los intervalos de confianza, y finalmente se hace el antilogaritmo\nUna limitación del método es que los valores deben ser siempre mayores de 0, ya que no es posible calcular el logaritmo de 0 ni de números negativos. Para sortear ese escollo, Betty Kirkwood recomienda sumarles 1 a todos los valores originales, realizar los cálculos y, finalmente, restar 1 a los valores finales.\nEn el script Corredor.R de la unidad 6 hay un ejemplo paso a paso, partiendo de datos de vigilancia de enfermedades respiratorias, para generar corredores endémicos por los dos métodos.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#personalización",
    "href": "unidad7.html#personalización",
    "title": "Unidad 7: Visualización de datos",
    "section": "Personalización",
    "text": "Personalización\nLa función theme() de ggplot2 brinda el poder de personalizar cada aspecto de la estética de un gráfico.\nCon theme() se puede modificar elementos como:\n\nFuentes: Selecciona las fuentes para títulos, etiquetas y textos del gráfico.\nLeyenda: Controla la posición, el formato y el estilo de la leyenda.\nEjes: Personaliza el grosor, el color, las marcas y las etiquetas de los ejes.\nTítulo: Define el estilo y la ubicación del título del gráfico.\nCuadrícula (grid): Controla la apariencia de la cuadrícula de fondo, incluyendo su color, grosor y tipo de línea.\n\nLos argumentos de la función theme() comienzan con un nombre del elemento en cuestión y le siguen nombres relacionados a caracteristicas de esos elementos.\nPor ejemplo, para los ejes, el argumento axis.* tiene nombres como title, text, ticks, line que se igualan a funciones tipo element_line() para personalización de líneas, element_text() para textos, etc.\nHagamos un pequeño ejemplo con el gráfico de puntos que desarrollamos en el documento.\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3) +\n  labs(title = \"Grafico de puntos\", # titulo de grafico\n       x = \"Eje x\", # titulo de eje x\n       y = \"Eje y\") + # titulo de eje y\n  scale_colour_brewer(palette = \"Set1\", # paleta Set1 en color\n                      name = \"Variable z\") + \n  theme(axis.title.x = element_text(face = \"bold\"), # titulo de eje x en negrita\n        axis.title.y = element_text(color = \"red\"), # titulo de eje y color rojo\n        axis.text.x = element_text(size = 8), # texto de eje x tamaño 7 pts\n        axis.text.y = element_text(face = \"italic\"), # texto de eje y en itálica\n        legend.title = element_text(size = 14), # titulo de leyenda tamaño 12 pts\n        plot.title = element_text(size = 18, face = \"bold\")) # titulo de grafico tamaño 16 pts y negrita\n\n\n\n\n\n\n\n\nPersonalizar temas permite mantener un estilo consistente en diferentes gráficos para crear una experiencia visual uniforme y mejorar su legibilidad.\nEs muy útil almacenar la personalización y aplicarla a los gráficos donde la necesitamos.\n\nmi_tema &lt;- theme(axis.title.x = element_text(face = \"bold\"), \n        axis.title.y = element_text(color = \"red\"),\n        axis.text.x = element_text(size = 8), \n        axis.text.y = element_text(face = \"italic\"), \n        legend.title = element_text(size = 14), #\n        plot.title = element_text(size = 18, face = \"bold\")) \n\n\ndatos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 3) +\n  labs(title = \"Grafico de puntos\", # titulo de grafico\n       x = \"Eje x\", # titulo de eje x\n       y = \"Eje y\") + # titulo de eje y\n  scale_colour_brewer(palette = \"Set1\", # paleta Set1 en color\n                      name = \"Variable z\") + \n  mi_tema\n\n\n\n\n\n\n\n\nSe sugiere comenzar con personalizaciones simples y avanzar gradualmente a modificaciones más complejas de forma progresiva.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#exportación",
    "href": "unidad7.html#exportación",
    "title": "Unidad 7: Visualización de datos",
    "section": "Exportación",
    "text": "Exportación\nLa función ggsave() exporta los graficos generados por ggplot2 en distintos formatos, tamaños y resoluciones.\nLa sintaxis con los argumentos opcionales es:\n\nggsave(filename,               # nombre del archivo\n  plot = last_plot(),          # nombre del objeto gráfico\n  device = NULL,               # formato de salida \"jpeg\", \"png\", \"tiff\", \"pdf\", etc\n  width = NA,                  # ancho en unidades de units\n  height = NA,                 # alto en unidades de units\n  units = c(\"in\", \"cm\", \"mm\"), # unidades de medidas\n  dpi = 300)                   # resolución de salida en dpi\n\nTambién es posible introducir las salidas gráficas en fragmentos de código de documentos Quarto para producir archivos html, pdf y docx de Microsoft Word.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  },
  {
    "objectID": "unidad7.html#composición-de-gráficos",
    "href": "unidad7.html#composición-de-gráficos",
    "title": "Unidad 7: Visualización de datos",
    "section": "Composición de gráficos",
    "text": "Composición de gráficos\nDentro de los paquetes complementarios del sistema ggplot, patchwork surge como una herramienta muy útil para la composición de gráficos de manera intuitiva y eficiente. A diferencia de las funciones de facetado propias de ggplot2, patchwork se enfoca en la flexibilidad y personalización, permitiendo crear composiciones complejas con mayor control sobre la disposición y el estilo de los gráficos individuales.\nSe basa en el concepto de fragmentos que se pueden combinar, superponer y organizar libremente utilizando operadores intuitivos como +, | y ~.\n\n\n\nOperador\nFunción\n\n\n\n\n+\nCombina gráficos horizontalmente.\n\n\n|\nCombina gráficos verticalmente.\n\n\n~\nApila gráficos uno encima del otro.\n\n\n\nAdemás de la simple combinación, patchwork ofrece herramientas para personalizar el diseño de la composición final, teniendo en cuenta márgenes, espacios, alineación y proporciones.\nImaginemos que tenemos varios gráficos que visualizar combinados (en nuestro ejemplo lo haremos con el único gráfico que construimos).\n\ngrafico &lt;- datos |&gt; \n  ggplot(mapping = aes(x = x, y = y, color = z)) + \n  geom_point(size = 2)\n\nlibrary(patchwork)\n\n(grafico + grafico) / grafico \n\n\n\n\n\n\n\n\nCombinamos mediante operadores básicos una salida de tres gráficos.",
    "crumbs": [
      "Unidad 7: Visualización de datos"
    ]
  }
]